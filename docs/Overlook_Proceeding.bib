% Encoding: UTF-8

@Article{Sundermeyer2015,
  author     = {Sundermeyer, Martin and Ney, Hermann and Schl\"{u}ter, Ralf},
  title      = {From Feedforward to Recurrent LSTM Neural Networks for Language Modeling},
  journal    = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
  year       = {2015},
  volume     = {23},
  number     = {3},
  pages      = {517--529},
  month      = mar,
  issn       = {2329-9290},
  abstract   = {Language models have traditionally been estimated based on relative frequencies, using count statistics that can be extracted from huge amounts of text data. More recently, it has been found that neural networks are particularly powerful at estimating probability distributions over word sequences, giving substantial improvements over state-of-the-art count models. However, the performance of neural network language models strongly depends on their architectural structure. This paper compares count models to feedforward, recurrent, and long short-term memory (LSTM) neural network variants on two large-vocabulary speech recognition tasks. We evaluate the models in terms of perplexity and word error rate, experimentally validating the strong correlation of the two quantities, which we find to hold regardless of the underlying type of the language model. Furthermore, neural networks incur an increased computational complexity compared to count models, and they differently model context dependences, often exceeding the number of words that are taken into account by count based approaches. These differences require efficient search methods for neural networks, and we analyze the potential improvements that can be obtained when applying advanced algorithms to the rescoring of word lattices on large-scale setups.},
  acmid      = {2876379},
  address    = {Piscataway, NJ, USA},
  doi        = {10.1109/TASLP.2015.2400218},
  issue_date = {March 2015},
  keywords   = {Kneser-Ney smoothing, feedforward neural network, language modeling, long short-term memory (LSTM), recurrent neural network (RNN)},
  numpages   = {13},
  publisher  = {IEEE Press},
  url        = {http://dx.doi.org/10.1109/TASLP.2015.2400218},
}

@Article{548162,
  author   = {Tsungnan Lin and B. G. Horne and P. Tino and C. L. Giles},
  title    = {Learning long-term dependencies in NARX recurrent neural networks},
  journal  = {IEEE Transactions on Neural Networks},
  year     = {1996},
  volume   = {7},
  number   = {6},
  pages    = {1329-1338},
  month    = {Nov},
  issn     = {1045-9227},
  abstract = {It has previously been shown that gradient-descent learning algorithms for recurrent neural networks can perform poorly on tasks that involve long-term dependencies, i.e. those problems for which the desired output depends on inputs presented at times far in the past. We show that the long-term dependencies problem is lessened for a class of architectures called nonlinear autoregressive models with exogenous (NARX) recurrent neural networks, which have powerful representational capabilities. We have previously reported that gradient descent learning can be more effective in NARX networks than in recurrent neural network architectures that have “hidden states” on problems including grammatical inference and nonlinear system identification. Typically, the network converges much faster and generalizes better than other networks. The results in this paper are consistent with this phenomenon. We present some experimental results which show that NARX networks can often retain information for two to three times as long as conventional recurrent neural networks. We show that although NARX networks do not circumvent the problem of long-term dependencies, they can greatly improve performance on long-term dependency problems. We also describe in detail some of the assumptions regarding what it means to latch information robustly and suggest possible ways to loosen these assumptions},
  doi      = {10.1109/72.548162},
  keywords = {autoregressive processes;generalisation (artificial intelligence);learning (artificial intelligence);recurrent neural nets;NARX recurrent neural networks;grammatical inference;information latching;information retention;long-term dependencies;nonlinear autoregressive models with exogenous recurrent neural networks;nonlinear system identification;representational capabilities;Computer science;Ear;Intelligent networks;National electric code;Neural networks;Nonlinear dynamical systems;Power system modeling;Recurrent neural networks;Robustness;System identification},
  url      = {https://clgiles.ist.psu.edu/papers/IEEE.TNN.long.term.dependencies.NARX.pdf},
}

@Article{558801,
  author   = {H. T. Siegelmann and B. G. Horne and C. L. Giles},
  title    = {Computational capabilities of recurrent NARX neural networks},
  journal  = {IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},
  year     = {1997},
  volume   = {27},
  number   = {2},
  pages    = {208-215},
  month    = {Apr},
  issn     = {1083-4419},
  abstract = {Recently, fully connected recurrent neural networks have been proven to be computationally rich-at least as powerful as Turing machines. This work focuses on another network which is popular in control applications and has been found to be very effective at learning a variety of problems. These networks are based upon Nonlinear AutoRegressive models with eXogenous Inputs (NARX models), and are therefore called NARX networks. As opposed to other recurrent networks, NARX networks have a limited feedback which comes only from the output neuron rather than from hidden states. They are formalized by y(t)=Ψ(u(t-nu), ..., u(t-1), u(t), y(t-ny), ..., y(t-1)) where u(t) and y(t) represent input and output of the network at time t, nu and ny are the input and output order, and the function Ψ is the mapping performed by a Multilayer Perceptron. We constructively prove that the NARX networks with a finite number of parameters are computationally as strong as fully connected recurrent networks and thus Turing machines. We conclude that in theory one can use the NARX models, rather than conventional recurrent networks without any computational loss even though their feedback is limited. Furthermore, these results raise the issue of what amount of feedback or recurrence is necessary for any network to be Turing equivalent and what restrictions on feedback limit computational power},
  doi      = {10.1109/3477.558801},
  keywords = {Turing machines;recurrent neural nets;Multilayer Perceptron;NARX neural networks;Nonlinear AutoRegressive models with eXogenous Inputs;Turing equivalent;fully connected;limited feedback;recurrent neural networks;Automata;Computational modeling;Computer networks;Multilayer perceptrons;National electric code;Neural networks;Neurofeedback;Nonlinear systems;Recurrent neural networks;Turing machines},
}

@Article{MenezesJr20083335,
  author   = {José Maria P. Menezes Jr. and Guilherme A. Barreto},
  title    = {Long-term time series prediction with the \{NARX\} network: An empirical evaluation},
  journal  = {Neurocomputing},
  year     = {2008},
  volume   = {71},
  number   = {16-18},
  pages    = {3335 - 3343},
  issn     = {0925-2312},
  note     = {Advances in Neural Information Processing (ICONIP 2006) / Brazilian Symposium on Neural Networks (SBRN 2006)},
  abstract = {The \{NARX\} network is a dynamical neural architecture commonly used for input–output modeling of nonlinear dynamical systems. When applied to time series prediction, the \{NARX\} network is designed as a feedforward time delay neural network (TDNN), i.e., without the feedback loop of delayed outputs, reducing substantially its predictive performance. In this paper, we show that the original architecture of the \{NARX\} network can be easily and efficiently applied to long-term (multi-step-ahead) prediction of univariate time series. We evaluate the proposed approach using two real-world data sets, namely the well-known chaotic laser time series and a variable bit rate (VBR) video traffic time series. All the results show that the proposed approach consistently outperforms standard neural network based predictors, such as the \{TDNN\} and Elman architectures.},
  doi      = {https://doi.org/10.1016/j.neucom.2008.01.030},
  keywords = {\{NARX\} neural network, Long-term prediction, Nonlinear traffic modeling, Chaotic time series, Recurrence plot },
  url      = {http://www.sciencedirect.com/science/article/pii/S0925231208003081},
}

@Article{Diaconescu:2008:UNN:1466884.1466892,
  author     = {Diaconescu, Eugen},
  title      = {The Use of NARX Neural Networks to Predict Chaotic Time Series},
  journal    = {WSEAS Trans. Comp. Res.},
  year       = {2008},
  volume     = {3},
  number     = {3},
  pages      = {182--191},
  month      = mar,
  issn       = {1991-8755},
  abstract   = {The prediction of chaotic time series with neural networks is a traditional practical problem of dynamic systems. This paper is not intended for proposing a new model or a new methodology, but to study carefully and thoroughly several aspects of a model on which there are no enough communicated experimental data, as well as to derive conclusions that would be of interest. The recurrent neural networks (RNN) models are not only important for the forecasting of time series but also generally for the control of the dynamical system. A RNN with a sufficiently large number of neurons is a nonlinear autoregressive and moving average (NARMA) model, with "moving average" referring to the inputs. The prediction can be assimilated to identification of dynamic process. An architectural approach of RNN with embedded memory, "Nonlinear Autoregressive model process with eXogenous input" (NARX), showing promising qualities for dynamic system applications, is analyzed in this paper. The performances of the NARX model are verified for several types of chaotic or fractal time series applied as input for neural network, in relation with the number of neurons, the training algorithms and the dimensions of his embedded memory. In addition, this work has attempted to identify a way to use the classic statistical methodologies (R/S Rescaled Range analysis and Hurst exponent) to obtain new methods of improving the process efficiency of the prediction chaotic time series with NARX.},
  acmid      = {1466892},
  address    = {Stevens Point, Wisconsin, USA},
  issue_date = {March 2008},
  keywords   = {NARX model, chaotic time series, hurst exponent, prediction, recurrent neural networks},
  numpages   = {10},
  publisher  = {World Scientific and Engineering Academy and Society (WSEAS)},
  url        = {http://dl.acm.org/citation.cfm?id=1466884.1466892},
}

@Article{Portegys2010306,
  author   = {Thomas E. Portegys},
  title    = {A maze learning comparison of Elman, long short-term memory, and Mona neural networks},
  journal  = {Neural Networks},
  year     = {2010},
  volume   = {23},
  number   = {2},
  pages    = {306 - 313},
  issn     = {0893-6080},
  abstract = {This study compares the maze learning performance of three artificial neural network architectures: an Elman recurrent neural network, a long short-term memory (LSTM) network, and Mona, a goal-seeking neural network. The mazes are networks of distinctly marked rooms randomly interconnected by doors that open probabilistically. The mazes are used to examine two important problems related to artificial neural networks: (1) the retention of long-term state information and (2) the modular use of learned information. For the former, mazes impose a context learning demand: at the beginning of the maze, an initial door choice forms a context that must be remembered until the end of the maze, where the same numbered door must be chosen again in order to reach the goal. For the latter, the effect of modular and non-modular training is examined. In modular training, the door associations are trained in separate trials from the intervening maze paths, and only presented together in testing trials. All networks performed well on mazes without the context learning requirement. The Mona and \{LSTM\} networks performed well on context learning with non-modular training; the Elman performance degraded as the task length increased. Mona also performed well for modular training; both the \{LSTM\} and Elman networks performed poorly with modular training.},
  doi      = {https://doi.org/10.1016/j.neunet.2009.11.002},
  keywords = {Maze learning, Context learning, Modular learning, Elman recurrent neural network, Long Short-Term Memory network, Mona goal-seeking neural network },
  url      = {http://www.sciencedirect.com/science/article/pii/S0893608009002871},
}

@Article{Portegys2015,
  author    = {Thomas E. Portegys},
  title     = {Training artificial neural networks to learn a nondeterministic game},
  journal   = {CoRR},
  year      = {2015},
  volume    = {abs/1507.04029},
  abstract  = {It is well known that artificial neural networks (ANNs) can learn deterministic automata. Learning nondeterministic automata is another matter. This is important because much of the world is nondeterministic, taking the form of unpredictable or probabilistic events that must be acted upon. If ANNs are to engage such phenomena, then they must be able to learn how to deal with nondeterminism. In this project the game of Pong poses a nondeterministic environment. The learner is given an incomplete view of the game state and underlying deterministic physics, resulting in a nondeterministic game. Three models were trained and tested on the game: Mona, Elman, and Numenta's NuPIC.},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/Portegys15},
  timestamp = {Sun, 02 Aug 2015 18:42:02 +0200},
  url       = {http://arxiv.org/abs/1507.04029},
}

@InProceedings{Kokkinos:2015:FPL:2801948.2801962,
  author    = {Kokkinos, Yiannis and Margaritis, Konstantinos G.},
  title     = {A Fast Progressive Local Learning Regression Ensemble of Generalized Regression Neural Networks},
  booktitle = {Proceedings of the 19th Panhellenic Conference on Informatics},
  year      = {2015},
  series    = {PCI '15},
  pages     = {109--114},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {The Generalized Regression Neural Network (GRNN) is a memory-based supervised learning neural network that performs non linear regressions and output estimation. However, if the number of the hidden layer neurons grows large, the evaluation of an unknown sample has a substantial computational cost. Whereas the GRNN run time can be reduced by parallelism, the computational load can be decreased by neuron reduction that compresses pattern neurons into fewer kernels. While such global models have been studied for a long time, there is another solution; that of local learning algorithms which use neighbourhoods to learn local parameters and create on the fly a local model specifically designed for any particular testing point. For this purpose we create a Progressive Local Learning Ensemble of many local GRNN models. Optimizing the number of k nearest neighbor neurons the method reduces substantially the cost of training as well as of predicting an unknown sample.},
  acmid     = {2801962},
  doi       = {10.1145/2801948.2801962},
  isbn      = {978-1-4503-3551-5},
  keywords  = {data mining, local learning algorithms, parallel computing, probabilistic neural networks},
  location  = {Athens, Greece},
  numpages  = {6},
  url       = {http://doi.acm.org/10.1145/2801948.2801962},
}

@Article{DBLP:journals/corr/MnihKSGAWR13,
  author    = {Volodymyr Mnih and Koray Kavukcuoglu and David Silver and Alex Graves and Ioannis Antonoglou and Daan Wierstra and Martin A. Riedmiller},
  title     = {Playing Atari with Deep Reinforcement Learning},
  journal   = {CoRR},
  year      = {2013},
  volume    = {abs/1312.5602},
  abstract  = {We present the first deep learning model to successfully learn control policies directly from high-dimensional sensory input using reinforcement learning. The model is a convolutional neural network, trained with a variant of Q-learning, whose input is raw pixels and whose output is a value function estimating future rewards. We apply our method to seven Atari 2600 games from the Arcade Learning Environment, with no adjustment of the architecture or learning algorithm. We find that it outperforms all previous approaches on six of the games and surpasses a human expert on three of them.},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/MnihKSGAWR13},
  timestamp = {Wed, 01 Apr 2015 20:06:15 +0200},
  url       = {http://arxiv.org/abs/1312.5602},
}

@Article{Mnih2015,
  author        = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
  title         = {Human-level control through deep reinforcement learning},
  journal       = {Nature},
  year          = {2015},
  volume        = {518},
  number        = {7540},
  pages         = {529--533},
  month         = feb,
  issn          = {0028-0836},
  __markedentry = {[sblo:]},
  abstract      = {The theory of reinforcement learning provides a normative account1, deeply rooted in psychological2 and neuroscientific3 perspectives on animal behaviour, of how agents may optimize their control of an environment. To use reinforcement learning successfully in situations approaching real-world complexity, however, agents are confronted with a difficult task: they must derive efficient representations of the environment from high-dimensional sensory inputs, and use these to generalize past experience to new situations. Remarkably, humans and other animals seem to solve this problem through a harmonious combination of reinforcement learning and hierarchical sensory processing systems4, 5, the former evidenced by a wealth of neural data revealing notable parallels between the phasic signals emitted by dopaminergic neurons and temporal difference reinforcement learning algorithms3. While reinforcement learning agents have achieved some successes in a variety of domains6, 7, 8, their applicability has previously been limited to domains in which useful features can be handcrafted, or to domains with fully observed, low-dimensional state spaces. Here we use recent advances in training deep neural networks9, 10, 11 to develop a novel artificial agent, termed a deep Q-network, that can learn successful policies directly from high-dimensional sensory inputs using end-to-end reinforcement learning. We tested this agent on the challenging domain of classic Atari 2600 games12. We demonstrate that the deep Q-network agent, receiving only the pixels and the game score as inputs, was able to surpass the performance of all previous algorithms and achieve a level comparable to that of a professional human games tester across a set of 49 games, using the same algorithm, network architecture and hyperparameters. This work bridges the divide between high-dimensional sensory inputs and actions, resulting in the first artificial agent that is capable of learning to excel at a diverse array of challenging tasks.},
  publisher     = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  url           = {http://dx.doi.org/10.1038/nature14236},
}

@Article{Dymova2016,
  author        = {Dymova, Ludmila and Sevastjanov, Pavel and Kaczmarek, Krzysztof},
  title         = {A Forex trading expert system based on a new approach to the rule-base evidential reasoning},
  year          = {2016},
  volume        = {51},
  pages         = {1--13},
  month         = jun,
  issn          = {0957-4174},
  __markedentry = {[sblo:6]},
  abstract      = {Abstract Currently FOREX (foreign exchange market) is the largest financial market over the world. Usually the Forex market analysis is based on the Forex time series prediction. Nevertheless, trading expert systems based on such predictions do not usually provide satisfactory results. On the other hand, stock trading expert systems called also “mechanical trading systems”, which are based on the technical analysis, are very popular and may provide good profits. Therefore, in this paper we propose a Forex trading expert system based on some new technical analysis indicators and a new approach to the rule-base evidential reasoning (RBER) (the synthesis of fuzzy logic and the Dempster-Shafer theory of evidence). We have found that the traditional fuzzy logic rules lose an important information, when dealing with the intersecting fuzzy classes, e.g., such as Low and Medium and we have shown that this property may lead to the controversial results in practice. In the framework of the proposed in the current paper new approach, an information of the values of all membership functions representing the intersecting (competing) fuzzy classes is preserved and used in the fuzzy logic rules. The advantages of the proposed approach are demonstrated using the developed expert system optimized and tested on the real data from the Forex market for the four currency pairs and the time frames 15 m, 30 m, 1 h and 4 h.},
  keywords      = {Fuzzy logic, Dempster-Shafer theory, Forex, Technical analysis, Rule-base evidential reasoning, Expert system},
  url           = {http://www.sciencedirect.com/science/article/pii/S0957417415008301},
}

@Comment{jabref-meta: databaseType:bibtex;}
