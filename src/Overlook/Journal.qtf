[#l417;r417;R $$0,0#00000000000000000000000000000000:Default]
[=l417;r417;phN1;*cR+150 $$1,1#26C05E505BFA12B5D94A958416AE5FF3:Chapter 1]
[=l417;r417;phN11;*R+117 $$2,2#F98403FAA9BE0040ACA893F21E4D9F2D:Chapter 2]
[=l417;r417;phN111;*R $$3,3#0680C0FF67EEE4E167183D1E74BF079F:Chapter 3]
[{_}%FI-FI 
[s1;N; &]
[s1;N; &]
[s1;N; &]
[s1;N; &]
[s1;N; &]
[s1;N; &]
[s1;N; &]
[s1;N; &]
[s1;N; &]
[s1;N; &]
[s1;N; &]
[s1;N; &]
[s1;N; &]
[s1;N; [2 In the making of the Overlook]&]
[s1;N; [+217 JOURNAL]&]
[s1;N;3 &]
[s1;N;3 &]
[s1;N; [3 Everything is obvious afterwards]&]
[s1;N; &]
[s1;N; &]
[s1;N; &]
[s1;N; &]
[s1;N; &]
[s1;N; &]
[s1;N; &]
[s1;N; &]
[s1;N; &]
[s1;N; &]
[s1;N; &]
[s1;N; &]
[s1;N;2 &]
[s1;N;2 &]
[s1;N; [2 by]&]
[s1;N; Seppo Pakonen&]
[s1; Introduction&]
[s0; I write this journal to keep myself focused on the end result: 
the working product. This text is sort of an investment, which 
loses value, if I don`'t get the product finished. Writing investment 
code gets on to your nerve intensively and failing code means 
losses. Keeping this program open and social helps one to cool 
down from the stress of the `"real life losses`" part.&]
[s0; I like to tell how original this application is and to communicate 
the countless hours and the sweat what I did see for this. The 
progress of this project is driven only by my curiosity and basic 
needs. Please note that my native language is not English, but 
Finnish. This journal is intended for the audience who see some 
entertainment value in this. This document is an artistic expression 
as whole without target audience. This is only an opinion of 
the author and this is not checked for wrong facts.&]
[s0; This journal is mostly about very uninteresting stuff and this 
is a good option for those who would otherwise check the progress 
via git commit history. This text tells mostly about technical 
problems in a difficult way, but it has some juicier off`-topic 
sections.&]
[s0; &]
[s0; &]
[s0; &]
[s0; &]
[s0; &]
[s0; &]
[s0; &]
[s0; &]
[s0; &]
[s0; &]
[s0; &]
[s0; &]
[s0; &]
[s0; &]
[s0; &]
[s0; &]
[s0; &]
[s0; &]
[s0; &]
[s0; &]
[s0; &]
[s0; &]
[s0; &]
[s0; &]
[s0; &]
[s0; &]
[s0; &]
[s0; &]
[s0; &]
[s0; &]
[s0; &]
[s0; &]
[s0; &]
[s0; &]
[s0; &]
[s0; &]
[s2; Pre`-Release Journal&]
[s0; This is the time before the first working version. It is about 
searching for the best design via trial and error. Some ideas 
seemed good but turned out to be bad. All of the ideas were related 
to the end result in some way, however.&]
[s0; The result was good and the whole process went almost as expected. 
Only the completion took longer than expected. The following 
phase took almost 3 months and work was done almost every day. 
During that time, estimated 600`-800 hours was worked on this 
directly. The count of hours was very well noted during development, 
which did lead to a lot of off`-topic text.&]
[s3; 26.4.2017&]
[s0; Welcome to the first entry of this journal.&]
[s0; Today, I am trying to get runner working. Slots should be processed 
in very varying and complex order. Slots have dependencies, and 
first thing is to make the graph to draw them in a nice way. 
The time is 10.20 and there is snow raining outside my window. 
The sky is completely white from clouds. The snow what was melted 
during early spring is replaced again by new snow. The temperature 
is around 0 Celcius. I am way behind schedule if I check how 
much coffee I have been drinking already. This is a isolated 
place with long, dark and cold winter and short summer, which 
is the very essential reason for my programming. I would rather 
travel to Greece for most of the winter.&]
[s0; Graph works. I noticed missed links from that image. Next: the 
processing batches, which can have concurrent internal processing. 
The progressing is kind of brute`-forcing now. I need to get 
this finished by end of may. Luckily, I have free time now from 
the university where I am studying computer science.&]
[s0; Ok, so I planned the new batched runner thing. I checked the 
huge todo and problem list, and then checked what code exists 
and what should be added. That`'s the normal method. I can`'t 
start implementing immediately, because it requires a more practical 
mindset. I must take a break before it. I`'m listening to classic 
rock internet radio channel... now playing Pearl Jam `- Even 
Flow. I usually listen to classic rock or ambient electronic 
internet radio. I can`'t stand too repeating playlist.&]
[s0; I got the batches formed. The groups are interesting. There 
is 8 groups in total currently. Such a difficult time to progress 
now. Planned stuff doesn`'t fit well, and some old requirements 
are invalid.&]
[s0; Finished. The RunnerCtrl now has batches. The result is a lot 
different what I planned, but it turned out well. I am too tired 
to debug it, though... This was rather difficult day, mostly 
because I had to re`-plan the implementation few times and then 
again change it while implementing. The change of the plan is 
the worst energy consumer... Usually I don`'t have to re`-plan 
this much.&]
[s3; 27.4.2017&]
[s0; The first batch is being processed. It happens somewhat correctly. 
Seems like locking data areas for processing is a mess, and it 
must be solved next. I am thinking about adding few more arguments 
to `"AddDependency`" and then locking data areas for them, and 
also asserting that data is really locked already at use time. 
Without that, multithreading seems to be slower than single thread 
:D ...that`'s bad.&]
[s0; Also, I was thinking, that some continuous training would be 
great. Agent slots doesn`'t need to be necessarily entirely trained 
and processed, but all of them can be done incrementally. As 
the input stays same, all neural networks just fits better to 
existing and they doesn`'t change much. For that reason it is 
possible. Basically, the whole stack will be trained instead 
of just going from bottom to top once. That, while reacting fast 
to the real`-time events simultaneously, will be a challenge.&]
[s3; 28.4.2017&]
[s0; Last evening I got an idea, that the nn`-slot`-stack should 
have specific time how long it can be trained. In that way, uniform 
training could be guaranteed. Ever symbol/timeframe/custom`-slot 
would get it`'s own share of processing time. The task`-switch 
of slot`-processing is very light procedure, so rather fast switching 
is possible. Only at least one full processing cycle is required 
before moving to next batch, and lower slots should be ahead 
of higher in processing position, but that is only recommended, 
not required.&]
[s0; Hmm... ok, so I have been reducing those spinlocks and memory 
releases from old model, and I think that the current small memory 
model is too fine`-grained for efficient usage. All time`-slots 
for symbol are single memory units, and that causes too much 
overhead. Previously I did the normal thing: reserved one long 
vector for sym/tf/slot, but it had other problems. I guess, I 
must fall back into that. There was a possibility, that slots 
would require same type from different sym/tf, which required 
preparing for sym/tf complexities inside one type of slot, but 
it never came true. Now all reservations for those complexities 
can be pruned away. I must say, that the current API was developed 
with this small memory model and that is better than previous, 
but the underlying model must be returned to have whole time`-range 
in one vector. Actually, the small memory model was extremely 
compact, and I could set the memory limit to 640kb, with over 
1GB cache, and it would still work :) ...but now that feature 
causes only overhead.&]
[s0; Ok, so the normal memory model raises the minimum requirement 
from that 640kb to a lot more. My PC and server can have more 
than 64GB SSD swap memory, so it won`'t be problem for me, but 
we try to think little guys too. My PC is by the way AMD CPU 
8`-core 4GHz, Memory 8GB DDR3, and I don`'t care graphics any 
more. I guess it`'s still high`-end PC currently. I have always 
had AMD cpu in my built`-from`-parts PC since Amiga 500.&]
[s0; Looks like there is some Fyre Festival situation going on. Some 
critique is not valid, since there is clearly images about the 
accomodation being in that kind of tents. However, the marketing 
is too rosy as always and common sense was missing. I was the 
opposite of the rich kid, and while I never would have fallen 
into buying a Fyre ticket, that event could have also been a 
success, if that huge ticket money was spent properly. Unfortunately, 
the high price was a scam, like too many times in the past. Next 
time when someone tries something similar, they should have a 
great 24/7 buffet and the real security.&]
[s0; Seems like changing the memory model is a big operation. I had 
to comment the existing code out, and it`'s hard to see what 
needs to be done. It will sort out eventually.&]
[s0; Didn`'t finish the memory model changing today.&]
[s3; 29.4.2017&]
[s0; The program is now running and it seems to be free of memory`-errors. 
I could valgrind it, but it probably shows clean, because the 
U`+`+ memory debugger usually catches worst problems. It starts 
and stops cleanly, but slowly. Some kind of beautiful waiting 
screen is needed.&]
[s0; Today, the target is to get first two batches processed, which 
is rather easy one.&]
[s0; The first batch done. The second batch crashes to some asserts. 
How typical.&]
[s0; The second batch done, earlier than expected.&]
[s0; When I have time to work all day, then the second part of the 
day is usually full of mistakes and difficulties to progress 
because of me being tired. I overcome that by solving simpler 
problems and fixing bugs only at next morning. It`'s usually 
comfortable enough, but it requires knowing that you can`'t do 
as good as in the morning and you shouldn`'t even try. The most 
stressful thing is to have deadlines and strict jobs while being 
tired, and being stressed is bad in the long run. Writing natural 
language notes, like this, is also useful, because you can collapse 
your thoughts into something concrete. It takes time to get into 
this kind of work routine and many kind of rewards must be involved.&]
[s0; I added serialization functions for remaining classes. I`'m 
not sure if they work at first try. There is some tricky reloadings.&]
[s3; 6.5.2017&]
[s0; One week since previous entry. I didn`'t have much time to do 
this at this week and I forgot this journal. I feel that this 
is a little bit silly. I am going to give it a try anyway.&]
[s0; This Overlook repository was forked once during the week, and 
I got nice message concerning improvements of the program. This 
is a very little amount of activity compared to popular open 
source projects, but big deal for me. Forking this is still discourged, 
as the app doesn`'t have any useful and working state yet.&]
[s0; During the week, I fixed the processing of recurrent neural 
network slots. The values might be still incorrect, but I can`'t 
fix them yet. I can diagnose the data, only when the app runs 
completely. So, one step at a time.&]
[s0; This is absolutely massive project for one programmer. I would 
highly appreciate other contributors. Also, processing times 
are worrisome for the current computing capacity. I am not sure 
that is the neural network training time something acceptable 
and sane yet. The training must be repeated eventually, and probably 
sooner than later, so I don`'t want to wait two weeks after reset...&]
[s0; I also created a proceeding document in the [/ /docs] folder. 
I am doing the master`'s thesis later, and that might be re`-used 
in the thesis. It also helps a lot to keep this project coherent. 
In that paper, you must say things as clear as possible, and 
test results must be handled properly, which is very helpful, 
even if the paper isn`'t published ever. I am still looking for 
to finish this project in this May 2017, but the paper will propably 
remain unfinished for some time.&]
[s0; Today`'s objective is to get all agents running, but if something 
bigger must be implemented, then it won`'t happen. After that 
the big loop should run without problems, but the values will 
still need bugfixes.&]
[s0; Overlook is basically huge pipeline. It has complex dependencies, 
which causes processing to be done in batches, which is like 
car assembly line, where different stuff is done in different 
places. To progress with the implementation efficiently, programmer 
have to use a technique, which has different kind of rounds. 
These rounds can take from hours to weeks. For example, round 
structure has been following so far (`+ what I assume happening 
next):&]
[s0;i150;O9; 1. Planning of the pipeline&]
[s0;i150;O9; 2. Creating all classes and main functions, and implementing 
main frame, including threading model and all busy loops. The 
program must shutdown properly, without memory leaks etc. , in 
this point. The pipeline should work with dummy classes after 
this point.&]
[s0;i150;O9; 3. Implementing all classes and adding them to the pipeline. 
Code must compile but not run. The programmer must be experienced 
to be able to program without testing the code.&]
[s0;i150;O9; 4. Running the program and fixing the runtime bugs in 
the pipeline.&]
[s0;i150;O9; 5. Implementing and testing rest of the GUI features. 
This usually requires so much fast iterative testing and fixing, 
that it must be done in per`-class basis. The pipeline must be 
able to be restored from the cache file in 20 seconds for this 
method to work.&]
[s0;i150;O9; 6. Analysing the pipeline and checking all values with 
the nice new GUI. It must be constant and everything must be 
logged in a fail`-safe way.&]
[s0;i150;O9; 7. Polishing the turd. Release the little fucker into 
the wild and see what happens. In this point, you really must 
clean the code and do or discard your TODO list.&]
[s0; I am currently at the round 4 and I try to finish it today. 
This requries much patience from the programmer and this can`'t 
be recommended to noobs.&]
[s0; Aaaand round 4 finished. I have still time to: test multithreading, 
fix re`-processing looping broker reset, the change slot has 
[/ cost] everywehere but shouldn`'t.&]
[s3; 7.5.2017&]
[s0; The analyzer part needs planning currently. The paper what I`'m 
writing requries that, and it`'s also useful in general.&]
[s0; Oh, I needed the ideal orders slot, and then I thought how it 
could be used in forecasting or with agents, and then I remembered 
two types what I ignored previously.&]
[s0; The ignored forecaster was autoencoder neural network, which 
basically has very tight bottleneck in the center, which causes 
very generalized output, which is good if you want very generic 
forecast. That might be useful input in the combining Forecaster 
class. Alone it won`'t work well.&]
[s0; The ignored agent was classifier neural network. I didn`'t know 
how to imlement this previously. Basically, it uses that ideal 
order signal as output, which is `"the shortest route to highest 
value accumulation`". It is unrealistic to expect finding that 
in real time, but it is possible afterwards. The market behaves 
very randomly, so the classifier won`'t perform well alone, but 
it can be a good additional signal for meta`-agent.&]
[s3; 9.5.2017&]
[s0; A lot of plan changes today. I needed my old A`* search algorithm 
code. When I found it, I decided to import some other old code 
too. You can check it from CoreUtils... Anyway, one thing led 
to another, and I need to redesign everything from the AnalyzerCtrl 
viewpoint. Ok, not everything, but many things. There was the 
QueryTable code and I noticed that it was also a very simple 
predictor and there is always demand for different types of predictors 
in this project. I noticed, that the QueryTable is so generic, 
that it could be used as a dummy alternative instead of almost 
any forecaster or agent. The QueryTable imports integer values 
and exports integer values, if you reduce the string`-complexity. 
Comparing QueryTable and NN forecasters is kind of like comparing 
discrete and continuous probability distributions.&]
[s0; So, all NN classes in Overlook could be over`-simplified to 
QueryTables, and all values could be changed to be discrete values 
in some range. That might be stupid to implement, but for me 
it gave a new idea about class structure for connecting classes 
to each other, and by classifing different types of signals.&]
[s0; I haven`'t developed this idea yet, but seems like from analyzer`'s 
viewpoint, you should make the testing more comprehensive and 
automatic, and the combination of slots should be done based 
of that testing [_ instead of the manual loader.]&]
[s0; Currently user sets what slots he wants to use, but the premise 
is that user wants the best performance and better solution would 
be that the performance analyzer combines best performing slots 
or uses existing pre`-analyzed combination.&]
[s0; One expects, that NN forecasters and agents outperforms QueryTable 
alternatives, but it should be measured.&]
[s0; This also opens possibility of out`-of`-order slot connections. 
Basically it causes falling back to one class object per symbol/timeframe. 
It might be too complicated, though. Also, there is no need to 
make unreasonable combinations and the rules for combinations 
will still be rather strict.&]
[s0; Damn, so much more work.&]
[s0; I guess, that the basis will be some kind of prioritising system, 
which can connect different kind of slots in different symbol/timeframes. 
It prunes out probably known outcomes and verifies the best performing 
combinations.&]
[s0; The prioritising system needs a new Slot`-class replacement 
and that new class should prefer smallest possible processing 
unit (1. sym`+tf, 2. sym, 3. tf, 4. all). [_ All kind of processing 
units should still be possible,] because that is required by 
some slots (e.g. NARX). Different phases could be: source`-data, 
indicator, forecaster, forecaster`-combiner, agent and agent`-combiner. 
Values between slots are classified based on their origin`-phase 
and type of value. Custom slots will define what classes of values 
they can use. It is better in that way instead of defining exact 
sources of values. Some slots could export same signal in floating`-point 
values and in integer`-values.&]
[s0; The overview of the change of the plan is now clear, but details 
are still missing. This is almost enough from today. Must sleep 
on this. FML.&]
[s3; 10.5.2017&]
[s0; I have been thinking how to implement new changes with least 
work and working time. Seems like I should build another base 
system from scratch and then copy`-paste all compatible parts. 
I could skip the reference memory model, because this can be 
done better without it. That means skipping all [/ linking] of 
paths. It was essential in the research phase, but it is not 
required for final product anymore. It was flexible for testing 
and for searching the final plan.&]
[s0; Another shortcut is that I could combine [/ Core] and [/ Ctrl ]code. 
That would mean that e.g. MovingAverage does both drawing the 
graph and calculating values. It`'s far from [/ high performance 
computing] as we know it, but I am going to run this in desktop 
PCs anyway. I am not huge fan for simplifying the program that 
far.&]
[s0; I am going to make all changes in place of current project files. 
I will put all files in the Overlook folder this time.&]
[s0; Now, let`'s do the planning. Custom classes and their features 
will be same, but the underlying system changes, and that must 
be planned:&]
[s0;i150;O2; All graphics and computing are in the same classes&]
[s0;i150;O2; Different phases in the pipeline are: source`-data, indicator, 
forecaster, forecaster`-combiner, agent and agent`-combiner.&]
[s0;i150;O2; Prioritizer has huge sym/tf/phase space to prioritize 
different combinations of pipeline`-units. The success of one 
combination will prioritize it higher on all sym/tf, etc.&]
[s0;i150;O2; Prioritizer`-slots are tied to phase and their import 
and export values have typed values (by their phase and type 
of signal). I guess these rules limits combinations enough.&]
[s0;i150;O2; Prioritizer`-slots define their processing area size. 
They can process 1. sym`+tf, 2. sym, 3. tf, 4. all. My traditional 
indicator collection in archives can be imported when sym`+tf 
are supported again.&]
[s0;i150;O2; The processing queue in the Prioritizer is derived from 
current Session class. The prioritized queue will replace batches, 
and analyze`-queue will change priorities when processing have 
been completed. Basically all [/ processing`-receipes] exists in 
the same queue and only the processing will trigger the creation 
of the processing slot object. All priority changes are done 
after the analyzing, which can be followed from the GUI.&]
[s0;i150;O2; The paper need results, which can be exported from analyzing 
results. It can be improved easily over time, when all the primitive 
analyzing is done in small parts at first, and the more comprehensive 
analyzing can be done from same points later.&]
[s0; I am little sad about the need to rewrite so much. This version 
required some seriously hard work already. However, this is 12th 
time during 6 years when this kind of rewrite plan had to be 
made, if I remember correctly. I wrote the progress down somewhere, 
but I have no clue where that text is.&]
[s0; The QueryTable will be the first dummy slot in every phase. 
Even the prioritizing could be done with it. Then NN archs can 
compete with it, and when they outperform QueryTable, they can 
the primary processor.&]
[s0; Round 2. Creating all classes. Also, moved everything to sourceforge 
in part of the new UltimateScript project :)&]
[s0; ...&]
[s0; Well this was unexpected day. I copied all the most important 
existing code and tried to reduce useless complexity at the same 
time. The line count is around 10000 lines, which is good.&]
[s3; 11.5.2017&]
[s0; The implementation plan for Prioritizer class was getting more 
clear today. Instead of iterating all combinations of slots somehow, 
the combination must be created from last to first based on QueryTable 
values. For most of the slots, there is huge amount of input 
switches, which suggests that combination iteration is very bad 
solution.&]
[s0; I also planned the featuers of QueryTable custom slots. They 
are very simple when compared to neural network alternatives, 
but that is good at the beginnig as NN slots can be added later.&]
[s0; Today`'s tasks are:&]
[s0;i150;O0; implementing queue generating function using QueryTable, 
which requires slot`-value`-types etc.&]
[s0;i150;O0; continue implementing QueryTable classes until time 
runs out&]
[s0; I might not complete the first task today. It`'s very complex.&]
[s0; ...&]
[s0; I searched the import and export types of values for existing 
classes. This changes plan again. These types can automatically 
be connected with QueryTable and existing custom slots can be 
provided as bridges between value`-types. So these bridges between 
value`-types are being connected, and the combinations are tested. 
&]
[s0; Seems like this should be started from new project. The existing 
package is a mess. I will add good stuff from it later. Sadly, 
this journal stays here too.&]
[s0; ...&]
[s0; This priority`-queue maker from recursive reverse visiter is 
a tough nut to crack. I haven`'t had this difficult problem in 
months. &]
[s0; ...&]
[s0; Finally, I cracked that nut. The combination of slots is a binary`-string. 
It enables some features which I am too tired to describe now. 
One thing sure is that I will start implementing it tomorrow. 
It allows very fast QueryTable processing and small memory footprint.&]
[s0; Basically, you can put all arguments affecting the system into 
the binary`-string, and you can easily fetch all results relating 
to a single argument. Then you can analyze how valuable some 
argument`-value is. In the end the application can show detailed 
list of reasons why the best combination is what it is.&]
[s0; This was exhausting day, and I almost didn`'t write code at 
all. Very weird... I just refined this plan. The complete opposite 
is to do some hand routine where you don`'t need to think at 
all.&]
[s0; This day will be the cornerstone of the results of my master`'s 
thesis, however.&]
[s3; 12.5.2017&]
[s0; Yesterday was especially troublesome day. It is almost unbelieveable 
that I managed to summarise the final binary`-string plan. The 
clues kept coming throughout the day, but they weren`'t obvious.&]
[s0; Seems like the project progresses normally today. I`'m on the 
way of implemention already. The tasks for today are:&]
[s0;i150;O0; custom slots must export input `& output types&]
[s0;i150;O0; in `& out types must be collected at custom slot registration&]
[s0;i150;O0; RefreshQueue combination queue maker&]
[s0;i150;O0; unique slot processing queue for combination queue&]
[s0;i150;O0; new slot objects to the queue objects or move from previous 
queue&]
[s0;i150;O0; the correct processing order based on dependency relationships&]
[s0;i150;O0; processing of slots&]
[s0; Yet, yesterday I was completely stuck with the plan.&]
[s0; ...&]
[s0; This comination`-queue maker is the worst bottleneck. I made 
a plan and schematic`-like picture, but I still almost get stuck. 
This is completely new topic for me, maybe that`'s why.&]
[s0; ...&]
[s0; The progressing is exceptionally slow. The RefreshQueue combination 
queue maker has such a resistance. &]
[s0; I managed to iterate all initial combinations, but some of them 
might be bad. There are some rules for those, and I haven`'t 
checked them all yet.&]
[s0; Ok, the progressing speed was 1/4 of what I hoped, but that 
is still better than being stuck. This was almost fun and it 
was pure entertainment compared to the confused planning of yesterday.&]
[s3; 13.5.2017&]
[s0; I found a nice graphical list of neural network architectures 
via stumbleupon http://www.asimovinstitute.org/neural`-network`-zoo/ 
. It would be interesting to implement all of these in the Overlook 
and make a performance comparison. The included ConvNetC`+`+ 
supports almost all of those already, and many of those has been 
demonstrated in the ConvNetC`+`+ examples. The missing features 
are rather easy to implement with the correct documentation. 
I don`'t have high hopes for finding anything useful from those, 
but it sure would be interesting. It would also be good for the 
sake of completeness.&]
[s0; Today things go smoothly. The speed of progress has been improving 
two days in a row.&]
[s0; There is some epic computer security problem going on. Every 
news source reports it. Those doesn`'t really affect my FBSD 
systems. This is vulnerable, of course, but the reward for exploiting 
them is so low, that probably no one bothers. The feeling of 
open and secure OS is just best.&]
[s0; ...&]
[s0; I did some major restructuring. The new Factory class handles 
all custom classes in the project now. The main overlook program 
is just opening static objects which are registered to the factory. 
Very simple and nice.&]
[s0; ...&]
[s0; Seems like in 24 hours happened `"Biggest Ransomware Attack 
In History`". Only news reports about it yet. Some smaller blogs 
too. ZeroHedge has long discussion topic about it, and . The 
New York Times has `"Animated Map of How Tens of Thousands of 
Computers Were Infected With Ransomware`" (https://t.co/LDFCW9K5Ls) 
which is interesting, because it shows a global response in one 
hour. This may not be big thing in total cost of damages, but 
it will cause huge wave of discussion in every smallest possible 
traditional news source, [_ and at the same time globally.] That 
will be a wake up call about the real global scale of human establishment 
for many for sure. Unfortunately, it will cause an opposition 
of people wanting to ban bitcoin and crypto`-currencies, without 
understanding that they want to ban a mathematical algorithm, 
which was invented a short time ago.&]
[s0; ...&]
[s0; I managed to implement all the queueing today. Still, querytable 
isn`'t being used. Seems like I must postpone it until result 
vector has enought items in it.&]
[s3; 14.5.2017&]
[s0; Heavy snowfall at outside. Usually this doesn`'t happen in May. 
I haven`'t seen anything like this ever before. This feels like 
January and I can`'t tell any difference from the view what I 
see from my window. It should be almost summer. Two years ago 
the may was especially sunny and between 15`-20 degress of Celcius 
at daytime, now it rains snow all the time. This is still somewhat 
normal in Finland, but not usual. This year`'s potato farming 
will definitely suffer with this trend.&]
[s0; I am implementing the processing of the job`-queue, but there 
is some dragons ahead. Previously I tested some high`-performance 
computing model, but it had to be ditched eventually. It just 
wasn`'t flexible enough and benefits were also lost in the end. 
Now I am falling back to the model, which is very similar to 
the MetaTrader`'s MQL language. This, however, allows processing 
of multiple symbols and timeframes at once, which is requirement 
for classes like NARX. There is some positive implications from 
this too: I can import all my old indicators to the overlook. 
If it had been any more difficult than copy`-pasting, I would 
have skipped it, but now I can adjust the base class to do just 
that.&]
[s3; 15.5.2017&]
[s0; I am continuing developing Overlook in github. I tested to combine 
all libraries to one repository, but it wasn`'t such a good idea. 
First of all, the UltimateScript, where I added them, could have 
them in a repository, but they should be converted to it`'s own 
GUI`-libraries, which hasn`'t been started even yet, in it takes 
forever to get there. Second, I can`'t showcase invidual modules, 
which has unique value. I am going to work on UltimateScript 
this summer, though, but it`'s better to start that from empty 
desk (or repository).&]
[s3; 17.5.2017&]
[s0; Implementing the Prioritizer class was a lot more difficult 
than expected. Yesterday, I had to add features which caused 
more complexity to it again. Today I finally got into debugging 
it. Now I am creating functions to dump all the debugging information, 
and even that is rather difficult. I am not complaining about 
it, but just writing it as a note. You can`'t always do easy 
routines, which can be done as fast as your hands can write. 
It would be a bad sign if you could.&]
[s0; ...&]
[s0; Looks like the initial job`-queue is being formed correctly. 
It was difficult to debug the prioritizer enough to do that. 
I am afraid that there will be some hard`-to`-find bugs left 
there. Not good. Now I could finally start work on basic graph 
indicators and make them work. Almost enough from today... must 
have a break, at least.&]
[s3; 18.5.2017&]
[s0; Today, I lost my focus because of some troubles around me. In 
the end, I managed to restore my good spirit by thinking symbolically 
this Overlook project and what it reminds me of. I wrote very 
little code, but I found some new thoughts what I would like 
to share in this. I am just improvising here...&]
[s0; Overlook is, essentially, about watching the most important 
aspects of the whole human establishment on Earth. So, what if 
you take away humans from the equation, and think it as one single 
super`-organism, which could work even without humans or animals. 
You would get a huge lifeless or plant`-like organism, where 
evolution of technology etc. would happen virtually via databases 
and mechanical plants. There would a enormous single database 
of everything.&]
[s0; What if we would re`-introduce entities with neural`-networks 
into that enormous almost lifeless plant`-like organism? Micro`-organisms 
with brains, like birds and fishes, but not quite same. Something 
completely new. The super`-organism would create their body and 
give a spark for thinking, but what would happen next? Technically, 
their brain would start to train the huge database and to recognize 
the image of the structure of the super`-organism. Symbolically, 
they would duplicate a tiny portion of perfect information into 
the weight of their neural networks. While training their brains, 
they would start to feel enlightened. Perplexity of the training 
would go lower, and they would feel really, really small when 
they compare their training`-data to all possible information.&]
[s0; You and me feel some constant signals, like background noise, 
pain in the butt while sitting, and the temperature of the room. 
Those neural`-network entities would also have some of those. 
Have you ever suddenly remembered, that you have some event next 
day, which you had completely forgotten? Those entities would 
have same senses. Other example is, that sometimes the lecturer 
will give you new inspiring thoughts, and sometimes you are waiting 
the class to end and the lecturing is just background noise. 
You and me would probably prefer that curious feeling of learning 
something new and important, instead of making the time go by 
as fast as it can. My guess is, that the curious feeling is technically 
just very fast forward`- and backward`-propagation in biological 
synapses with lowering perplexity of the training data, which 
is connected as a reward to some hormone producer. That is a 
over`-simplification, of course.&]
[s0; The conciousness of those neural`-network entities would be 
the increasing harmony with the perfect information, the information 
by itself and their biological structure being produced by the 
super`-structure for whatever reason. The probability of their 
existence would be lower, than existence of the super`-structure 
and the information. So, one part of the conciousness would also 
be the understanding, that they really do exist despite improbabilities.&]
[s0; This is just me goofing around. Don`'t take it too seriously... 
:)&]
[s0; Hopefully something real tomorrow...&]
[s0; This was very silly post.&]
[s3; 19.5.2017&]
[s0; Finally something real. The candle`-stick graph drawer works 
now. There is still many problems left even before indicators 
can be drawn. This is definitely the most difficult thing that 
I have ever programmed. That prioritizer code is a b`*tch. The 
progressing speed is about 1/5 of what I expected. Not fun.&]
[s0; [/ Next stop]: adding connections of multiple symbols and timeframes 
to a single core`-object at the single job`-queue iteration in 
Prioritizer`::RefreshJobQueue. That kind of stuff needs a new 
morning and a fresh cup of coffee.&]
[s3; 20.5.2017&]
[s0; I added all`-symbols`-enabled and all`-timeframes`-enabled bits 
to the combination, which allows some custom`-core`-objects to 
automatically use multiple symbol sources. That caused huge job`-queue 
to be created, which was correct, however. In this version, the 
core`-object is allocated to the job`-item, but with all those 
jobs, it takes too long time to allocate them all, and it seems 
to use too much memory in total. So, clearly this was a flaw 
in the design. It will probably be fixed by allocating only necessary 
core`-objects in the processing phase.&]
[s3; 23.5.2017&]
[s0; Today, I worked on the feature that allows user to configure 
custom core`-objects, e.g. changing period in the moving average 
indicator. This version, which uses prioritizer to resolve dependencies 
for the export object, doesn`'t allow configuring dependencies 
from dependee. It causes some headache, but it is actually very 
reasonable feature. Turns out, that most of the indicators doesn`'t 
require features, that couldn`'t be calculated locally, and those 
shouldn`'t be in the way of the prioritizer combination. Rest 
of old indicators, which relies heavily on some dependency, usually 
just proxies argument values to the dependency, and those values 
could be written directly the dependency. ... . I didn`'t foresee 
these things, but they occured while I was trying to implement 
some required features.&]
[s0; Also, some other simplifying was done today. [/ GetIO ]has to 
be changed to [/ IO,] because it can now be used for setting values. 
These simplifications makes me happy, because I don`'t need to 
reduce features, the amount of code is less and the readiblity 
of the code is better.&]
[s0; I still don`'t have a fast hand`-routine for converting old 
indicators to the current system, but it looks like in following 
days it could be found. I still have a problem, that some custom`-core`-classes 
requires different symbols and timeframes, and those should be 
known partially in the combination creation and entirely in the 
custom slot creation point, which is still long before the creation 
of the object... So, I guess there must be some sort of lambda`-function, 
that can be statically exported to change those arguments.&]
[s0; To sum it all, in the old version, all dependencies could be 
configured in the Init method, but in the current version, all 
custom`-class dependencies must be solved internally, and all 
different symbol/timeframe dependencies must be solved with a 
static function. Previously 1 part, now 2 parts. All java programmers 
have been used to static functions and classes, but with the 
C`+`+ rule, that everything must be owned by someone, static 
functions must have a good reason to exist. Of course, some people 
code C`+`+ like java etc. and it works, but with the target of 
clean, readable, safe and compact code, you don`'t code C`+`+ 
like java.&]
[s3; 24.5.2017&]
[s0; Quick update, because I`'ve already programmed enough today.&]
[s0; This prioritizer class is ridiculously complex, but it will 
allow some complex optimizing, which can take some shortcuts 
in the heavy processing, hopefully. Usually those custom`-core 
classes make just clean pipes, but sometimes they require data 
of different symbols and timeframes, and you don`'t want to calculate 
them all. That was the problem, and today I implemented the feature, 
which allows adding different symbols and timeframes to input 
with a static function. This was something, what I didn`'t see 
coming, and I haven`'t programmed anything like this before. 
So, it is challenging, but also interesting. Everything in Prioritizer 
implementation looks very weird and complicated now, even for 
me. I can`'t even split big loops into separate functions, because 
I don`'t see clear pattern. It`'s like programming in assembly 
language.&]
[s3; 26.5.2017&]
[s0; Today, I am going to rant a little bit. Very little. That amount, 
what you would tell to your co`-workers at the dinner table.&]
[s0; Living in this kind of small and isolated place while supporting 
hi`-tech culture is a disaster. You can`'t focus to essential 
and important details, while everyone has lost their curiosity 
and don`'t see the point in any voluntary team`-work. The only 
motivation is money, and even with that you can`'t get motivated 
and skilled team from this small amount of people. Resources 
are really scarce. Also, the incredibly stupid teenage drinking 
alcoholism culture doesn`'t help at all. It helps low reproduction 
statistics, but it`'s kinda evil way to improve that. So, the 
money loses some attractiveness, if you will still certainly 
get bad jobs and bad team with it. My recent experiences in team 
projects have only supported my understanding. This people is 
just keeping a screen of skilled workforce, they will never be 
capable to do development with this training. I am a skilled 
long`-term hobbyist programmer, and I have sometimes being doing 
[* all] the work in a team, while others are still taking the credit. 
Disgusting. Their moral doesn`'t prevent taking the credit from 
work of others at all. It is very important to offically upkeep 
a image of high`-skilled workforce for economic reasons, but 
in practice, this is just a dog`-training and indocrination.&]
[s0; The public schooling has absolutely nothing to do with my programming 
skills. In contrast, they were actually harming that, because 
they tried to make me do things in old way when I could do something 
more efficiently by programming. So, no thanks to public school, 
at all, or to university, in this regard. Only negative feedback 
for them. For my programming skills, I can only thank: Clickteam 
for The Games Factory, Adobe for Flash MX (now Animate), Microsoft 
for Visual Basic 6, people behind Python, and the biggest thanks 
goes to Ultimate`+`+, which made programming great again.&]
[s0; I am not saying, that money is not a good motivation, but I 
am saying, that you should not start from fast and high yielding 
plan. Being too greedy is bad. Waiting for long`-term reward 
is usually good with a good plan. With that greedy attitude you 
are only producing that marketing crap, which doesn`'t have any 
content in it. If I had wanted, I could have gone making a career 
in software development and have a decent salary in this point. 
I am a skilled programmer, I`'ve been in team leader training 
in army and I have high work morale, so I could have that job, 
but I don`'t want, at least yet. So, I could have had in this 
point a nice career, a big house bought with loan, and big`-tit 
blonde making me beautiful babies, but that was not what I wanted. 
I never wanted that. Ok, so in this point I probably lose all 
US readers :D .... but bear with me, I am living in isolated place 
with 100k`-200k residents, and I am basically writing my name 
to the gravestone if I am taking a girlfriend here. Also, the 
feminist movement, or something like that, have caused high divorce 
rate, and we have more single`-mothers now than ever. So there 
is high probability, that the woman leaves you for the most stupidest 
reason, and ruins everything. Last thing what I would want after 
making a family, was a woman blackmailing me for more money to 
keep the family together. But that`'s the reality here. In Iceland, 
they have the free`-sex culture, what you can search from google, 
but we have the opposite of that. We have some very old`-school 
religious culture here. That, were you are not allowed have TV, 
or even be friends with regular people. Even the regular people 
is rather old`-school in many of those matters.&]
[s0;%- [%FI-FI I tried long`-term relationship once. It was a huge 
failure and caused huge losses for me. The lesson was that money 
is more involved in relationship that people accepts publicly, 
even when the other person is denying the importance of money. 
In my relationship`-story, the first bad sign was that there 
was alcholism in her family tree. At the beginning it was sweet 
and rather normal. She had two personalities. Other was the innocent 
little girl and the other was underage drinking and smoking social 
daredevil. I did fit into the innocent family part well, but 
as her dark side took over her, being her felt like it was forced. 
Look, I am not a morality preacher, but that included constant 
lying and keeping two personalities. Not healthy or fun for others. 
Last part in the relationship was when she found some guy, whose 
family was rich, and who started to give her all sorts of crazy 
pills for free. I guess there was sex involved too. That was 
not a fair competition and I was dragged into that because of 
her dark side. It was way too much for me, but that guy`'s crazy 
pills made her so crazy, that she lost it totally. When I tried 
to break up, she went totally suicidal. She climbed on top of 
high places and tried suicide, and I had to forcily prevent her. 
She even went tried to freeze herself to death by going almost 
frozen lake, and I had to get her out from it. Her alcoholism 
supporting family almost did not care at all, so I was clueless 
what I had to do. ][%FI-FI/ Luckily][%FI-FI  she tried suicide in 
front of her family, so they took her into the mental hospital. 
I thought I was free from that hell, but I was wrong. That girl 
found a guy from mental hospital, who was a huge drug dealer, 
and who made his business all over country. It included stealing 
cars and travelling with them to places (which is in record after 
they got caught). I thought I was free from their idiotic network, 
but unfortunately I was wrong. The girl went even more nuts, 
and in her head she ][%FI-FI/ changed identity with me][%FI-FI  , 
and tried to say to anyone that I did force her in all sorts 
of things while we had the relationship. Doctors and other professionals 
can see past her talk, but her new friends were these incredibly 
retard drug dealer people who couldn`'t. So, she got drunk and 
high and told all crazy things about me being evil monster to 
that people. I got some hint of that, when I was out in the city 
center, and got attacked by 3 guys. They attacked me directly 
from behind, with the only intention to hurt me. They started 
by hitting me with a beer bottle to the head, and I almost lost 
eyesight from right eye. Luckily, I managed to run away with 
bleeding head. I was drunk and saw those guys for 1`-3 seconds 
in dark night and I initally reported them to be something different, 
but afterwards I am sure they were her new friends. At that point 
I started to get treated bad by my old friends too. Turned out, 
that her crazy gossipping has reached them too, and no`-one from 
my old friends had guts to warn me about those empty stories. 
This is small and boring place where stories travel fast. Unluckily, 
even at that point I was far from it being over. In our country, 
the military service is mandatory. I did not support or resist 
the idea and I was somewhat curious about it. So there I was, 
doing it all, you know, in the army. Greetings to all servicemen. 
I should have known, that I had went through traumatic experience, 
and that was not a good place for me, but unfortunately I had 
no`-one to discuss it with. Things went south really fast, when 
I was assigned to a military police team leader team with one 
of her new friends, which was some incredibly retarted and narsistic 
taxi driver. Even at that point I did not know how bad her crazy 
gossipping was. So, that guy had some narsistic personality disorder, 
just like her, and he continued that gossipping in our team. 
Unfortunately, even our ]second lieutenant got that gossip, and 
did not tell me, but took part in the crazy gossip ring. It is 
important to emphasize the point, that second lieutenant military 
policy took part into that gossip instead of solving and eliminating 
it, effectively continuing the violence, which started in that 
attack in the city centre. I was basically &]
[s0;%- ed by higher ranking officials for 6 months, without knowing 
the reason, and afterwards shockingly know that they had taken 
the side of those attackers. I changed to sivil service afterwards, 
so now I don`'t need to be in contact with those traitors of 
justice anymore. After the service I was back in the city. Here 
the weird treating of me continued, and I smelled the injustice, 
but couldn`'t quite grasp it. Basically, her crazy group had 
got larger and those tried to make me look bad and they somewhat 
succeeded in it, but it doesn`'t really matter anymore. Last 
point was, when her newest boyfriend sent text messages to me 
pretending to be her. I met him instead of her, and he repeated 
death`-threats to me and he threated to come into my apartment 
beating me to death. I wasn`'t really in danger, because you 
know, I was trained to be military police and he was skinny and 
alone, but he might have knife or gun, so I did not take risks. 
Her friends are known to have guns also, even though guns are 
highly regulated in our country. Turns out, that bad guys get 
the guns anyway. The craziest part was, that her parents had 
allowed that guy to go `"make me man`" like that. They even insulted 
my mother, when she insisted to be in contact with her parents, 
because my mother thought that there was some sense in them left. 
Finally it was over. I have enough material to make a report, 
but this is so big mess now, that I am not sure will they take 
me seriously now. There is a huge list of unlucky details for 
that story, but I think this is enough now. This might even be 
too much to tell publicly, but I don`'t think this text will 
reach people very fast. In the end, I have heightened sense of 
injustice and sense of all history falsification. I have still 
constant pain from that attack, but luckily I kept my eyesight. 
I am now greatly tramatized, but also I feel the peace with the 
world now more than ever. It is going to be fine. That sad little 
people can`'t win in the long run. Justice is like a weed, finding 
it`'s way trough thoughest cracks in the pavement.&]
[s0;%- I could go on and on, but this was off`-topic, and I have 
work to do, so let`'s focus on that, shall we?&]
[s0;%- ...&]
[s0;%- One interesting feature, what separates Overlook from MT4, 
is having fixed time`-positions, which allows to leave out close`-price 
and time slots. There was a common mistake in many mt4 expert 
advisors, which uses close price even though the decision was 
done in the open price point. Basically, all MT4 code prefers 
close`-price, even though open price would be correct in the 
point of decision. The indicator is recalculated when new time 
bar is added, where the open price is only constant value. So, 
in Overlook there is still possibility to use future data, but 
today I added checks that no wrong indicator can read those. 
It caused errors and solving those actually changed the output 
of some indicators. However, these AI agents etc. won`'t be too 
strict about those things. It is still difficult to keep indicators 
from peeking future and refreshing values correctly when time 
goes by. ZigZag, for example, is completely peeking indicator 
and it is used in the feature detector. It is a huge problem, 
because it gives peeked data. It is currently broken in that 
way, but I don`'t know how to fix it yet.&]
[s3;%- 30.5.2017&]
[s0;%- I just completed the first and simplest query`-table forecaster. 
I had to learn a lot about the decision tree theory via documentation 
and trial and error, but finally I made it. There is many problems 
because of the overfitting, but in this case the underfitting 
was even a bigger problem. Unlike in MT4, in this weekends and 
closed markets causes zero`-change bars, which caused the pruning 
function to delete all nodes which predicted something else than 
zero change. Well, I guess it`'s overfitting to zero`-change, 
but underfitting describes it better.&]
[s0;%- The proper testing is still undone. It probably needs to be 
done in larger scale, with all other classes in the pipeline, 
so I postpone that temporarily.&]
[s0;%- What next? I still have time today. Let`'s see after lunch 
break.&]
[s3;%- 31.5.2017&]
[s0;%- Hello. It starts to look clearer and clearer that neural networks 
are unnecessary for Overlook. Slower timeframes are easier to 
forecast and faster timeframes goes along with the slower usually, 
so you can try to forecast faster changes by using slower forecast 
as input. Events are also highly repeating and networked. I will 
re`-introduce neural networks to this by stricly comparing them 
to decision trees, but current neural network custom core classes 
are wrong. They are not being used and they will be removed. 
Mona neural network is probably gone for good from the Overlook, 
and recurrent networks can`'t do decision tree`'s job, but fully`-connected 
deep neural networks will be used if they perform better than 
decision trees. The nature of the markets is more web`-like than 
reoccuring patterns of single stocks, indices or currencypairs. 
This is simply an improvement in the plan and makes the result 
better, in the exchange to small amount of lost work by me. I 
have no personal attachments to any part of the plan.&]
[s0;%- I feel that doing this project as the public open source project 
helps me to notice obvious things, that other programmers would 
see if they looked my code, even though I can see from statistics 
that nobody probably haven`'t read this yet. Only the notion 
of potential observers seems to make my subconscious attitude 
little different, like what observer does to the probability 
distribution in those weird quantum state phenomenons, but I 
really don`'t know and connecting those two separate ideas is 
silly.&]
[s0;%- I debugged the huge query`-table forecaster. It starts in 
`~5 seconds in my 4GHz machine and seems to give correct results. 
Making the decision tree from this many predictors is slow, but 
it`'s nothing compared to neural network training.&]
[s3;%- 1.6.2017&]
[s0;%- It`'s 1.6, first day of summer, and there is hailstorm outside. 
It looks like it`'s snowing, but in fast`-forward, because hails 
are heavier and comes down faster. The temperature is `+5 Celsius. 
Worst spring in years, as far as I remember.&]
[s0;%- I am re`-planning forecaster and agent classes again. Now, 
when neural networks will compete first with the decision tree, 
there won`'t be much complexity in the pipeline. One agent is 
enough in the beginning, instead of many weird neural network 
efforts. I am using more generic approach now. All classes must 
try to use their slower timeframe instance as input, and they 
must try to work in the fastest timeframe, in which they are 
the proxy of slower tf or they use their own calculations if 
it`'s better. It seems complicated now, but the result should 
be simple. I did something similar with the SubTf and MetaTf 
indicators, which tracked the `"progress`" of expected volatily 
in comparison to longer period. Those indicators are useless 
now, but they were the precursor of this model. I should make 
them work again for historical reasons only.&]
[s0;%- Looks like I get better performance comparison to my master`'s 
thesis now. The description is much simpler now: everything was 
designed with the minimum system (query`-table and decision trees) 
and neural network systems are being compared to the decision 
tree system in 8 different predictor sets. I knew I would get 
some kind of performance comparison, but this is just much more 
smoother and better than I expected. Only the math is an obstacle 
to the completion of my master`'s degree in computer science 
(or whatever it was called). There is just this evil elitist 
math teacher, which is blocking the progress. I have been in 
very different schools in different `"social classes`". I got 
very high grades in the large `"people`'s school`" `-like place. 
There I was [/ the best] in math. Then we moved and I went to [/ the 
elitist school], where my friends behaved like little children 
and they wanted to be doctors and pilots and yes, they became 
those. There they didn`'t even bother to teach. They just kept 
the limit too high to motivate them to do something impossible. 
That was so ugly that I [/ wanted] to change to more liberal school, 
where people didn`'t even bother to try to do the math. Now in 
university, I have only those [/ elitist] and entitlement teachers 
left, who keeps the price of the title high. Basically they exploit 
the fact that there is no real comptetition to make good learning 
material in good price, and they can just throw the bone to the 
most difficult maze and say `"[/ go fetch it]`", instead of providing 
comprehensive material with included solutions, so that they 
could be analyzed and the whole structure of things could be 
observed and solving problems could be optimized. It`'s like 
there is a artifical limit to prevent people learning more in 
the sake of their elitist social entitlement program. What I 
have done with my computer science attitude, is that I searched 
the automation to all math problems, including statistics and 
differential equations, which made me also to understand the 
math behind it all. However, [/ the evil teacher] actually did 
put to exam [_ only problems without automated solution] (all exception 
cases)[* ,] and he continues to do it, essentially stripping off 
all my motivation. So basically he does huge effort to prevent 
this method to work and he tries to make old`-school math heads 
look better than they deserve. So, I am stuck with that old`-school 
devil who actually actively targets my method to prevent it to 
work. He is literally so bad, that his statistical exercises 
includes proving, that `"[/ punishing children with violence improves 
their learning]`". It`'s fucking unbelieveable to have that kind 
of teacher in an university and this doesn`'t even come from 
some [/ `"leftist safe`-space student`"]. It`'s really medieval.&]
[s3;%- 3.6.2017&]
[s0;%- Hi, again.&]
[s0;%- This is the day when I thought that this program would have 
been ready. I hope that two week extension is enough, because 
I have huge todo list of school work for this summer. I couldn`'t 
get any summer job because of that, which makes the budget tight, 
but bearable.&]
[s0;%- There have been some change of plans already today. I started 
normally by planning the implementation of the `'[/ Custom]`' forecaster 
class, which was next thing in the TODO list. Then, I thought 
that some more abstract Model class would be better and it could 
be reused by inheriting in other forecaster classes too. That 
required checking of all requirements for upcoming forecasters, 
and that required the detailed description of every class. After 
describing classes the Occam`'s razor principle did hit me once 
again. One class might be better than all of those custom classes 
[/ (one class to rule them all... is the Lord of the Ring only 
about Occam`'s razor principle after all?)]. So, instead of inheritable 
Model class, I decided to do only one class. That is a good change 
of plan, but all change of plans tends to cause much stress for 
me because of some [/ biological branch predictor in the brain] 
or whatever. I can probably plan the class today only, and that`'s 
all.&]
[s0;%- ...&]
[s0;%- I have planned again big portion of the app. This follows 
the Occam`'s razor princple. This is smaller, scales better and 
the previous version is a subset of this. As usual, some work 
seems to have been useless. In previous plan, I thought that 
I could measure the performance of pipelines and then construct 
better pipelines with that information. My mistake was, that 
I thought that it could be performed better with decision trees 
and NNs than with genetic optimizer. I was wrong. Clearly some 
result table with genetic optimization is better. You know, sorting 
results by performance, combining best ones, adding random values... 
With that, only the traditional use case is problematic with 
candlesticks and an indicator of single sym/tf combination. &]
[s0;%- ...&]
[s0;%- I need to make big changes to the whole project structure. 
I broke some code and I will fix it in next days. I did the detailed 
list of changes but I don`'t care enough to translate it to English 
and add here. The revised plan includes everything that current 
version has and solves all remaining issues with the pipeline 
optimizer. Now I can`'t say anymore that I had done useless work 
at all, because Prioritizer clearly did solve many other problems 
and it will be re`-used as parts. Implementing the new System 
class will cause a lot of headache, however, and I am not happy 
about it.&]
[s0;%- I think Overlook will be ready in 2 weeks.&]
[s3;%- 4.6.2017&]
[s0;%- I can easily say that the [C SystemOptimizer.cpp] and it`'s 
past versions is the most difficult thing I have ever programmed. 
It`'s one of those things where you know parts, but not what 
the whole combined thing should be. Basically it genetically 
optimizes tree`-structured pipelines (with differential evolution 
algorithm) and creates job`-queues where all duplicate objects 
are avoided for performance reasons. All leaf objects can be 
easily re`-used and the root`-object is never the same, and the 
area in between is like gradient of those. Object dependencies 
and their priorities must also be known, so that less important 
objects can be released instead of regularly used objects. Now 
I am trying to re`-use existing code from Prioritizer, but the 
task is difficult. You can usually do a lot of routine programming 
or limited amount of problem`-solving`-like programming in a 
day. The [C SystemOptimizer.cpp] is a huge pile of problems, which 
demands many days, while in the paper it looks like there is 
almost no progress at all. The plan is detailed enough, but it 
also must be simplified at the same time when parts are connected 
and unnecessary complexity is recognized, which makes this a 
constant battle with heuristic guide. That kind of working is 
hard to do in a team and zero`-budget... Luckily, this, the most 
frustrating project I`'ve ever worked with, is probably finished 
in about two weeks.&]
[s3;%- 5.6.2017&]
[s0;%- I am still working on [C SystemOptimizer.cpp] and it still is 
ridiculously difficult. I had to write all certain things as 
comments in that file. That showed the point of uncertainty very 
well and it was like modern highway stopped suddenly to the wall 
of rainforest jungle. There is some code from old Prioritizer 
class, which implements all the same necessary stuff but for 
different system, which is like a lighthouse glowing in the dark, 
but it doesn`'t help to get trough.&]
[s0;%- ...&]
[s0;%- What... I made huge mistake again... I thought that a type 
of input`-indicator could be in one column, but I thought it 
and it is bad idea. The mutation happens by combining many values 
and it doesn`'t work for classifiers. I knew it was wrong from 
past coding, but I didn`'t connect it to this. Mutating the enabled/disabled 
bit works, however. That was how it worked in the Prioritizer, 
but somehow I missed the point once again. So, now I must re`-check 
all column values again, that there is not a single classifier 
as a value. Only weaks classifiers are allowed, like which average 
method is used in moving average...&]
[s0;%- Hmm.... seems like I am so stuck with this that I didn`'t 
even write it in a wrong way yet.&]
[s0;%- So, now there must be room for enabled bits for all traditional 
sources, and their arguments, to make the mutations work. That 
shrinks the tree`-structure of template classes to a stub, but 
that doesn`'t really matter. I didn`'t expect the multi`-level 
structure to bring much more value anyway.&]
[s3;%- 6.6.2017&]
[s0;%- I was so pissed yesterday about being stuck, that I didn`'t 
commit anything. The way I commit everyday, is not good for community 
or company projects, of course, but this is not one. I have been 
in team projects where I was the only one to make commits and 
the work anyway, so I got less interested about if the project 
will compile and link... &]
[s0;%- ...&]
[s0;%- Exciting findings... I simplified some old code and that gave 
me some interesting questions and answers...&]
[s0;%- So, the decision tree allows only one target value. At first, 
you think that it should give the long/short signal. `"[/ But but 
but I want more than one investment instrument...]`". Ok, fine, 
either you discard the decision tree or you start to be creative. 
Why don`'t you just use artifical neural networks, which gives 
you multiple outputs, which you can interpret as many long/shorts 
signals and give reward accordingly? Well, remember how I told 
how there is this tree`-structured pipeline, which has combiner 
at the root and the disabled/enabled bit is for leaf nodes to 
allow sane mutations in genetic optimizer? Turns out, that it 
might not be that good idea to put enabled/disabled bit row to 
the direction of root, like it is in the direction of leafs... 
That would be something that would happen if you would put artifical 
neural network in the root combiner without working decision 
tree model to replace it.&]
[s0;%- There is a good reason for not using that enabled/disabled 
bit row for all market symbols. If you look what the correlation 
oscillator indicator draws, you`'ll see, that there is usually 
very strong correlation for or against other symbols. You`'ll 
see, that sometimes some symbol suddenly flips it`'s side (`+1 
to `-1 or `-1 to `+1), but most of the time symbols are almost 
`-1 or `+1 by their correlation value (with medium to small sample 
size). There is actually a good classifier for root target which 
has a reasonable description. That would be [/ strongly correlating 
groups with descending order]; the largest strongly correlating 
group would have the identification number 0. Weaker groups would 
have their id starting from 1. After that there would be sub`-groups 
and maybe even some intersecting areas. I think that is what 
the Overlook will have as the target value of the root combiner. 
However, I might find some flaws in this model.&]
[s3;%- 7.6.2017&]
[s0;%- Good morning. I woke early enough to watch sunrise from clear 
blue sky at 4:30 am. I am lucky to have very nice view for that 
from my desktop where I program. It`'s going to be warm (20 Celcius) 
 day. In these days trees will get their full leaf and the summer 
will truly begin. Best time to be in Oulu, Finland. It`'s already 
entirely bright night and it continues to be so for couple of 
months while having the peak brightness after two weeks from 
now.&]
[s0;%- I noticed, that I should create virtual nodes for baskets, 
just like I have already done for single currencies now. In that 
way there is no need to calculate values for items in basket 
separately. In those baskets I would put highly positively correlating 
symbols, which is opposite of hedging, where you put negatively 
correlating symbols in the same basket to cancel changes in total 
value.&]
[s0;%- ...&]
[s0;%- A lot of progress was made today with SystemOptimizer.cpp, 
but it`'s still not completely in the previous working state. 
It`'s worth noticing how much complexity have been reduced today 
without limiting features.&]
[s3;%- 8.6.2017&]
[s0;%- To the practical matters... The classic viewing mode works 
again (candlesticks `+ indicators). I have had this at this point 
many times before, but I had to change something structural, 
so something would break and I would have to fix it.&]
[s0;%- About the basket symbols what I mentioned yesterday... changing 
between those at different times should be decided by the optimizer, 
not by some template object. That would take the planned combiner 
object away, and that is probably how I end up doing. It will 
decrease a great deal of complexity, because there is no need 
for combiner to listen all the most important baskets and switch 
between them. Optimizer will have the primary time`-range, which 
will be trimmed to include the most efficient time`-range, and 
secondary time`-slots will fill the remaining time, and they 
will be trimmed again until limit is reached. This kind of simplifying 
is very powerful and this is how you should do it: immediately 
after you have recognized the opportunity and before the old 
and more complex design has been implemented further. Unfortunately, 
sometimes you have contracts to make something in a bad and old 
design. There is, of course, a small probability, that some opportunities 
turns about to be useless learning experiences, meaning that 
you were wrong ;)&]
[s0;%- ...&]
[s0;%- I took a walk (there`'s freakin`' hot outside) and got an 
idea, that maybe the optimizer should seek to the timeslot `& 
basket instead of only timeslot. Also some basic environment 
states could be seeked. The optimizer becomes some multi`-headed 
monster, which tries to fill the whole surface with some sharpest 
tops. Every head has a differential solver and a decision tree 
pruner and they have a strict priority order. That seems interesting, 
at least for me.&]
[s3;%- 9.6.2017&]
[s0;%- Ok, so the simple and efficient solution is to add timeslot 
and basket optimization to the differential evolution solver. 
No need to make it more complicated.&]
[s0;%- The main optimization loop is slowly but steadily starting... 
Next: basket bardata from long argument vector and templates. 
The alpha version will be ready soon.... I can`'t wait to get 
this project to slower development phase.&]
[s3;%- 10.6.2017&]
[s0;%- Happy name day me.&]
[s0;%- One can connect dots, how the Overlook is using MT4 and market 
symbols and genetic optimization to improve results, but one 
important feature of the Overlook is to make connecting those 
dots difficult. I mean, you can`'t give everything to everyone 
on the golden serving dish, right? However, the life doesn`'t 
need to be bloody zero`-sum game neither. Some golden rules must 
be applied.&]
[s0;%- I have witnessed the most heart breaking discrimination of 
poor people many times, which have had completely elitist zero`-sum 
game nature. The most heart breaking is that, when someone haven`'t 
had a chance yet, and the weaker position have been the fault 
of their parents. Of course, we have genes, but we also have 
brains, and it`'s weak minded to weight bad genes or bad inheritance 
instead of strong. My sister is one of those. Girls are very 
evil in that point. They demand irrational sweetness of life 
more than men, and discriminate other girls for the stupidest 
elitist reason. Men at least can come together with the sports 
by nature. It is also sad to see accumulating effects of one 
single unjust treatment and the evil ignorance of those greedy 
sweet`-tooths. That makes you want to listen to `"The Prodigy 
`- Smack My Bitch Up`".&]
[s0;%- Ultimately, there is the world of all uncesessities, which 
allows using human resources by luring people unknowingly into 
life`-long traps with marketing and claims for moar success, 
moar `$`$`$ and moar something, which is generally accepted for 
some GDP increase or whatever. Start looking that more in`-depth 
and someone will say `"[/ The big bubble of human resources filling 
the result of evolution of the society is none of your business, 
stay away!]`", `"[/ No taking of pictures!]`" or `"[/ Only the simulation 
of official timeline in very low resolution for recreational 
purposes is allowed!]`". However, the brain`-dead culture of 
recreationial ceremonies and related stories is only valid as 
long as those stories are not analyzed with personal computers 
using scientific big data methods, artifical neural networks 
and logical reasoning. Even then they would try to sell some 
of it as true by some so`-called trusted scheme and religious 
fake`-science. Only the immature system needs the exploration 
of doing something which is not needed, but it is hard to tell, 
which parts of the system actually are mature. Some parts have 
known mature versions, but some narcissistic predatory adult 
cry`-babies are blocking their distribution, because it would 
prevent them exploiting existing immature versions. The corruption 
is about someone trying to keep your life limited to the noisy 
M1 timeframe and putting random expensive nonsense into it. It 
is about making you sad but smiling under eye. It is about making 
someone else too rich in your expense without you knowing it. 
It is about not having opportunities to travel and meet new people 
by making you to scare your own shadow.&]
[s3;%- 11.6.2017&]
[s0;%- Today, I want to talk about porn. I have been working on the 
DataBridge correlation code, but it doesn`'t have anything to 
mention about.&]
[s0;%- Oh porn, the magical thing which tickles our primitive instincts...&]
[s0;%- I was one of those who found the secret porn stash with my 
4 friends. That was not my father`'s but my friend`'s father`'s. 
I was around 10 years old. We didn`'t think it as bad then, and 
I haven`'t changed my mind ever after. I understand the sensitivity 
of the subject, however.&]
[s0;%- Few decades ago, everything was more innocent. Pinup girls 
showed only a little bit of leg and had their mouths shaped in 
a weird kissing way. Then the actual penetration came along. 
It was tied to a story, but eventually the story had to go. Then 
came renting of videos and Internet. The XXX culture started 
to grow even more as business.&]
[s0;%- All of those of us who have seen porn knows, that there is 
a lot of dick and pussy in the screen. You can`'t somehow unsee 
men`'s parts even if you are heterosexual, like me. It is part 
of the whole product. You start to understand the friendship 
between straights and gays. There is no big difference between 
what you see with girl`-boy anal and what gays see with boy`-boy 
anal. You don`'t have the feeling, but you can understand.&]
[s0;%- This topic deserves a scientific paper, but unfortunately 
I have time to write only about my experiences. It is extremely 
important to understand, that the virtual adult entertainment 
industry has nothing to do with non`-virtual counterparts. To 
my understanding, only a small fraction of audience would mix 
those two. Healthy people will have strong emotional response 
to physical contact, which is not comparable to virtual experience.&]
[s0;%- Mixing the pleasant virtual experience to real life can be 
challenging. Many of us are in a relationship, where the partner 
have had a traditional and religious image of reproduction. Someone 
can sometimes find out, that the partner has insanely strong 
opposing reaction to porn. The topic may scar both the porn loving 
and the porn hating party. Wrong behavior is to prevent the other 
loving porn or trying the other to love porn. Personally, I was 
one of those unlucky men, who had that kind of partner, which 
tried to both prevent me loving porn and who accused me trying 
to make her love porn, when I obviously rather broke up with 
her for being selfish and narcissist. She was a actual nutjob 
in other ways too, though. She went to extreme opposition and 
started to ruin my public image with insane lies; after I had 
saved her life around 5 times from violent suicide and was crying 
from emotional stress, she was still in denial of me being the 
good guy so much, that she started to gossip that I was weird 
crying gay`-hater. My biggest mistake was, that I didn`'t file 
a official report, but I was young and clueless and adults around 
me were stupid. Shit happens.&]
[s0;%- Anyway, for some of us the porn is a healer, which keeps us 
sane in the hateful world, and for some others, it is from the 
devil which eats good men. Pick your side.&]
[s3;%- 12.6.2017&]
[s0;%- Focusing on the project again. Basket symbols are now working 
and the next step is to make the optimization loop running. After 
that is the implementation of Template class, all the detailed 
debugging of optimization and real`-time code. Finally there 
is only cleaning of code, commenting and documentation. This 
took longer than expected, but this should be over in a couple 
of weeks.&]
[s0;%- ...&]
[s0;%- The main optimization loop runs now. It is unstable and template 
doesn`'t process for real, but it runs for a long time until 
some small bug occurs with the traditional indicator.&]
[s3;%- 14.6.2017&]
[s0;%- Today, I had to take a big step backward. There were some 
undesired setbacks with the target value to genetic optimizer 
and tweet from `@karpathy yesterday gave insight to a new method. 
Previously, I have translated the `@karpathy`'s ConvNetJS library 
from JavaScript to C`+`+ and I understand how powerful neural 
networks are, but I always thought that the differential evolution 
solver would be better in this problem. I think I made a mistake 
in that. The link was to [^https`:`/`/blog`.openai`.com`/deep`-reinforcement`-learning`-from`-human`-preferences`/^ L
earning from Human Preferences] and it has a great footnote comparing 
human input and user defined reward function. Trading is also 
complex problem like that. Also, user input to trading is important 
for ethical reasons, me thinks. 100% automated conqueror sounds 
baaaaaad... and technical leverage for user`'s preferences sounds 
like a shoe that fits well.&]
[s0;%- What I understood from that scientific paper, was that it 
is almost like a DQN agent where the program gives a set of visualized 
decisions and users decides which is better. `"All weight is 
put on the better`", which is something I don`'t understand in 
practise. It might be, that the better set is being used in training 
only and worse is discarded, or it might be that the better might 
be trained with `+1 reward and the worse with `-1 loss. The difference 
to DQN is that there is no begin and end states with reward but 
right and wrong set of states.&]
[s0;%- I guess I must go back to basics and do an example with air 
hockey, which is something what I planned to do with mona, but 
this is fine too. I did some useless work, but I also did some 
awesome features what I wouldn`'t otherwise had done, like highly 
correlating basket symbols. I didn`'t trim any features and this 
is simplier, so it can`'t be bad neither.&]
[s0;%- Replacing that differential evolution algorithm with some 
DQN`-like NN causes some new problems. Evolution algorithm works 
fine with huge list of items in the set, but NN slows down fast 
with increasing items. Also, getting multiple output values from 
DQN`-like agents is problematic. I got an idea from Mona NN that 
you could change location and that would be remembered while 
reading sensors, so with this DQN`-like NN it could also work. 
Instead of putting all available sensors to the NN, you could 
change reading position, and then proceed to different actions, 
until wait action is selected. That`'s something worth testing. 
I guess both methods could be compared with that air hockey, 
because it still works with that single action per time`-step 
method.&]
[s0;%- Hmm... it actually has even simpler version, which it sort 
of inherits. You could put those sequences to querytable with 
those weights, and run it from that, instead of training NN. 
Actually, you could skip the user rating which sequence is better 
by simple function.&]
[s0;%- I am trying to follow that paper and start with existing DQN`-agent, 
but I will adjust that to larger amount of inputs by adding sub`-timestep 
`"movement`" and few writable memory`-sensors. Then it is going 
to train the better sequence, which is selected by some simple 
function, and which contains many time`-steps. It is a make`-it`-or`-break`-it 
moment for me at this summer, because I don`'t have much time. 
If it doesn`'t work, then I need to read more some scientific 
papers and try again later. I have only good experiences from 
DQN`-agent, however.&]
[s3;%- 15.6.2017&]
[s0;%- That sequential comparison for DQN`-agent was the missing 
key, what blocked me from using DQN in overlook. I am thankful 
for that paper. I need to remove some existing code, but not 
too much. At least the DE solver will go.&]
[s0;%- The other approach seems to fit unexpectedly well now. It 
is a iterator going trough the time`-range and showing all information 
in a heatmap, and then NN get trained by more correct sequence 
from two sequences of actions. It requires a lot less complexity 
from the system, but it still requires a huge work`-queue to 
be processed until even one single time`-step can be taken. It 
must process all data and technical indicators before starting 
iteration.&]
[s0;%- One interesting new approach would be to sweep the whole data 
range in one time step in fixed order and use next time`-step 
result as the comparison value, and then train the better sequence. 
In the context of exhausting amount of inputs, that might be 
worth testing. Some read/write sensors could be used as memory 
during the sweep.&]
[s0;%- Hmm... seems like this is a possible many`-core application. 
I might have misunderstood some details in that paper, because 
the lack of source code, but currently I understand it as an 
extended DQN`-agent with training on better sequence of two sequences 
and with fixed zero reward. With too many inputs for sensors, 
one could try to sweep all inputs with DQN`-agent having small 
`"register`-memory`" in sensors and sweep it syncronizedly by 
many of those small DQN agents in same spot or different spots. 
They would all write to outputs until time is out for current 
time`-step. Two sequences would be measured and better one would 
be used in training. I don`'t know does it work or is it useful, 
but it would fit well to GPGPU kernels. It would be something 
like [* many`-inputs to many`-outputs with DQN`-agent swarm]. It 
would be very interesting to test that... It would be almost 
like that example in the paper, where the sequence consist of 
multiple time`-steps, but in this steps would be inside one time`-step 
and only one time`-step would be compared, because of the length 
of the sequence. Basically it would shrink multi`-time`-step 
sequence to one time`-step sequence, and use it to control multiple 
inputs and outputs internally. Yeaaaa, I think I`'ll do it immediately. 
I`'ll fall back to that paper version when everything fails...&]
[s3;%- 16.6.2017&]
[s0;%- I`'ve been thinking about that DQN`-agent swarm, and one interesting 
use case to test would be to create huge amount of small agent`-compatible 
objects (aka. physical swarm) and then add 0`-10% of DQN`-swarm`-agents 
for them. Then you would loop those swarm`-agents through all 
objects multiple times in one time`-step and then you would compare 
two outcomes after one`-step, and you would prefer the sequence, 
which is better e.g. where swarm objects has less collisions. 
You might even be able to move huge swarms through some obstacle 
courses, like training some flying bee swarm. If that would work 
in pracise, it would be an ideal many`-core application.&]
[s0;%- Today, I hope I can get the iterator working for that DQN`-agent 
thing and start implementation of the agent too.&]
[s3;%- 17.6.2017&]
[s0;%- It was hard to see the obvious solution somehow. The most 
safest and fastest design is to use one sequence`-DQN`-agent 
per sym/tf and give them few steps inside time`-step to allow 
competition. That can be implemented in Cuda or OpenCL too. Luckily, 
I didn`'t implement any other design yet. This design is almost 
proven with the ConvNetC`+`+ WaterWorld demo and with that scientific 
paper. Only difference is to make agents interact with each other 
for common reward. It should work as expected as the behaviour 
is similar to the WaterWorld demo.&]
[s0;%- I am very happy about this fix. Now the design matches to 
my previous expectations about combining all symbol instances. 
I tried many different suggestions, but this is the best so far. 
Rest of the details will show themself while I implement this.&]
[s0;%- The Overlook is now rapidly approaching the alpha version.&]
[s3;%- 19.6.2017&]
[s0;%- The main trainer loop runs, but without SimBroker implementation. 
I`'m worried that I forgot some sensors and I`'m worried that 
the agent has too many sensors now. Other parts of the loop seems 
to be okay; I can`'t find bugs with random checks.&]
[s0;%- Upcoming: SimBroker implementation and GUI for training, which 
allows inspection and debugging of the training. I`'ve been busy 
and super lazy in past days, but I hope I get better. The good 
objective is to get real`-time trading working before weekend. 
That would also mean that the first alpha version would be ready 
at the midsummer party and I would have two good reasons to take 
beer. The long hangover wouldn`'t be a problem, because following 
development would be on`-demand after test results. Maybe I`'ll 
work harder when I think that as a reward...&]
[s3;%- 20.6.2017&]
[s0;%- This journal tends to go off`-topic too easily... but I think 
this free`-speech smell in this kind of project makes a good 
statement. I only draw a line on political commentary.&]
[s0;%- I`'ve been writing the SimBroker`::Cycle() function and it 
is really difficult. It`'s too overwhelming to write it at once. 
I have written all parts of that previously, but this time all 
parts are in one tight function. I have only this task for today 
and it might still be too much.&]
[s0;%- ...&]
[s0;%- So, it is sort of difficult to progress with the implementation 
now. I couldn`'t plan this better because of unknown release 
target and now when it is known, it is hard to get good picture 
of everything. I think I should literally draw picture of this.&]
[s0;%- ...&]
[s0;%- I remembered what the reward is despite the performance of 
the trading automation; you get constant excitement about being 
involved in the markets with real money. It is like morning coffee. 
That is my [/ real] objective, even if the performance would be 
rather bad. I am also confident that I can get something worth 
processing with the sequential`-DQN`-agent, but it might take 
a while to tune it correctly. This is my 10`-20 year plan, so 
I`'m not in a hurry. I am sharing this program to help others 
to get that kind of excitement, but please don`'t quit your day 
job.&]
[s3;%- 22.6.2017&]
[s0;%- Good day. Seems like I get stuck with this before my morning 
coffee ends (which is medium roast 0.7 litres with milk and without 
sugar by the way, and some would say that it is way too much). 
Also, I have work to do relating to next year in university, 
so I am doing this only at the morning for now on.&]
[s0;%- ...&]
[s0;%- I think the education about AI in investing is totally non`-existent. 
While I highly appreciate the MetaTrader community about their 
efforts, I think the quality of those expert advisors is mostly 
total rubbish. This is what I think about them:&]
[s0;i150;O0;%- They don`'t recognize slower timeframes being usually 
easier to predict and trading faster is exception to the slower 
target.&]
[s0;i150;O0;%- Some instruments follow other: just try some simple 
cross`-symbol predictor and test to hide each of them. It shows 
that hiding the leader increases the error rate.&]
[s0;i150;O0;%- They don`'t try to calculate virtual currency instrument 
from pairs, which could be good source of cross`-symbol prediction.&]
[s0;i150;O0;%- They don`'t have money management usually, and if 
they do have, they don`'t have the safe range optimizer. This 
is the important factor which could enable exponential growth 
in theory (, but probably not in practice).&]
[s0;%- The Overlook considers all of those things while being free 
and open source. You`'re welcome.&]
[s3;%- 23.6.2017&]
[s0;%- Implementing SimBroker`::Cycle turns out to be harder and harder 
every day. It should be done with correct exposure calculations. 
I have correct (enough) exposure calculations, which I modeled 
from exposure`-values, what MT4 gave. However, those work in 
forward propagation way and now I need backward propagation. 
With this, I must start from the value what forward propagation 
returns. Why? Well, when you want to update your orders and want 
to have some target total margin, then you want to get real volumes 
from relative volumes of your requested orders. If you have already 
opened orders, you want to take those into account with their 
existing margins. To make this even more complicated, this is 
called in the most busiest training loop in every time`-tick, 
so it should be high`-performance`-computing`-friendly.&]
[s0;%- Seems like Brokerage class has had too little attention: SimBroker 
and MetaTrader classes has many duplicate features. Also, it 
should cache variables better, because the bridge is sloooooooow.&]
[s3;%- 25.6.2017&]
[s0;%- The Brokerage class is still a mess. Nothing more to say...&]
[s0;%- ...&]
[s0;%- Hmm... it seems like it is difficult to separate pairs from 
virtual currency nodes while calculating volumes from total base 
currency exposure. Also, it is tempting to treat currencies as 
a basket of pairs. However, preferring that would require proving 
the assumption, that virtual currency nodes maintain integrity 
better than other kind of baskets, like basket of highly correlating 
pairs. I actually have very little knowledge of these sorts of 
things, because I can`'t find relevant scientific papers, and 
they might not even exists. This is mostly my best guess only. 
I am lacking all proper theory. However, the objective is to 
get something worth running at background (and this is not rocket 
science), and current reasonable solutions and minimum requirements 
would suggest that currency basket (of pairs) would have higher 
priority, and other sort of baskets should be added later while 
comparing their performance to currency baskets. This description 
is not as clear as it is in the code.&]
[s0;%- In the code, it seems to be reasonable to give relative weights 
for currencies, indices and stock CFDs, and the program would 
solve weights for pairs from currency weights. That would require 
minimum amount of programming while being more intuitive in real`-life. 
The difference would be to not allow giving signals for single 
currency pairs, which is something that manual traders wouldn`'t 
even consider.&]
[s0;%- Basically, the Occam`'s razor principle would suggest that 
manual traders trades only the most direct currency pair, and 
automatic traders trades weighted pairs from currency weights, 
because the correct backward exposure calculation is easier in 
that way (to put it mildly). That doesn`'t even have anything 
to do with the integrity of virtual currency node (derived from 
pairs), but which is also reasonable assumption and which would 
suggest that basket of pairs is more stable and easier to predict. 
Also, single pairs tends to have more spikes, which is also something 
to avoid with automated solution.&]
[s0;%- In the end, benefits for ditching single pair signals and 
custom baskets until further interest outweights my curiosity 
to research this more.&]
[s0;%- To simplify to the maximum: the sequence`-DQN`-agent gives 
direct signal to the asset, and then that drives volumes of instruments 
indirectly using that backward exposure calculation.&]
[s0;%- To be continued tomorrow at the same bat channel `[[^https`:`/`/www`.youtube`.com`/watch`?v`=alQ0zUjLLmg^ 1
], [^https`:`/`/www`.youtube`.com`/watch`?v`=mlsXRq`-Y6zE^ 2], 
[^https`:`/`/www`.youtube`.com`/watch`?v`=iwbsx6LvnfY^ 3]`].&]
[s3;%- 26.6.2017&]
[s0;%- Newly implemented exposure calculations must be tested and 
a proper gui widget for that is needed. That will allow manual 
testing of the SimBroker class. Maybe tomorrow...&]
[s3;%- 27.6.2017&]
[s0;%- Somehow I mixed together profit calculations and exposure, 
but they have nothing in common in code. That was a small mistake, 
however, and I only removed additional variables for open/close 
price of proxy symbols... The exposure calculation doesn`'t give 
equal values to MT4, but it is close enough for me. Also, as 
long as the agent is trained for the same algorithm, it doesn`'t 
affect to the outcome.&]
[s0;%- ...&]
[s0;%- I took a walk outside, where happens to be internationally 
nice summer weather, and I pondered what is the problem, because 
this is not progressing steadily. I would like to communicate 
this in very scientific way, but that is not going to happen, 
so I am just trying something...&]
[s0;%- ...so, previously I did an experiement, where I generated 
changing value dataset for nodes. Then I `"connected`" those 
nodes and generated pair instruments. Then I tried to regenerate 
the node value from pairs. The result was closer to original, 
when there was many nodes, and worse, when there was only a few 
nodes. From this I jump far to the real life, where those nodes 
are currencies and connected pairs are available pair instruments. 
Now, one must ask, that once in isolated system, with multiple 
nodes, is it equal to put weight on all nodes (assets) via [* the 
single immediate pair] or via [* all pairs] (all cross`-sections 
between nodes)? If not, how it is different and why?&]
[s0;%- ...&]
[s0;%- Ok, so the answer is very experiemental. I have two graphs 
on my monitor. The other is EURUSD and the other is virtual EUR 
graph with mostly USD centric instrument`-set. So, most people 
would expect these to be equal, and they are very similar, but 
not equal. That is just obvious. First part of the answer is 
obvious no, it is not equal, but why? Currencies have a large 
real`-world asset base, but the trading happens in the most outer 
layer of the real`-world counterpart, sort of. The outer layer 
balances itself with other parts of the layer and with the base 
value, but it is not constant. There are `"internal pairs`", 
sort of, what are not shown. Actually, by exposing those connections 
you might have even higher success rate in predictions... Visually, 
it looks like EURUSD follows the virtual node sometimes many 
days. Oops, I might have said too much ;)&]
[s0;%- Technically, I am not sure. The exposure would show same value 
of assets, but they would be committed via different instruments, 
which in practice wouldn`'t be linked to same constant asset.&]
[s0;%- ...&]
[s0;%- Actually, this gave an idea about `"next generation Overlook`", 
which would have `"multi`-timeframe currency`-agents`" instead 
of `"trading agents`". Pair data would be generated with simple 
function and difference to real data or MSE would be returned 
for the trainer. Then next values would be predicted and those 
would be traded in very simple ways.... but why wait to next 
generation?&]
[s0;%- So, actually, it could be possible to have that previously 
mentioned `"multi`-timeframe currency`-agent`", which would generate 
multi`-timeframe predictions for pairs, and then separate trader 
agent would be trained for that pair. The sweet`-spot for correct 
predictions might actually be that virtual currency node.&]
[s3;%- 28.6.2017&]
[s0;%- I would much rather do this in a team, but I can`'t find anyone 
who is voluntary and skilled. I like to play co`-op multiplayer 
games like [/ Sven Coop] , [/ Alien Swarm: Reactive Drop ]and even[/  
Serious Sam], but most can`'t see the `"co`-op game`" in this...&]
[s0;%- After yesterday`'s [/ new] information, I thought about one 
simpler design, which might be better starting point. This is 
not entirely new. You could put autoencoder forecaster to currency, 
all pairs, and to the web, and use simple trading mechanisms. 
Usually simpler structures are better starting point and they 
can be extended with more advanced solutions. It`'s just difficult 
to see what is simple here. Also, I still have the problem of 
separating training and testing areas, so that is easier with 
less dynamic and iterating design.&]
[s0;%- ...&]
[s0;%- I first noticed the `"proxy`" effect with non`-base pairs, 
when I calculated profits separately from MT4 and they didn`'t 
match. Then I added the proxy`-change and it matched. I guess 
you could hedge that change, but then you must pay proxy spread 
twice. I think that is confusing, because some brokers might 
hedge that automatically and some not, and they don`'t say that. 
Currently I am assuming that it must be manually hedged if you 
don`'t want the proxy effect. That`'s not bad, but it is confusing 
to notice it from calculations and not from some friendly description.&]
[s0;%- So, trading the whole web of pairs is difficult, but not impossible. 
First you get relative lots for crosses, then you check how much 
they require proxies, then you balance proxies to relative lots 
(possibly hedging), and then you get the relative margin, and 
then you check how much you want the total margin to be, and 
then you multiply those relative lots to be real lots. It`'s 
nice to have high leverage for that situation, but not for the 
casino`-like `"all`-in for single pair or stock`"...&]
[s0;%- ...&]
[s0;%- I searched for my old codebase and found a lot of useful code. 
My old margin calculations were a real time`-saver... Exposure 
calculations seems to be ok now and also profit calculations 
passed initial checks, but I am suspicious about them still. 
This part is one of those `"undocumented`" parts, where you can`'t 
find any good existing material. BrokerCtrl works mostly now, 
but it has some small things to do still.&]
[s3;%- 29.6.2017&]
[s0;%- Automatic signal trading works now in SimBroker. It has some 
issues by not using volumes, but at least with pairs it seems 
to give matching values to MT4.&]
[s0;%- I think I`'ll try full autoencoder stack first, which means 
that RL`-agents will skipped temporarily. The last step will 
take all sym/tf forecasts as input and it gives smallest tf what 
can be followed per sym, and those will be applied directly to 
Brokerage class as signals. It`'s pretty straightforward, and 
that makes it even nicer. All levels are not autoencoders exactly. 
First level will reconstruct input data, but next levels uses 
previous level output as input and tries to reconstruct original 
from that. Last level will try to construct different signal 
entirely. It gives very generalized signal, and I think that 
is a good starting point.&]
[s0;%- This is a little embarrasing continuous changing of the plan, 
but I much rather fix the design before implementation than after.&]
[s0;%- ...&]
[s0;%- Yet another walk outside and another new idea. ConvNet MagicNet 
neural network architecture optimizer can be used instead of 
autoencoder.&]
[s3;%- 30.6.2017&]
[s0;%- Because of this constant changing of the design, I decided 
to start today from writing down all previous designs and reasons 
for not using them in their full form. The signal part and the 
money manager part is always considered to be separate and the 
success depends only on signal, but gets amplified with the proper 
MM.&]
[s0;%- I think this progress is universal and could be happen in 
very similar ways to others too.&]
[s0;%- [* Major phases were ](as known during involvement)[* :]&]
[s0;%-  `- Fundamental and basic technical signals&]
[s0;%-  `- Local optimizer based signals&]
[s0;%-  `- Scheduler and local optimizer based signals&]
[s0;%-  `- Chained signals. Fundamentals and probable asset based 
signals&]
[s0;%-  `- Agent chain signals&]
[s0;%-  `- Autoencoder chain signals&]
[s0;%-  `- [/ latest:] currency`-NN, web`-NN, accelerator`-NN signals&]
[s0;%- [* Simplified phases were ](as better afterthoughts):&]
[s0;%-  `- from peer`-reviewing observer to fundamental structure 
analyzer&]
[s0;%-  `- from breaking to combining pieces together&]
[s0;%-  `- from scalping to recognizing long`-term probabilities&]
[s0;%- -|( `- from slowing down fast to making slow faster)&]
[s0;%-  `- from news to structural&]
[s0;%-  `- from iterative units to best weights of whole web of instruments&]
[s0;%-  `- from fixed to locally optimized neural network architectures&]
[s0;%-  `- from genetic optimizers to neural networks (MT4 has Gen.Opt.)&]
[s0;%- [* ...and as implementation`-wise ](or more like `-dumb)&]
[s0;%- [_ Testing all ways to trade traditional signals]&]
[s0;%-  `- compared all traditional indis and found out that traditional 
indicators are useless&]
[s0;%-  `+ learned about spreads and characteristics of instruments&]
[s0;%-  `+ found periodical stats to outperform momentum`-following 
trading&]
[s0;%- [_ Local optimizer based signals]&]
[s0;%-  `- configuring stupid algorithm well once doesn`'t give long 
term performance&]
[s0;%-  `+ found that configured algorithm gets worse gradually, 
not immediately or never&]
[s0;%-  `+ found that optimization should be continuous during realtime 
operation&]
[s0;%- [_ Scheduler and local optimizer based signals]&]
[s0;%-  `- periodical scheduler implementation is a nightmare&]
[s0;%-  `- it is a very big and monolithic piece of complex inflexibility&]
[s0;%-  `+ found that following fixed timeframe changes is simpler 
and more powerful&]
[s0;%-  `+ found that querytable methods are better solutions to 
periodical statistics (and tech superset)&]
[s0;%- [_ Chained signals. Fundamentals and probable asset based signals]&]
[s0;%-  `- any loose strategy with existing methods did not work&]
[s0;%-  `+ improved probability math...&]
[s0;%-  `+ `"one future`" via slow tf instead of fast heuristic found&]
[s0;%- -|`+ the quest for `"fastest slow strength`" begun&]
[s0;%-  `+ found that stocks and indices has better forecast success 
rate when compared to other instruments&]
[s0;%-  `+ found proxy costs&]
[s0;%-  `- stocks are open very short time&]
[s0;%-  `- stocks have a lot of technical difficulties because of 
repeating opens and closes&]
[s0;%-  `- in the end, even forex`-crosses are betters instruments&]
[s0;%-  `- parsing fundamental news and interpreting them with a 
machine is a nightmare&]
[s0;%-  `+ found cent accounts to allow all instruments simultaneously, 
instead of only few&]
[s0;%- -|`+ also more accurate volume is possible with them&]
[s0;%- [_ Agent chain signals]&]
[s0;%-  `- too experimental, no known existing solutions, should 
have known demos&]
[s0;%-  `+ idea of chaining web of signals&]
[s0;%-  `- the chaining must be structurally correct, and signal 
must be derived from strong to weak&]
[s0;%- -|`- I was chaining from weak to strong... :/&]
[s0;%- [_ Autoencoder chain signals]&]
[s0;%-  `+ fits fundamental structures&]
[s0;%-  `+ found `"outer layer of currency asset`", proxy hedging 
and web of signals&]
[s0;%-  `- does have fixed network structure&]
[s0;%-  `- has easily too many levels&]
[s0;%- [* To conclude...]&]
[s0;%- ... this is clearly more like racing environment than good`-will 
scientific research, which was actually a disappointment. I think 
the content of everything I mentioned previously is very good 
knowledge of the surrounding world, instead of some trading secrets 
which should be taught only to selected few. I don`'t know why 
this is so undocumented topic and nobody seems to be willing 
to co`-work with me in this.&]
[s0;%- As previously mentioned, the good base is to start from something 
strong and to derive it with usable instruments and to extend 
it with new techniques.&]
[s0;%- Strong points are:&]
[s0;%-  `+ start from slow predictions, and use the fastest which 
performs better than slower&]
[s0;%-  `+ start from forces, what are caused to currencies because 
of pair exchanges&]
[s0;%-  `+ split risks to multiple instruments, so spikes doesn`'t 
damage that much&]
[s0;%-  `+ consider trading the full predictable wave of all instruments 
as one big single order&]
[s0;%-  `+ use combination of neural networks and genetic optimizer 
by optimizing the architecture&]
[s0;%- -|`- but don`'t settle on small networks if your computer is 
inefficient&]
[s0;%-  `+ follow repeating events instead of momentum&]
[s0;%- And the current design to implement those includes features 
such as:&]
[s0;%-  `- from strong to weak&]
[s0;%- -|`- first prediction from neural network modelling internal 
tensions of currencies&]
[s0;%- -|`- second prediction from neural network modelling balancing 
web of currency`-pairs&]
[s0;%- -|`- third prediction from NN trained for fastest safe timeframe 
for reading predictions&]
[s0;%-  `- probability math&]
[s0;%- -|`- the neural network library and the setup and is from tested 
source&]
[s0;%-  `- split risks to multiple instruments&]
[s0;%- -|`- all crosses are traded and illusion of currency exposure 
is ignored&]
[s0;%-  `- be flexible with local optimizer&]
[s0;%- -|`- all NN archs are optimized with magicnet (`+ gen.opt.) 
architecture optimizer&]
[s0;%-  `- follow repeating events instead of momentum&]
[s0;%- -|`- training is done with real time`-value vectors rather 
than heuristic view at single time`-pos&]
[s0;%- ...&]
[s0;%- Actually, one could join all those NN`-layers, but that`'s 
some difficult crafting there...&]
[s0;%- Fuck, change of plans, again....&]
[s3;%- 1.7.2017&]
[s0;%- I am a month late with this already.&]
[s0;%- So, what`'s today? Yesterday I found out, that a big single 
regression NN could be the most generalized solution, which is 
what is searched for here. It fits well to what I know. It feels 
like it`'s obvious solution, but it`'s not if you need to find 
it out by yourself. If you don`'t know all required things about 
markets, then it`'s just one possible solution and you can`'t 
tell why it is better than others.&]
[s0;%- Implementation`-wise, it`'s not a big deal. It is very similar 
to ConvNet examples, what I did. It has only a few `"moving`-parts`". 
That`'s very good, because otherwise you would worry about unknown 
bugs in the runtime. This constant changing of the design only 
gives me a headache, and it`'s exhausting to start working on 
the revised design. The headache goes away, however, but it will 
be worse if you let the feeling of frustration to get a grip 
on you. Picturing the new design is like rendering 3D image with 
global illumination, and it starts with grainy radiation and 
eventually it forms into a clear picture. That headache is like 
starting rendering that new picture. Physically it is more like 
tiredness and only a little bit of real headache.&]
[s0;%- Performance`-wise, it`'s a big deal. It consumes all processing 
power what I can provide. This solution should be processed with 
some accelerated processing card. ConvNet can easily wrap any 
NN library for those cards, so that is a easy feat. I don`'t 
currently have any and I am looking forward to getting one. With 
other solutions, acceleration cards wasn`'t an option, but with 
this final solution it is.&]
[s0;%- By the way, those other solutions are not forgotten. All fast 
timeframe area, which cannot be traded with the most generalized 
design, can be processed separately with more dynamic solutions. 
That is my understanding currently, at least.&]
[s3;%- 2.7.2017&]
[s0;%- To the Overlook, again. A little experimental tweak is required. 
It surprised me that it was something new, which is usually a 
very bad sign. Visually, it is like that Classify2D example but 
with additional slow moving dots, and one would expect, that 
the network follows them without too much problems. It is a internal 
performance value, and I try to make the NN to give it`'s expectation 
about it`'s performance. It is low at begin but should get higher 
during training, and those low values is expected to be overwritten 
during training. This is just an idea and maybe a bad one.&]
[s0;%- ...&]
[s0;%- Training seems to work, but data reading position is not changing 
yet. The quality of training must be checked with monitor widgets 
during runtime. My 8`-core 4GHz CPU hits 100% immediately and 
it starts a new training phase which will take weeks and months, 
but which will be limited after more training gets useless. The 
alpha version is just around the corner...&]
[s3;%- 3.7.2017&]
[s0;%- Training runs now. Quality checks are not done yet, but widgets 
shows reasonable processing happening. I have slightly pessimistic 
expectations about this... The lack of processing power without 
GPGPU or Phi etc. is a real problem. All current IOs are required, 
so I probably hit a limit with this hardware or the network is 
too small. I can consider buying those only later in this year. 
I have Parallella though, but it`'s not enough ;) I`'ll probably 
get some decent second hand card.&]
[s3;%- 4.7.2017&]
[s0;%- Ok, so the reading position wasn`'t changing even yesterday. 
I misinterpreted the indicator. Now it trains properly. Next: 
some graphs about quality, and that is the exciting part. They 
tell me that was this all work useless or not ;)&]
[s0;%- ...&]
[s0;%- Hmm... I got stuck. Some kind of network architecture manager 
is required to remember tested setups. Then you could add automatic 
architecture optimizer, like ConvNet MagicNet, to it, but it 
should be more intelligent. Basically it is easiest to just fork 
ConvNet MagicNet and connect those graphs to it.&]
[s0;%- Or maybe not. Automatic NN arch evolution is still better 
idea, but MagicNet trains all nets synchronously, and this already 
uses threads, so maybe best of boths should be combined. I`'ll 
just run thread per core, and when one finishes, then it will 
generate new session using differential evolution. It`'s actually 
better than MagicNet, which randomizes everything for new session 
always.&]
[s0;%- ...&]
[s0;%- Graphs works. I made simple and fast drawers, even though 
nicer plotters could have been used.&]
[s0;%- First results about performance have emerged: with timeframes 
W1,D1,H4,H1 average correct boolean`-direction (long/short) for 
all symbols is between D1 and H4 (0.63 in 0.5`-0.75). That value 
reaches surprisingly fast some plateau and I don`'t know yet 
how it should be interpreted. This doesn`'t have the arch optimizer 
enabled yet and I haven`'t tested it with test data yet (which 
hasn`'t been used in training), but 0.63 with that would be very 
good indicator.&]
[s3;%- 5.7.2017&]
[s0;%- Some positive results with the test data, or not as bad as 
they could have been. The copy`-pasted differential evolution 
code clearly works, but some limiting plateau occurs always.&]
[s0;%- Serialization works and all reasonable graphs works. Some 
values are cleary incorrect, but I`'ll focus on details later. 
This can be connected to real demo account tomorrow. Rapid loss 
of value can be expected, but the best reward of having this 
s`*it done is certain.&]
[s3;%- 6.7.2017&]
[s0;%- Found the stupid bug in the signal sum calculation, which 
gave incorrect values. That signal is like what would happen 
if all orders would have the same volume and there would be no 
costs. It`'s easier to calculate and it gives the most important 
information. So, that value is clearly positive with top networks 
and with the testing data, which is actually the biggest deal. 
Some practical issues remains still, though. Also, there is always 
a good chance for unexpected setbacks.&]
[s0;%- Overlook just opened it`'s first live MT4 orders (110 at once). 
All good, for now. No active updating yet, so this account might 
go south fast, but it`'s only fake virtual money anyway.&]
[s0;%- Only few tasks left before the alpha version. Then everything 
must be cleaned and commented, and after that, only slow long 
term debugging and fine`-tuning remains, but that takes very 
little time. End of the tunnel ahead...&]
[s3;%- 7.7.2017&]
[s0;%- The date of three sevens.&]
[s0;%- The list of tasks and issues is still long. Few important:&]
[s0;i150;O0;%- Costs affect the target length of orders, which must 
be considered. Patience and full coverage is preferred over reducing 
instruments, because of less risks and pair`-specific noise over 
asset.&]
[s0;i150;O0;%- Positive and negative limits of orders must be dynamically 
followed to avoid unwanted `"channel`-breaks`" in value.&]
[s0;i150;O0;%- Positive result with SimBroker must be asserted before 
continuing to MT4 demo account. That is just no`-brainer.&]
[s0;%- ...&]
[s0;%- I had to solve numerous weird bugs, which in the end found 
out to be caused by forgotten vector reallocations during Volume 
object writing. There was also other concurrency problems related 
to that. It`'s worst kind of debugging, sort of. With `"cheap`" 
debugging you can`'t be sure which causes the bug. The fixed 
result was better than expected. It solved efficiently many problems 
at once.&]
[s0;%- First time, the sum of all 110 MT4 orders resulted total positive 
sum. Not bad. That`'s just a meaningless detail, but sweet one.&]
[s0;%- ...&]
[s0;%- I got an idea how to configure SimBroker without using differential 
evolution local optimizer.&]
[s0;%- 1. Take that sequence trainer from that earlier mentioned 
scientific paper.&]
[s0;%- 2. Apply that to the DQN`-agent.&]
[s0;%- 3. Use fully connected regression network instead of RL`-graph 
actions.&]
[s0;%- That network will give configuration values. Few sequences 
of configuration values are recorded. The sequence with best 
result is used in training and others are discarded. Add some 
random input value if sequences are otherwise too similar. This 
is still very close to that proven method, and it is expected 
to work (or is it?). The most ridiculous thing is that this sounds 
like a baking receipe, even though the idea might be a worth 
of good published paper.&]
[s0;%- ...&]
[s0;%- Actually, it bypasses easily this current solution, if implemented. 
With few lines of code it can be made to give signals. Change 
of plans?&]
[s3;%- 8.7.2017&]
[s0;%- I`'ve been poking that weird regression network sequence agent 
this morning. It has two ways to implement it. The first is simpler, 
non`-threaded version, and the other is greedy threaded, where 
combination testing is done using a little outdated network while 
training is being constantly done in other thread. The current 
state is closer to that second one, so that will be used.&]
[s0;%- ...&]
[s0;%- I implemented it right away. The core of the engine seems 
to work, but it`'s not connected to GUI. That`'s a good point 
to continue tomorrow.&]
[s3;%- 9.7.2017&]
[s0;%- I got the first results of that weird regression network sequence 
agent. It clearly shows slow increasing in the performance. It 
simply works.&]
[s0;%- ...&]
[s0;%- No no no.... I was almost finished, but this will never be 
reactive enough, like DQN`-Agent. Even single`-threaded DQN`-agent 
with h4x for multiple output actions seems better. Instead of 
1 gradient you set multiple gradients at once. Gotta change plan.&]
[s0;%- ...&]
[s0;%- Or maybe not, this is actually very close to it already. That 
is actually very small change.&]
[s0;%- ...&]
[s0;%- I`'ll try that experience learning next. Those have beginning 
state, ending state and `'value change`' between those. Usually 
they give only one action, but I`'ll try to hack 3 actions (long/short/idle) 
for every symbol simultaneously. There`'s no technical limits 
at all. The most challenging task is to collect those experiences 
properly. By the way, the single action version has a working 
example in the ConvNetC`+`+ library.&]
[s0;%- The task list is getting REALLY short. The Overlook is feature 
complete tomorrow or day after it. Then only cleaning, commenting 
and `"real`" documentation remains. The finest documentation 
is a master`'s thesis document to my school, but that isn`'t 
in a hurry. [/ They see my journal, they hatin`'... red`-marking, 
tryin`' catch me writin`' dirty...]&]
[s3;%- 10.7.2017&]
[s0;%- I couldn`'t see it coming, but this experience training version 
is very close to yesterday`'s version. I was almost frustrated 
about useless work already, but it was pointless luckily. Network 
outputs changes only a little, training is slightly different 
and rewards must be calculated for all symbols every time step, 
but that`'s all. Only the monitoring and verifying of the process 
will be some long`-term challenge. The multi`-action tweak is 
still the only difference to proven neural network applications. 
The rest of these problems are practical.&]
[s0;%- ...&]
[s0;%- Ok, this is almost finished. Today had the last foggy technological 
step. The code still needs much scrutiny, but that`'s always 
better to do after a break.&]
[s0;%- ...&]
[s0;%- I found more bugs. Bad ones. I don`'t think it`'s done yet, 
but it`'s enough today.&]
[s0;%- ...&]
[s0;%- Fucking unbelieveable. I get rid of this bullshit in 2 days...&]
[s3;%- 11.7.2017&]
[s0;%- After one night of training, the Overlook seems to show green 
for real usage. The multi`-action tweak seems to work. It is 
a lot faster than putting the values separately.&]
[s0;%- ...&]
[s0;%- A lot of constraints with this. When positive and negative 
values are splitted to separate normalized sensors, the volume 
size gets huge. That allows only immediate previous and next 
values.&]
[s0;%- I am definitely seeing some satisfying results here. The loss 
value seems to decrease gradually and tests are passing for real 
usage.&]
[s0;%- ...&]
[s0;%- Hmm.... this seems bad.&]
[s0;%- I am starting to notice, that I missed the simplest and most 
obvious solution, which is to create single`-threaded solutions 
for single instruments, which ignores all web`-effects, but those 
were very theoretical anyway. This current plan has many weaknesses 
and inflexibilities, but I solved many issues with this and got 
it running, so it`'s not that bad. This actually gives positive 
results already, but in a very cumbersome way.&]
[s0;%- Yeah, I am going to pivot into that... I think I learned a 
lot with this version, and now it`'s going to be easy.&]
[s0;%- Fortunately, it seems that I can just remove all symbol`-loops 
in the Agent class and dedicate one Agent object to one symbol/instrument.&]
[s3;%- 12.7.2017&]
[s0;%- I haven`'t done yet the university course, where you define 
complexities of functions, but I can say for sure, that it will 
reduce a lot when all for`-symbol loops are taken away from the 
Agent class.&]
[s0;%- ...&]
[s0;%- This solution could have been done first, but I couldn`'t 
prune those other possibilities out without knowing why. In the 
end, this is the most obvious solution: DQN`-agent training with 
SimBroker using one instrument, and best agents are combined 
and exported to the MT4 account. I was talking about this all 
the time but I guess the implementation was harder to grasp than 
expected. I just had too many questions to go this directly.&]
[s0;%- I mean, this really gets simplified in front of my eyes to 
that solution which I knew really well all the time. My excuse 
is that maybe there was just too many details what couldn`'t 
be known by doing this first :)&]
[s0;%- I am clearly looking for reasons here to justify all that 
useless work... How I could keep all that web effect stuff that 
I was talking about? Maybe if I somehow connected all latest 
signals of all agents, and used them as inputs? Like a little 
virtual social network for those little virtual agents. Without 
that, I am just back in the square one, so let`'s do it! It just 
requires a synced group class.&]
[s0;%- Agent groups. Well, that could work. Code started to move 
to that direction fast already.&]
[s0;%- ...&]
[s0;%- Agents can be tested with and without previous signals of 
other group members as inputs. Hypothesis is that it does improve 
results and calculations can be repeated from statistical mathematics 
courses. I usually skip to conclusions faster, but real math 
can be done nevertheless.&]
[s0;%- This pivoting to agent groups shows as very broken code... 
I am not happy about the delay in the completion, but I am happy 
about the improvement in the design.&]
[s0;%- In conclusion, I converted the Agent to use DQN`-agent instead 
of deep fully connected neural network. I also moved instrument`-web 
features from Agent to AgentGroup. Both non`-obvious changes 
improves quality and robustness.&]
[s3;%- 13.7.2017&]
[s0;%- With new AgentGroup and Manager classes it is easy to test 
how other symbol data and previous signals affects the result. 
My hypothesis is that they both improves results in input and 
soon it can be tested. I am not going to do extensive statistical 
math immediately, but if this will be a source of my master`'s 
thesis, then the math part will be polished to the maximum.&]
[s3;%- 14.7.2017&]
[s0;%- Well, this is fun. DQN`-agent seems to hit high peaks with 
early training and after a while, it simply hits the upper maximum 
and stays there. How realistic is that? Not exactly simulation, 
but it`'s getting there. Also, it doesn`'t repeat always. These 
are the results what I wanted to see anyway.&]
[s0;%- I have weird Déjà vu feeling while writing this... In previous 
versions, I have seen good results and then immediatelly started 
an upgrade which breaks all existing functionality. Is it different 
this time?&]
[s0;%- I would say, that there won`'t be more powerful AI than DQN`-agent 
in this for a while. Also, if I happen to find something else, 
I might not even care anymore to update this.&]
[s0;%- So, there is a good chance that this engine finally stays. 
I haven`'t had time for fine`-tuning and re`-checking stuff when 
I had to focus on the engine, but now I might finally have time.&]
[s0;%- Some agents are really hitting the maximum value and getting 
SimBroker stuck, which is actually the funniest bug for a while. 
Some of the instruments fails constantly, so it`'s not all positive. 
Also, I don`'t test this now with test data and real environments 
have all sort of constraints, so it is not realistical, but that`'s 
not the point.&]
[s0;%- Today was a bit more relaxed day. I am in a hurry and I don`'t 
have much time for this, but one must listen to himself sometimes. 
Next semester is coming and it sets a great pressure to prepare 
some math, but I also need to get this to run at background before 
that.&]
[s0;%- There is tens of issues what still must be resolved. The rewriting 
of the engine has been a time consumer, but if this is final 
(and it probably is), then this fine`-tuning part is going to 
be over in two weeks too.&]
[s3;%- 15.7.2017&]
[s0;%- Hi all, again. First, I want to note, that I am fan of rap/hiphop/reggae/dance
hall etc. music. I have been listening to those via Internet 
radios since before teenage. I actually searched for the history 
of hiphop musics as teenager and listened to most known artists 
which affected to the evolution of the culture. Nowadays, I must 
focus on working, so I listen to background music without vocals, 
but that also usually have impacts from hiphop anyway. I have 
also been producing some hiphop music, which has been successful 
(best song >200000 listening before youtube... I lost track at 
some point), but I didn`'t pursue that path, because I was such 
a nerd.&]
[s0;%- As you can see, the Overlook is an good example, where cold 
professional attitude would have prevented the most important 
progress and evolution of the design. I know that some people 
counts this as failure, deplorable and even cancer invidualism, 
but I would say them, that they are clueless and their world`-view 
is too narrow. This is not forced worldview, this is not parasitic, 
this is not anti`-social. Sometimes people forgets, that the 
unity of thoughts is only a simplified song about surrounding 
world. It makes you have a great high, but the hangover is unbearable.&]
[s0;%- ...&]
[s0;%- But back to the programming.&]
[s0;%- There is some hard`-to`-see problems with the free`-margin`-level 
money manager. It`'s basically too passive and impossible to 
train properly for agents. Following notes have required a lot 
of testing and work, which has been done in the past:&]
[s0;%-  `- the result of combined agents is chaotic&]
[s0;%- -|`- one goes negative&]
[s0;%- -|-|1. allowed margins decreases&]
[s0;%- -|-|2. volumes are fixed&]
[s0;%- -|-|3. new orders get too small volume&]
[s0;%- -|-|4. volumes are not balanced to risks of instruments anymore&]
[s0;%- -|`- one goes positive&]
[s0;%- -|-|1. allowed margins increases&]
[s0;%- -|-|2. new orders get high volume&]
[s0;%- -|-|3. one goes too much negative temporarily&]
[s0;%- -|-|4. open volumes are too high, and must be reduced and it`'s 
just costs and losses&]
[s0;%-  `- single agent training is actually incorrect&]
[s0;%- -|`- reward is relative to the value of the account, but not 
to the volume&]
[s0;%- -|-|`- agent is not trained for the risks of the volume&]
[s0;%- -|`- the other way around: when reward is relative to the volume:&]
[s0;%- -|-|`- agent is not trained to balance the account value&]
[s0;%- So there you have it. Using that kind of MM is just plain 
WRONG! Well, I was the one who made the mistake here, but I am 
just going to overwrite this with the proper solution, which 
is to train for signal and MM with separate agents. Hopefully 
I prevented a lot of useless work for someone with this.&]
[s0;%- ...&]
[s0;%- Training seems to be very demanding, but results seems promising 
otherwise. Results has constant increasing average trends. I 
haven`'t had this kind of system ever, so it takes some time 
to learn how to tune this correctly.&]
[s3;%- 16.7.2017&]
[s0;%- Ok, so the reward model was wrong. I didn`'t follow original 
examples too strictly... The reward comes only from closing orders, 
but the realtime change value should be forwarded via inputs. 
Also, average signal to input was wrong, and original had `"velocity`", 
which has similar counterpart in this as accumulated signal, 
which is interpreted simply to `+1 or `-1. Orderlist started 
to look a lot more realistic with these fixes...&]
[s0;%- This solves the issue of not having continuous orders, and 
now shorter timeframes can be used. M1 is now a valid target, 
but I am very skeptical to scalping methods. With this, it is 
still worth testing and easy. Short timeframes actually have 
a lot more price`-change area (the surface is kind of a fractal 
with only technical limitations), but it`'s hard to combine with 
longer strategies. I think that if you can`'t `"accelerate`" 
good slow strategy to faster, then you should avoid fast strategies. 
I know that institutional, HFT and big business worlds are just 
completely different topics. My computer science knowledge is 
related to business exactly this amount and nothing more, and 
I do all I can to finally close this topic fast as possible.&]
[s3;%- 17.7.2017&]
[s0;%- It`'s almost over! This project, I mean. This AI won`'t scare 
anyone. It`'s a nice demo and maybe a source of fine master`'s 
thesis, but that`'s it. I guess that the training will take 1`-2 
weeks, because of the count of agents.&]
[s0;%- Technically, I am almost satisfied. Many parts of the DataBridge 
are very hackish solutions, but I don`'t seem to find anything 
that I would really want to change. The result feels robust, 
except that the underlying asserts are triggered sometimes by 
imperfections in the DataBridge connections.&]
[s0;%- Many ideas have been popped into my mind at previous days, 
but none of them has been an improvement in the end. That`'s 
good. This is finally holding water, metaphorically.&]
[s0;%- GCC and MSC compiles working release versions with 2`-5x speedup 
to debug version. If this has any positive results, then I`'ll 
upload release to the github. Only some realtime fixes and cleaning 
left... finally?&]
[s3;%- 18.7.2017&]
[s0;%- The program trained for 12 hours with 8 fx instruments and 
all drawdowns are between 20`-50% in D1 timeframe, but I haven`'t 
tested that with separate test data yet. However, stock CFDs 
are even more successful in my experience. To finish this pre`-alpha 
stage, I am going to train D1 stock CFDs and fix the realtime 
support.&]
[s0;%- ...&]
[s0;%- Using DQN`-agent as the group optimizer was terrible idea. 
It`'s just not a good tool for the job. In the past, I made an 
indicator, which shows average volatility per hour of week or 
day of week. It did show, that different instruments have different 
days of peak volatility. So, the theory is, that with genetic 
optimizer, one can optimize weights of instruments per timeslots 
to maximize `"usefulness`".&]
[s0;%- ...&]
[s0;%- Only realtime sync details and some small fixes left...&]
[s0;%- ...&]
[s0;%- CFDs seems to fail, which surprised me. They might work only 
with W1 tf and slower...&]
[s0;%- I am going to give only one hint how to tune this and it`'s 
the following: currently, I guess that the best result comes using 
this with base currency USD, with timeframes D1,W1 and with instruments 
AUDJPY, AUDUSD, EURAUD, EURUSD, GBPAUD, GBPJPY, GBPUSD, NQ, NZDUSD, 
USDCAD, USDJPY, YM. It have been pretty much instant <50% drawdown 
with training data (and the result is still unknown with testing 
data), but it`'s not a promise of any results.&]
[s3;%- 19.7.2017&]
[s0;%- It`'s pretty much done now. Drawdown after 1 day of training 
is <5% at best in training data, and realtime connection seems 
to work. It`'s only up to the user to tune this properly, which 
is not hard if the user has any will to do it. Only few tasks 
left before changing the status to `"after release`".&]
[s0;%- There is only some tidying to do before the first release. 
The app is alpha quality otherwise now. I am probably going to 
push the release at friday with a small final rant... and after 
that, I am going to drink a bottle of vodka and smoke a pack 
of cigarettes with my friends.&]
[s3;%- 20.7.2017&]
[s0;%- Fucking margin calculations were wrong and now I must restart 
training. I did those correctly in the past, but seems like I 
didn`'t remember them at all while writing this. This was those 
last tasks in the TODO list and it broke more than expected. 
The reward changes and the agent can`'t understand it. Actually, 
I added some variables that should be serialized, and since I 
don`'t do versioned files, then old files would break anyway. 
Also, I think I`'ll change broker to InstaForex because of their 
awesome cent account and red color.&]
[s0;%- ...&]
[s0;%- I just checked this journal for release. I didn`'t read it 
in details, but it can`'t be too bad. I have tried to keep some 
high standards with this. I can`'t really remove or fix much.&]
[s0;%- [* Yeah, the release is happening tomorrow.]&]
[s0;%- I almost can`'t believe this. So many times the schedule was 
extended because this was incomplete, but now I can`'t do anything 
more, except to make the release package.&]
[s0;%- I am satisfied to the end result. Constraints for doing this 
are strict, but I think I managed to make quite a product in 
those limits.&]
[s0;%- I am going to write the results to the after`-release section 
of this journal. I don`'t think I need to make big changes to 
make this work, but I might be wrong... I haven`'t proven this 
to work in test data or in real environment yet.&]
[s0;%- I think this was worth the time and effort.&]
[s0;%- My immediate reward is to not need to think about working 
on this at next day. Then, I can finally do school work, which 
is more relaxed, believe me or not. I will be working on math 
programming environment until start of semester, because I made 
such a success in learning using my previous hackish environment. 
I`'ll use javascript for that this time.&]
[s0;%- Oops, I forgot that I broke exposure calculations previously 
for some stupid reasons. Now they seem to work again, at least 
for forex.&]
[s0;%- I promised a rant tomorrow with the release and I still plan 
to do it.&]
[s3;%- 22.7.2017&]
[s0;%- Well that was a fun release day... too fun to write that rant. 
Also, turned out that my friend gets married next summer and 
I am the best man, so that`'s new to me. Today in hangover, I`'ve 
started making N`-Trance `- Set you free remix, but I got also 
improvement idea to Overlook, which I had to do.&]
[s0;%- There was a gap between H4 and D1: H8 and H12, which might 
have more success than H4. I added few lines to generate those.&]
[s3;%- 23.7.2017&]
[s0;%- Turned out, that AgentGroup optimizer was still buggy. It`'s 
now fixed, but there is still improvements to do. SimBroker gets 
stuck with high account value and reason for it is hard to trace. 
Maybe DQN`-agent could be brought back with different reward 
model and it could do some `"collecting`" to avoid getting account 
value too high. Btw, it`'s still not related to real life performance...&]
[s0;%- ...&]
[s0;%- Hmm... so many mistakes today. The reward function for AgentGroup 
is definitely not any collecting or order closing. It actually 
seems to lose almost in every way to timeslot local optimizer, 
but it just doesn`'t break the SimBroker for too high value...&]
[s0;%- ...&]
[s0;%- This just might work. DQN with AgentGroup seems to match the 
performance of the timeslot optimizer after training for a while. 
I think I`'ll stick with this solution.&]
[s3;%- 24.7.2017&]
[s0;%- Still some bugfixing had do be done today. Also, training 
had to be restarted, because serialization changed so much. Turned 
out, that the experience vector must be serialized too or otherwise 
the training doesn`'t continue correctly after restart. The serialization 
file grew from 200Mt to 2Gt... and that can`'t be fixed.&]
[s0;%- I haven`'t had correct realtime processing yet, but maybe 
starting from midnight... There is sill chance for bad bugs, 
but I think I`'ll still start the Post`-Release part tomorrow.&]
[s3;%- 25.7.2017&]
[s0;%- I finally noticed incorrect profit calculations with proxy 
currency. There`'s no documentation for that so I had to find 
out those formulas by trial and error. Everything must be re`-trained 
after this fix...&]
[s3;%-  27.7.2017&]
[s0;%- I still didn`'t change to `"after`-release journal`" mode. 
I have a short tasklist to do and after that I`'ll release v0.2. 
It will be a lot better than v0.1, which had that fatal error 
in latest snapshot signal writing which prevented it to work 
in real`-time properly.&]
[s0;%- ...&]
[s0;%- I`'ve been getting positive results in real`-time mode with 
H12 timeframe. It`'s the first time that I`'m feeling some hard 
support with this project, but I have still so much to do that 
I can`'t focus on that.&]
[s0;%- I must still bring back the DE solver to optimize AgentGroup 
stuff. This time it will also combine different timeframes. Modes 
with H12, D1 and W1 works alone, but it`'s even more reliable 
to use all of them simultaneously, which is what I`'m going to 
do. So, the slowest must have some fixed volume, which must be 
cannibalized in case of negative peaks in faster tfs, but that`'s 
the only exception. Then again, it`'s useless to hedge different 
tfs against each other and unless you did that negative peak, 
then you can re`-open the slower with same volume. So obviously 
you don`'t acquire that useless margin and you go with that weird 
re`-open mode, and then it`'s so complicated that I can`'t even 
... tell about it yet. It`'s basically about a list of balancing 
tasks which must be done in correct order and only input signals 
(of H12,D1,W1 agents and their weights) can be changed and the 
huge sequence of signals are trained only by the end result.&]
[s0;%- One of the tasks is to create a analyzer module, which follows 
unique real`-time modes what I use and gathers all real`-time 
data properly. I`'ve said already, that I am trying to use this 
in my master`'s thesis in the computer science and I have time 
to do some long`-term testing before that, which requires the 
data collecting. The Overlook is not the most easiest topic to 
defend in ethics debate and it basically brings all the dirt 
from all sides visible, but unless they go full retard religious 
or nationalist mode, then this is ethical.&]
[s0;%- ...&]
[s0;%- Personally, I am so prone to think that the brain is a biological 
neural machine with inputs and outputs, that I can only think 
that `"which training/experience will make the brain to put out 
that it has connection to superior brain instance or not when 
the input is X`". So in my opinion, a discussion about atheism 
or theism is outdated.&]
[s3;%- 30.7.2017&]
[s0;%- I finished the tasklist. I could release the v0.2, but I`'ll 
run the app for a while and check for bugs.&]
[s0;%- The snapshot is HUGE with 21 pairs.. almost 7 Gb and it cannot 
be made any smaller... unbelieveable. So yeah, serializing the 
runtime takes fucking 7 Gb snapshot... all of that stuff has 
valid reason.&]
[s0;%- The app lacks all sorts of user friendly features, such as 
progress bar for writing/reading that 7Gb snapshot. I`'m dreaming 
about the v1.0 release, where all those issues have been resolved 
and the user gets beautiful fully automated solution, but it`'s 
a long way there and I have barely time and interest for this 
engine part.&]
[s2;%- Post`-Release Journal&]
[s0; This is the time after the released alpha version and before 
the v1.0 release. It started from the version v0.2, because v0.1 
turned out to not work in the real`-time mode.&]
[s3; 31.7.2017&]
[s0; I just released the v0.2. If I had wrote any journal text today, 
then I would had swiched to post`-release only tomorrow.&]
[s0; This is not as exciting as v0.1, but it feels good, man.&]
[s0; I haven`'t witnessed any good long`-term performance yet, but 
it`'s nearly there. I`'ve been using fast timeframes as H4, which 
are known to fail easier. Last mistake that I found was to not 
use randomness in group optimization, which caused optimizer 
to weight more on overfitted H4. One cannot avoid the overfitting 
to training data, because data can`'t be generated, but by adding 
the randomness it looks more like real`-world like situation 
and group weights are tuned accordingly.&]
[s3; 1.8.2017&]
[s0; I must test one tweak today. The other option is to retreat 
a little too much to slow long`-term strategy.&]
[s0; Faster tf agents had only 2 tfs in DQN inputs for performance 
reasons, but if you put all slow tfs to their inputs, they`'ll 
get better support. However, it is going to be slower to train.&]
[s0; So, I`'ll test all instruments with timeframes W1,D1,H4,M30... 
Ratios between them are 7,6,8 with average of 7. Faster tfs have 
been tested to not work well alone, but if they get full chain 
of signals from slower agents, it might change the result completely. 
I haven`'t tested anything like this before and it`'s definetely 
the most complex test so far. I`'m amazed that the app scales 
to this test. These features actually came up during implementation 
and they weren`'t in the design.&]
[s0; What the hell, I`'ll test with W1,D1,H4,M30,M5,M1 with ratios 
7,6,8,6,5 with average of 6.4. It`'s pretty ridiculous and it 
might totally fail to updating orders between every minute. However, 
enabling the freezing of signals might prevent that.&]
[s0; ...&]
[s0; I had to add feature for focusing on single timeframe at a time. 
It switches tf processing from W1 to D1 to H4 etc. when drawdown 
is small enough.&]
[s3; 2.8.2017&]
[s0; Today I started a serious training, which will take about week 
to complete. Timeframes W1,D1,H4,M30,M5,M1 are trained for all 
21 major pairs. Signals are freezed to avoid modifying orders 
when unnecessary. I am hoping to achieve positive results with 
M1 training data. It haven`'t worked alone without slower tfs. 
Relatively high random action probability costs more with faster 
tfs, because spreads costs more when continuous signal is disturbed.&]
[s3; 3.8.2017&]
[s0; Hmm... I am totally hitting a brick wall with the lack of processing 
power. Faster than H12 is not feasible with this system. I will 
do C`+`+ AMP GPU`-accelerated version later. I found out how 
to implement that, but it`'s the complete opposite to the current 
model, because deep containers are hard or impossible to move 
GPU`-memory. So, basically the object size of Agent class should 
contain everything, which can be made dynamic with templates. 
Once done, it will be blazing fast. They run faster and there 
can be much more of them. They will have limited inputs, however, 
since they can`'t read every agent`'s previous output.&]
[s0; Implementation`-wise, it`'s like a jump from steam train to 
F1`-car. I very much dislike the standard c`+`+ conventions and 
I prefer U`+`+ conventions over them every time. I think that 
the standard conventions are utterly impractical, ugly and very 
unintuitive for every non`-native English speaker. I could talk 
about that topic for hours, and it would be very bitter`-sweet 
talk, and I won`'t do it for fun. So, first I need to add some 
very thin Ultimate`+`+ convention abstraction layer on top of 
the C`+`+ AMP standard library. Then I need to port the ConvNet 
library on top of that, and only after that I can start to port 
Overlook to it. I would do only that for my day`-job if I could, 
but unfortunately no`-one is paying for it, so it won`'t happen. 
I am already behind schedule with the university work, so even 
working on this at evenings will be a challenge. It`'s a very 
unfortunate situation to do something what you dislike instead 
of doing something worth of money just because no`-one is sponsoring 
and surrounding environment is full of ignorant fools and leftist 
liberals.&]
[s0; I think I`'ll find some time next semester to work on this too, 
but those timeslots are scarce. Until that, I`'ll run this with 
W1,D1,H12 setup at background. I am satisified for that result, 
also. It was my target. This is far from over, but I`'ll temporarily 
suspend all work on this because of school work.&]
[s3; 11.8.2017&]
[s0; Test results have been positive since wednesday. I found that 
sensors were still incorrect at monday because of the weekend, 
so that might explain negative results at monday and tuesday. 
The total change per day increased steadily from monday to friday. 
The week was positive in total. I noticed that this didn`'t take 
much risk at all and the balance increase was `+4% for the whole 
week. One must remember, that this is very short test period 
for swing trading (in which the length of order is at least one 
day), and these shouldn`'t be projected to long term performance 
estimation.&]
[s0; This system won`'t get much better by making it faster, but 
I am testing the 6x faster setup for next week. The serialization 
file will be huge.&]
[s0; I tried to fix that weekend sensor bug... I guess it`'s good 
this time.&]
[s3; 17.8.2017&]
[s0; I tested M15 instead of H4. It was a total failure. This technique 
just doesn`'t work for that. However, the test was a nice technical 
feat even with a negative result, because a group with W1,D1,H12,H4,H1,M15 
took too much resources in the start and now it is possible. 
The limit for period with this technique is at least between 
H4 and H1, but H12 and H4 are not tested yet, so the limit might 
get higher.&]
[s0; The other technique for higher frequencies might be that one 
would use only the fastest data and agents would have different 
actions for different length of orders (with sl/tp limits). I 
got that idea today and it seems very reasonable feature to me. 
It is a small addition to current version...&]
[s3; 18.8.2017&]
[s0; I planned the other technique and found a bad bug in the current 
version. While slower agents are training, they can only see 
previous actions of other agents, but when faster agents are 
training, they should see actions of slower agents in the same 
timestap and not previous.&]
[s3; 19.8.2017&]
[s0; Today I have time to implement some of planned changes.&]
[s0; I looked upon the code to estimate how much code could be improved 
if I had much more spare time. I thought that I could do the 
AMP C`+`+ accelerated DQN`-agent, but now it seems too difficult. 
The ugly truth is that this program is glued together while programming 
without known end result, and it`'s increasingly difficult to 
modify it without planning. Also, I have had to be fast, which 
haven`'t made the code more intuitive. The DQN`-agent barely 
works correctly with the 1:1 JS`->C`+`+ conversion and with one 
working and identical test. New major version with almost complete 
rewrite would be needed, but only when this version has known 
working final version. The nice feature of this version is that 
it is completely cross`-platform supported on desktop computers: 
Windows, Linux, OSX, FreeBSD. It just gets an better edge on 
Windows with Visual C compiler.&]
[s0; Hmm... more issues. I tested the `"reward for closing orders`"`-model, 
and forgot to return it back to normal sustained increase model. 
The question is, why the training seemed to work anyway? The 
reward didn`'t go after the timestep but immediately after the 
action, which closed or opened something.&]
[s0; Hmm... and even more issues. This is the one I fear the most. 
This is reoccuring problem and the reason why I added safety 
limits to indicators. I accidentally wrote rewards to all snapshots 
between previously forwarded snapshot, which gave correct reward 
value for faster timeframes, like at tuesday you knew the reward 
for the whole week. That`'s non`-realistic peeking and it ruins 
everything. The neural network notices that short`-cut of course 
and uses it in training... You can forecast, but you can`'t peek. 
I meant to wrote those after when the reward is known...&]
[s0; ...&]
[s0; Whew... I added the timestep feature for smaller timeframes. 
At first time I could get positive results with M5 in training. 
It`'s far from stable, but there`'s a chance that it would just 
work now.&]
[s3; 20.8.2017&]
[s0; White supremacist have been a topic recently. I didn`'t know 
any of those while living in the city, but when I had to go to 
the mandatory military service, then I met more of them than 
I could handle. In the military police training, I had to sleep 
in the same house with guys, who said how them want to be a police 
so they get to beat some non`-white people. They had friends 
who were cops and they were generally good candidates to be polices 
otherwise, which is scary. That was rather common thinking, and 
none of non`-white people could get higher ranks. We had a lot 
of boxers there, and there was a lot of casual violence everywhere 
at free time. Many of those compared their penis sizes and yelled 
to everyone about their length. The penis talk was common in 
that sense. They were very visually thinking also, and not deep 
thinkers. Together with enforced religious events, it was a brutal 
and tribalistic place. There was some seriously evil `"tower 
gossips`" also. Some guy gossiped me being a `"rapist`" and my 
sister`'s house got sprayed with `"rapist`'s sister`" tag. That`'s 
seriously evil... Since Finland`'s military is a complete copy 
cat military from Russia, then I guess it`'s same there in bigger 
scale.&]
[s0; I had been reading psychology and a lot of Freud for fun before 
going there, so I was just analyzing sub`-conscious stuff and 
do they really have some father`-relations to their leader etc 
(in very non`-serious and non`-professional way)... Apparently 
that`'s a sweet spot for that kind of stuff, but I`'ll tell you, 
it`'s dangerous. One thing for sure is that they have an eye 
for courgeous women. The most beautiful women I`'ve met have 
been daughters of some military leaders.&]
[s0; ...&]
[s0; Drawdowns have been realistically high after fixing that peeking 
bug. M5 seems to be viable now, and I am testing W1,D1,H12,H4,M5 
group this week.&]
[s3; 22.8.2017&]
[s0; The performance have been ok, but the iterative real`-time version 
is too complicated and it has some issues. Snapshots must be 
splitted to parts and their state must be flagged and flags and 
values must be matched before using. Simple stuff, but hard to 
see from the direction in which I`'m coming. The top`-down method 
instead of interative has always been more clear so far.&]
[s0; Today, I got a new key idea to solve the remaining quality issues. 
Again, simple stuff, but hard to come by. The group agent can 
be a DQN`-agent. The problem is, that it can only give one action. 
Somehow I missed the point, that it can have a variety of dumb 
balancing functions and those can be triggered from actions. 
It doesn`'t need to have full control of details, but it can 
call those dumb functions in right time.&]
[s3; 23.8.2017&]
[s0; I decided to do remaining improvements, including making DQN 
to run in GPGPU.&]
[s0; I could go on an on how evil and stupid some of these faulty 
products of socialists around me are, but that`'s not very important. 
The people who go under radar to do something are the real problem, 
and those can`'t usually communicate properly etc... One event; 
some fighting sport fan son of owner of some McDonald restaurants 
came to me with those insane gossips saying `"I`'ve been hearing 
some things about you...`" and I thought he meant that bowl of 
weed I smoked at some weekend, so I said `"ssshhh`", but he meant 
some rapist gossips and took that as a reason to gossip even 
more that insanity. Stupidity of people just gets new high scores... 
Meth`-head fight`-clubber, and goes against educated, socially 
and in rare events smoking ... other type of heads.&]
[s0; ...&]
[s0; Anyway, looks like DQN agent can run in a one big chunk of memory.&]
[s0; I broke a lot of code today. I am doing all changes at once. 
Very unprofessional, but fast...&]
[s3; 24.8.2017&]
[s0; I found many improvement ideas today while implementing other 
new features.&]
[s0; Now when fast timeframes works, only M1 is needed. Stochastic 
oscillator and OsMA can be used with varying period to have longer 
sensing. C`+`+ AMP can be used for processing, and multiple agent 
group can be used simultaneously. Currently there is 21 instruments 
in one group, so there can be many of those groups. One group 
will have `"manager agent`", which modifies the lot amount and 
then `"manager of managers`" can join the signal for exporting.&]
[s0; I also found the reason why large experience size was preferred, 
and it was due to the buggy leaking of reward value. It basically 
allowed to remember all leaking values during training. That 
can be reduced and now many agents can fit in GPGPU memory.&]
[s0; The codebase is in extremely messy state currently, but it will 
be in working state soon again.&]
[s0; ..&]
[s0; C`+`+ AMP code is incredibly easy to use compared to OpenCL 
or Cuda. Just brilliant. I wrote my first few lines with only 
generic C`+`+ experience.&]
[s0; This is going to be fast... It`'s very nice too see this getting 
simpler, but also I know that research relating to that stops. 
These settings seems very stable, but it`'s always risky to make 
the inflexible and optimized version.&]
[s3; 31.8.2017&]
[s0; The AMP port has been progressed steadily. Training of agents 
works currently and it`'s much faster than previously. The amount 
of rewriting has been high. Macros must be used to get AMP compatible 
code and it`'s hard to get pretty. I got rid of slower tfs than 
M1 and now I`'ll sensor slower periods with high period in OsMA 
and stochastic oscillator. I think these all are huge improvements, 
but I can`'t research more that previous multi`-tf stuff.&]
[s0; I tested the new Joiner agent yesterday, which is expected to 
be better solution than previous time`-slot differential solver 
optimization, because it is more sensitive to real`-time operations. 
It didn`'t work out well, yet. It was a first test of the first 
prototype of the new concept, so it`'s not a unexpected problem. 
It showed that instrument functions, that are provided to the 
agent for action`-switch type usage, are not good... I`'ll temporarily 
replace it with the most simplest algorithm and see, if there`'s 
problem with the common wrapper code. Unfortuntaly, I might be 
almost clueless about the correct instrument functions what should 
be provided for the agent. This kind of code usually requires 
much time to evolve into something usable, and I am just in the 
beginning :( ...and I also must go to the next semester in the 
university starting next week, so bye bye money code.&]
[s0; I am basically finishing the porting today and after that I`'ll 
improve user friendliness and add support for imported long`-term 
M1 data. Finally, I`'ll leave that Joiner class problem to solve 
itself at background. I am pretty satisfied, even though the 
app won`'t be working yet. Now it`'s robust and fast and it only 
has some troubles with the theory of the Joiner class.&]
[s0; ...&]
[s0; Yeah... the best of the day... the AMP version seems to work. 
AMP debugging doesn`'t work in Ultimate`+`+ IDE, but I made that 
thin `"CPU Only`" AMP wrapper, which works in Linux and FreeBSD, 
and you can debug the app with that, and then it seems to run 
in the GPGPU correctly.&]
[s0; I had to import random number library for AMP. I tested it and 
it seems to work properly, also. So no problems, except with 
that Joiner class theory.&]
[s3; 1.9.2017&]
[s0; Joiner seems to work well now. I didn`'t change anything, but 
I just forgot to enable training previously.&]
[s0; The AMP porting and new functional features are now complete. 
I haven`'t done the real training and testing yet, but it looks 
promising in debugging too. I`'ll still add support for long 
term external M1 data and do some user friendliness improvements 
and the it`'s time for a new release again.&]
[s3; 2.9.2017&]
[s0; Hmm... AMP version is not really working. It throws some exception 
and I can`'t find out what it is without Visual Studio. Then 
again, this is Ultimate`+`+ and I can`'t just open and compile 
this in Visual Studio. Once again, the monopolistic attitude 
of MS ruined everything. I`'ve noticed, that software, which 
doesn`'t support Windows, Linux and FreeBSD tends to be crappy 
in quality. AMP is definitely the way to go, but it`'s not very 
well supported yet. I might get it working in Linux (https://github.com/RadeonOpen
Compute/hcc) but I don`'t have time and mood for that kind of 
tinkering right now. That probably will support FreeBSD later, 
because it compiles to OpenCL and runs on Radeon GPUs, which 
happens to work also in FreeBSD. So yeah, it will be the most 
user friendliest, sanest and most compatible parallel computing 
API, but it`'s just not there yet...&]
[s0; I think Ultimate`+`+ is actually the higher standard. It has 
very good and the most sane API, which scales through all libraries 
well. Raising the bar on that level just doesn`'t allow you to 
use much existing code. It is always a dispute between making 
products fast and making a quality product which lasts. I really 
don`'t understand why people doesn`'t see the huge problem with 
`"Object`* o `= new Object();`" model, and why it is in almost 
every most popular language. That works in C`+`+ too, but it`'s 
just the most dicouraged way to used the language. Why Qt uses 
that extensively? Beats me... That only shows, that old habits 
sticks, and it doesn`'t look good for community afterwards.&]
[s0; So, I am almost completely disappointed about my brief comeback 
in Windoze systemz incorporated. While it tries very hard to 
be all`-in`-one solution in IT, it tends to be the most insignificant 
system for developers. Maybe that is why their phone sucked so 
hard... M`$ is the reason why my PC hardware is so affordable, 
but that`'s all.&]
[s0; ...&]
[s0; Hmm... maybe the program was just too big. There`'s no problem 
if it runs only partially. AMP programs usually are very small, 
and this is rather big.&]
[s0; Damn. This actually should be programmed in C`-style, where 
you get `"this`"`-pointer in the GPU memory. I mean, this is 
currently better, but unsupported, but if I want to get this 
work, then I should do that. Otherwise calls just take too much 
resources.&]
[s0; ...&]
[s0; Damn. I tried hard but I couldn`'t save it. It just didn`'t 
work out with AMP. The threading point was too close to the root, 
and the processing limit exceeded easily. Midway threading would 
have been good, but it would have had blocks and difficult if`-else 
handling, so it would have been too ugly. The most close to leaf 
`-threading did so much data`-transfering between CPU and GPU 
that it did not speed up anything. So basically, OpenCL should 
be used. It will actually work as`-is in FreeBSD too and no separate 
GPU version will be needed. So that is now in the TODO list, 
but I am helplessly out of time with this. New courses start 
at next week :S&]
[s3; 3.9.2017&]
[s0; Looks like next release is coming... I think it`'s time for 
my rant, or `"my life in short`" text.&]
[s0; ...&]
[s0; Seems like nobody is responsible. Clearly, electric universe 
theory beats the Einsteinian world, where most of us lives. Climate 
change is bullshit as described by electric universe theory, 
but environmental damaging is real. History is completely falsified 
as you can see from what power religious groups holds and what 
kind of lies they can tell about 9/11. There are real conspiracies, 
what have been exposed officially after tens of years, which 
proves that they exists. There is speculation about current conspiracies. 
Some of them might be true, we don`'t know, but we will know 
later, at least some of them. What can be said certainly, is 
that we live in the world of deceiving for profit.&]
[s0; The real history is probably something as described by Fomenko 
in the New Chronology. We are very close to repeating that research 
with A.I and in socially acceptable way. Fomenko`'s research 
clearly has some smell of being beyond the iron curtain. The 
life on earth might be a shorter than currently official chronology, 
which by the way have actually very real holes in it, even without 
going to that how fucking insane some of those religious stories 
are. The current state of our story is not in automatically verifiable 
format, which is a very good sign that there is no real sanity 
check for the description of our reality. That could be done 
in very standardized way with neural networks etc. , but religious 
leaders knows what holes their history holds and are against 
doing it automatically.&]
[s0; In Finland, we have people, who have had spoken history about 
our country and it is offically ridiculed and thought as `"corrupted 
by generations`". It is very different from official, but matches 
to Fomenko`'s chronology more closely. Of course, spoken history 
has very much data corruption, but if you check some relations 
without taking into account claimed times, then it seems more 
valid.&]
[s0; Very few understand virtual neural networks and their potential 
currently. People don`'t understand how they can be used to match 
complicated sensor images. They are like probability functions, 
but much more flexible. There is a great gap between `"pure mathematical 
statistics`" and neural networks, but it shouldn`'t be like that. 
Old school ways have much more accumulated investements now, 
but it could change at some point.&]
[s0; The best sign of the insanity is that religious stories can`'t 
be ridiculed for their insane content, but everyone must fear 
of hurting someone`'s feelings about stating the obvious. I don`'t 
think this is good for religions in long`-term. It is just a 
big elephant in the living room. They just should recuse themselfs 
in dignity as the culture advances.&]
[s0; [* The legacy of post`-war education is almost toxic waste.]&]
[s0; I`'ll start from my own experience. I taught myself computers 
and programming languages. I had actually no help from anyone 
at all. Not even a little bit. Not even that much that anyone 
could get an excuse. None. Okay, so I followed anonymously Internet 
tutorials, so they helped, but in traditional sense: none. Having 
military experience improved me to get grip of myself, but even 
that wasn`'t critical.&]
[s0; I have found, that best way to complete an assignment in honestly 
teaching way is to have a collection of small blocks what you 
can copy to your assignment. Then you add small changes and eventually 
you get a new block to your collection, which also visualizes 
your learning. I completed most of my university math and physics 
courses in this way after getting helplessly stuck with their 
version of learning. I don`'t even try to get courses passed 
in their ways anymore. Now they are just more harmful than useful 
for me. It is just shame that this takes more time for me than 
for others, and I can`'t get other schoolfriends to work with 
me.&]
[s0; I think that problem is that traditional education institution 
fears that collection of small usable blocks. They might think 
that it gets too easy to pass courses, when in my experience, 
is it just faster and more pleasant learning. The intuitive API 
also plays a big role in it. Those blocks must actually fit to 
other blocks without much effort. Ultimate`+`+ is a great example 
for well fitting blocks and much of the old codebase can`'t be 
used in that way, or they must at least be wrapped in more intuitive 
API. Old codebase blocks are huge compared to these API blocks. 
They see the application package as the target of polishing and 
not actual code of classes. I am talking about much more fine 
polishing of the API. Also, static types are important and no 
weird one liners... Nice big chunks and with the additude that 
nobody gets hurt by writing `";`" characters or types etc. Nothing 
should be left to reader to imagine. Also, hungarian notation 
is just insane brainfuck and people who use `"Object`* someObject 
`= new Object();`" should just be locked up somewhere. Just kidding...&]
[s0; The education should support individual learners more than those 
who go in groups. Nowadays, you can connect people via Internet 
and you don`'t need others to hold your hand. What you still 
need is financial support for your education and a freeway for 
your own personal learning without useless resistance. It`'s 
currently opposite of that and having university degree is a 
politized group learning experience, which it shouldn`'t be. 
I don`'t even want to think what my `"political view`" should 
be. There are different topics and I want to have my opinion 
about every topic separately without being labeled as some color 
of `"believer`". Those who label themself usually have pre`-determined 
opinion based on their cult and they haven`'t even bothered to 
reason their opinion based on their own experience. Actually, 
those political cults are so harmful, that they prevent you to 
change your opinion easily and it`'s probably even force`-fed 
to many anyway. You don`'t need any politized illusion about 
the world.&]
[s0; Actually the problem lies exactly there. Half`-monkeys imitating 
others and no`-one can reproduce the result alone. Religions 
love to hate speaking about the relation to monkeys, and I love 
to remind about the monkey humanity with big brains. That is 
the part what I like most in the official chronology.&]
[s0; What comes into my life and experience in this settlement of 
cold`-climate surviving religious factory half`-monkeys, it`'s 
been a challenge. My childhood was very happy and we played a 
lot in the park with girls and boys and many families had IBM 
PCs and we played with MS`-DOS and Windows 3.11. Nobody had internet. 
We were poor, however, and my single`-mother was very sick sometimes. 
We did not have money for clothes and we got donated clothes 
from neighbours. I was never bullied, but it wasn`'t far. I liked 
to ski and my best medal was 2nd in the school`'s competition. 
We were playing ice`-hockey at winter and rollerskating floorball 
at summer. What I didn`'t like was these dancing events, were 
I was almost forced to dance with girls. I was just very shy 
and didn`'t feel like it. It was clearly what girls liked more. 
I felt like my friends were stolen to that culture, but it actually 
did left very strong response to opposite sex to me, too, which 
was common.  Our family moved, and my old friends left there 
to continue that culture with teen`-age drinking and smoking 
in home`-parties. The new place didn`'t have that girls`-and`-boys`-dancing`-toge
ther culture, and I felt lucky. There was less competitive sports 
and we had much stronger PC gaming culture there. I started to 
make games with The Games Factory with one of my friends. We 
moved again and I changed school, but my friends from that place 
stayed for very long. I felt the lack of opposite sex at that 
point really hard, when my oldest friends were at doing a lots 
of home parties and drunken relationships. In my new place me 
and my friends found sober kissing in a group via truth`-or`-dare, 
which went to be epic dare thing... I can`'t even remember which 
girl I kissed first in my life. I`'ll never forget the talk with 
guys after that. We were literally kissing same girls all evening. 
That was once`-in`-a`-lifetime moment. Just beautiful.&]
[s0; I think time around that was a peak social experience for me. 
I was middle of very different social groups, and none of them 
felt my own. Well, my first relationship started around there 
too, and it sucked so hard... it was totally fucked up thing 
from her side and it did left long`-term damaging effects to 
me. She found me via facebook`-of`-the day. That was the closest 
thing to facebook before facebook arrived here. I don`'t even 
know what I was doing in that social service, but that was very 
popular thing between my oldest friends. So we were very close 
to the city center and very close to the dark stuff of the city 
and she was a bad smoker and drinker. She was also very dumb. 
Do I need to say more? It was also beautiful at the beginning, 
but she started to be like friend`-for`-life and I was like friend`-for`-year, 
and she was emotionally abusive and manipulative. She had some 
weird diary which she didn`'t let me read, but it contained some 
very non`-realistic descriptions of me. I had been watching porn 
many many years before that and she literally went nuts about 
me liking porn and about she being ditched because I didn`'t 
want long term relationship with her and just liked to watch 
porn sometimes. Needless to say, me and my oldest friends were 
huge porn fans together, so in my books she was the outsider. 
She actually found the dark substances of the inner city in those 
times and at the separation she actually had to be locked to 
the nut house. 2 weeks before that was hell... I had to forcily 
prevent her from jumping from bridges and buildings, and last 
time she went to frozen lake and I had to swim her out of it. 
Her parents were alcoholic and didn`'t care, but at that point 
they finally took responsibility, but only to be found by me 
that they completely lied about the whole story. Basically I 
was the bad guy for them, for their friends and for doctors too. 
It was already 100% fucked up story at that point, but there 
was more to come, a lot more. The correct solution would have 
been to call police for her, but I was completely clueless at 
that point.&]
[s0; She was at that point almost alcoholic like her father, and 
she was drinking at the city centre, and sometimes me and my 
friends were drinking there too. Me and my friends had got some 
mild warning messages that she is telling some very bad stuff 
about me to people, but we didn`'t consider it to be nothing. 
Well, first of May when everybody was at city centre, few guys 
came behind of me and did hit me to face with beer bottle. I 
got 15cm (5.9 inches) ragged scar to my face, but luckily escaped 
by running. I didn`'t connect that event to that girl even at 
that point, and nobody else too. It was very confusing... People 
just accepted `"random violence`" story too easily. After year 
or so, I had to go to mandatory military. There were a lot of 
folks from our city, and few of them I recognized. There were 
many who had connections to the inner city opioid and meth circles. 
Some of my schoolfriends had been close to them too, so that 
is how I knew. And I mean there was those who just didn`'t do 
much else than laying in bed doing hard drugs and then circulating 
them. Maybe something good can come out of the living way like 
that generally, like Red Hot Chili Peppers, but I don`'t know... 
So, unfortunately, there was some who recognized me as the ex 
of that girl, and then it got even a lot worse... they planted 
some rumors that I have been raping that girl and a lot of other 
evil stuff. Turned out that my leader also heard those, and basically 
asked me in front of all my peers, that was I in `"that place 
in that time`", and I accidentally said yes, because I didn`'t 
understand and they didn`'t tell me the context, and after that, 
everyone thought that those rumours were true. My leader was 
actually those who said many times that he would beat non`-white 
people if had a chance, and air force actually hired him to train 
next rookies. Yeah, pretty fucked up at this point, but wait, 
it gets worse. So, I got off from military, and even at that 
point I didn`'t actually know what those rumours were, because 
those fucked up nazis were actually that fucked up, that they 
didn`'t tell me. So, my sister`'s house got sprayed by `"rapist`'s 
sister`" tag and my house with `"sick`" tag, and I still didn`'t 
have a clue. Some of my ex`-girfriend`'s (the troublemaker) musician 
meth`-head friends, which circulated a lot of drugs, and could 
have provided me, if necessary, tried also to make me to make 
some orders from tor`-network. I didn`'t have a clue even at 
that point. Only, when finally, my ex started to `"settle down`" 
and her latest `"big dick boyfriend with money`" came to `"get 
even`" with me by giving death`-threats and threats about coming 
to my apartment to beat me up, I got clue, that she was STILL 
insanely angry to me... about me watching porn.&]
[s0; And with that, I`'ll leave you to ponder, that what is really 
fucked up in the world...&]
[s0; Without that episode overlaying the reality, I`'ve been just 
watching porn and almost never getting laid, because girls are 
too difficult, too not`-my`-type, too hard to find, or too religious, 
and nobody is helping me to find anyone. That Tinder culture 
is not helping either. What is actually more body shaming than 
that. What I want to know, that what kind of positions you like, 
do you like your pussy getting licked, do you take blow`-jobs, 
what is your endurance, can you max 3 ours with foreplay and 
breaks if at that mood, are you sensitive to accidentally disgusting 
stuff. Just kidding, again... I mean, are you sad for life, or 
can you just enjoy spontaneous romantic background music and 
snuggling between sheets for hours, if felt like so, and how 
often you feel like so? That one face picture judging all that 
is just an insult. I, as a long term porn viewer know, that one 
should always separate the visual part and the real thing... 
but it seems that many have hard times doing that. I`'ve never 
succeeded in making something soft and sensual from something 
hard as a rock, and I don`'t think I`'ll ever will. Some sex 
tapes, like few of Lisa Ann, actually reminds me of the real 
love making, but most of the porn is just cold exercise. They 
are interesting in non`-realistic ways.&]
[s0; ...&]
[s0; Back to the development... It was difficult to tune Joiner class 
properly, but it might work now. If not, I have some other ideas 
too.&]
[s3; 5.9.2017&]
[s0; I overslept the first day of the semester. I swear I did set 
the alarm clock... I did wake to some positive results, however.&]
[s0; Only Joiner was buggy. I tried to combine the signal (Agent) 
and the amplifier (Joiner) parts, but it`'s not working at all. 
After that I just improved the Joiner to do exactly the amplifying 
function for corresponding agent.&]
[s0; I need to fix the c`-array `[`] operators away. It`'s just dangerously 
unsafe. I checked them all, but what about after next modifications?&]
[s3; 7.9.2017&]
[s0; I noticed, that some stopper agent would be usable. One for 
every symbol and one for the whole group. That would only train 
for stopping useless losses and it gets it`'s reward for that 
how much it prevented losses. However, then one symbol in group 
has 3 type of dqn`-agents and those should be joined together 
for simplicity. Naming should be reconsidered, also. Current 
names are just the legacy of the older code. I think, that I`'ll 
use `"Signal`", `"Amp`" and `"Fuse`" terms, because they give 
instant corresponding image for eletrical engineers at least. 
The signal part gives `-1,0,`+1 outputs. The amp part amplifies 
that signal with some integer multiplier. The fuse part switches 
all off when a harmful current of value is recognized. Very corresponding.&]
[s0; I`'ve seen some very positive results, but I noticed, that the 
stopper or `"fuse`" might be critical to not allow the returning 
negative trend, which actually comes in the latter part of the 
lifetime of orders now. I can`'t emphasis enough, that this clearly 
benefits greatly from separating the roles of agents instead 
of doing one super agent.&]
[s0; ...&]
[s0; Seems like few other fixes got along with new changes. The return 
value for DQN`-agent had to be, of course, average per smallest 
time`-step. Otherwise the agent prefers the longest time`-step 
always. I think I got enough assertions and cross`-checks that 
it will work or crash, but not something in between, in pretty 
good probability. I must still change the program to use try/catch, 
so that user gets a friendly message if assertion fails. It`'s 
bad, but less worse than no explanation.&]
[s0; This took a while again, but school work didn`'t really start 
this week yet... I am really looking for a cold beer and company 
after this. I think I should meet some pretty freshmen women... 
Campus was so crowded this week... Oh, that pretty girl who always 
slips away...&]
[s0; &]
[s0;= [/ It`'s more than a feeling, when I hear that old song they 
used to play (more than a feeling)]&]
[s0;= [/ I begin dreaming (more than a feeling)]&]
[s0;= [/ `'Till I see Marianne walk away]&]
[s0;= [/ I see my Marianne walkin`' away]&]
[s0; &]
[s3; 8.9.2017&]
[s0; I am going to release v0.3 today and add this little text to 
it as a PDF. I now it`'s silly, but I think it`'s like putting 
a message to a bottle and throwing it from a ship. It doesn`'t 
really matter to me, but might cause some interesting responses. 
Who knows...&]
[s0; It`'s been REALLY exciting to chase the profit with this. Almost 
anyone here doesn`'t understand it, but one who might find this 
software in the Internet, might actually understand that excitement. 
I am not posting on forums, because people there only understand 
classic MQL indicators, scripts and EAs, not something as Frankenstein 
as the Overlook. This barely works and requires advanced user 
to use. I read forums but don`'t really say anything there... 
because I don`'t have anything good to say.&]
[s0; ...&]
[s0; I have still the last tasklist to do.&]
[s0; One interesting detail: agents in one group could use the same 
broker. Now they just repeat the same calculation by copying 
signals of other agents to their own instance of the simulated 
broker. There is just one expensive problem preventing them to 
use the same broker instance: the threading point. We have rather 
high costs in starting of new threads and we lower it by doing 
more in thread at once. Threads could do only one timestep, and 
the main thread could process the simbroker after that, but the 
cost of syncing to the main thread and then restarting processing 
in threads is just too much. So agents will do some repeating 
calculations instead of the threading overhead. I haven`'t measured 
the difference, but I have some experience about the threading 
overhead, and I am pretty sure it`'s a lot cheaper in this way. 
Also, I can avoid work before release and the repeating calcuation 
might actually be very cheap.&]
[s0; ...&]
[s0; The app would be now in new beta version release state, but 
I didn`'t have enough time to test this today. I added external 
M1 data source and now Overlook has massive amount of training 
data.&]
[s0; Release works now again after finding hard`-to`-find bug. It`'s 
amazingly fast.&]
[s3; 10.9.2017&]
[s0; I trained the full signal/amp/fuse stack, but encountered some 
problems. Before this I removed 0`-signal from signal and amp 
parts, so that fuse part can only zero the signal. This prevented 
training to do only idling in some difficult cases. The problem 
was, however, that I tried to exploit the accurate model to make 
the system faster, instead of adding randomness in the sampling 
to allow little differences in the data, which is researched 
to increase the quality of the result in image recognition applications. 
ConvNet examples can show that by doing `"image augmentation`", 
which takes random smaller part of the image. This improvement 
is extremely small part of the code, but makes a huge difference 
to the result.&]
[s0; Almost all improvements currently are like very small details 
in some large mathematical equation. They mean a lot but are 
difficult to find.&]
[s0; So, I reduced the number of symbol groups to one, but increased 
(3x times) the amount of hidden neurons. The estimated computing 
time stayed same or increase a little. I limited signal periods 
to those, which worked well in the previous model (around H4, 
H8, D1) and then a little more sensitive amp periods (around 
H1, H2, H4, H8, D1) and then even more sensitive fuse (M30, H1, 
H2). This is still far from high frequency stuff, and I haven`'t 
had a single clue how this could work in the faster than1 hour 
trading.&]
[s0; One idea for scalping trading would be that you would limit 
the potential area with the first agent`-level, and then the 
second level would limit that even more, and the third level 
would make the decision to trade that or not. The difference 
to the current model is that you would give the absolute value 
of the current reward as the reward. So few levels would limit 
that absolute`-value`-reward to the maximum and then the last 
would only decide that will it do long or short.&]
[s0; So yeah, I have currently a nicely working slow model, but I`'ll 
exchange it immediately to this new idea to avoid losing time. 
Just minimizing the response time to the priceless...&]
[s0; Wait... I still need the amp and fuse part after that, so those 
time slot agents go before current parts. Ok, so it`'s not about 
exchanging anything, but about adding something...&]
[s0; Hmm... it`'s like the current `"fuse`" part needs to be BEFORE 
signal, and not after amp, and there should be many pre`-fuse 
parts. By the way, those stop`-loss/take`-profit mechanisms should 
be the real `"fuse`".&]
[s0; ...&]
[s0; I found bad bug again. Obviously agent is not allowed to train, 
if it exports 0 signal because input signal is 0.&]
[s0; ...&]
[s0; Hmm... I didn`'t expect to find so many bugs today... They were 
very hard to notice.&]
[s0; &]
[s3; 11.9.2017&]
[s0; Man this place is retarded. Those rats made a graffiti with 
text `"METH`" (but in Finnish) next to a elementary school in 
the city centre, and still they won`'t clean it up in years. 
This people is that clueless. Those rats should be considered 
as insane, like in Japan, and locked away in an asylym if they 
get caught.&]
[s0; That cluelessness reminds my of my military bullying, where 
I was completely clueless. One event was the last war exercise. 
We had irregular sleeping hours with wake to sleep ratio around 
20:4... changing campsite every day based on HQ place. I got high 
fever and no bail out. It was sort of fun, though, in some not`-completely`-sane 
way. Well, I told you already, that many men were against me, 
because those insane rumours were circulating. I was extremely 
exhausted at the point when it was ending, and just before we 
got finally to shower and bed, we got some unexpected check, 
where you had to show all your belongings. We never had those 
before, and it was suspicious. Well, I knew I didn`'t have a 
problem, expect that I did. Somehow, I found unopened box of 
ammo in my backbag. They had said, that they would punish anyone 
very hard, if someone found out to have exactly what I did. I 
went to those unit leaders and handed out those ammo. They looked 
me very angrily, and I was very clueless and too exhausted to 
say that I was clueless. I didn`'t knew about those, I had checked 
my backbag many times, and I do not remember even getting any 
of those. Anyway, they didn`'t punish anyone anyway, which leaves 
me wondering, if that was a set up. I believe it was. The situation 
at that point was so bad, that even my `"leader`" would have 
conspired that sort of bullying and dishonoring against me.&]
[s0; ...&]
[s0; Signal training seems very good now, but amp part had problems 
because too few symbols were opened simultaneously.&]
[s0; Seems like the time is filtered very extensively for the peak 
activity now. The remaining time should be used too. I guess 
that many groups could be used with the higher priority for faster 
group. &]
[s0; ...&]
[s0; I did the changes, but the amp is still behaving in a weird 
way. &]
[s3; 12.9.2017&]
[s0; It`'s difficult to find a solution for that weird amp problem. 
It`'s incredibly weird... the epoch result graph has some weird 
oscillation for some unknown reason. It might be because of some 
standing wave `-like effect what the relatively small experience 
buffer causes. It`'s like a very low frequency square wave, where 
it have phases of failing and succeeding after each other. It`'s 
the weirdest bug I`'ve seen so far. It happens after resetting 
again always. Well, it`'s not exactly failing, but a lot worse 
performance.&]
[s0; I got an idea for an improvement, in that the`-last`-piece`-that`-fits`-the`-puz
zle way. Let the amp multiplier acquire some fixed portion of 
the available margin and it doesn`'t matter if other instruments 
are present in the training... because they will get that same 
portion in the real operating mode. How obvious is that... but 
only after you got it.&]
[s0; Ah, it`'s might be just that randomization for time`-steps, 
which creates short losing periods to amp because of mis`-alignment 
in time. Only filter can have that randomization and the signal 
and the amp parts must have the same alignment. Yes, that mostly 
fixed it. Also, I forgot to clear orders when signal is zeroed, 
and now the signal and the amp parts must be re`-trained again.&]
[s0; ...&]
[s0; No it wasn`'t fixed... fuck... it was a stupid technical limitation, 
which caused the agent to learn a no`-reward state in the high`-end.&]
[s0; ...&]
[s0; Still no luck. This is a total [/ what the fuck] situation. The 
oscillation ended: it has the first successfull cycle and then 
the failing part never ends. It`'s total opposite of learning 
the reward. I have no clue what causes that... Filter and signal 
parts works fine, but the amp is just freaking out.&]
[s0; I just need moar diagnostics.&]
[s0; ...&]
[s0; A`-ha. Finally? That fucking bug was in every fucking layer 
except the first. The zero`-signal did cut some periods to shorter 
and the reward was divided by estimated timestep, not actual.&]
[s0; And yes, I have to start the whole fucking training all over 
again. [/ `*sigh`*]&]
[s0; [/ ...]&]
[s0; I`'m not sure is that fixed now. These fixes certainly affect 
the whole stack and that failing might actually be training glitch.&]
[s0; &]
[s3; 13.9.2017&]
[s0; Hmm... one possible explanation that previously mentioned weird 
oscillation could be, that the experience buffer for training 
is too small and it`'s filled in non`-uniform way causing training 
to wobble from one sample`-area to another. The fix for that 
would be to fill the training buffer evenly from the larger sample.&]
[s0; I did some calculations and it seems that non`-uniform sampling 
did happen. In some cases, the learning was greatly biased to 
local data instead of whole data. We`'ll see if that weird oscillation 
is fixed... but then I can`'t say what fixed it :)&]
[s0; &]
[s3; 14.9.20&]
[s0; Still no luck. So, in amp`-phase training reward graph and epoch`-result 
graph shows this weird oscillation, where failing and succeeding 
phases takes 3`-10 minutes. It happens in every agent. They all 
have it at exactly same time (same frequency and phase). It reminded 
me to reduce the learning rate linearly as getting closer to 
the end of the training, but even that won`'t solve the problem.&]
[s0; I just must test to tweak some settings. This is going to be 
expensive...&]
[s0;i150;O0; 1. test: the free`-margin`-level doesn`'t affect it.&]
[s0;i150;O0; 2. test: it happens even with fixed `+1/`-1/0 signal, 
like in the signal`-part...&]
[s0;i150;O0; 3. test: it happens even with seemingly identical agent 
to SignalAgent&]
[s0;i150;O0; 4. test: it happens even when FixedSimBroker is changed 
to SingleFixedSimBroker&]
[s0;i150;O0; 5. it does NOT happen, when SignalAgent is cloned to 
replace AmpAgent&]
[s0;i150;O0; 6. it DOES happen, when SignalAgent clone uses Amp actions&]
[s0; So yeah, the problem of oscillation is limited to this piece 
of code:&]
[s0; [C0 -|-|const int maxscale`_steps `= AMP`_MAXSCALES;]&]
[s0; [C0 -|-|const int timefwd`_steps `= AMP`_FWDSTEPS;]&]
[s0; [C0 -|-|ASSERT(AMP`_ACTIONCOUNT `=`= (maxscale`_steps `* timefwd`_steps));]&]
[s0; [C0 -|-|]&]
[s0; [C0 -|-|int maxscale`_step-|`= action % maxscale`_steps;]&]
[s0; [C0 -|-|int timefwd`_step-|`= action / maxscale`_steps;]&]
[s0; [C0 -|-|]&]
[s0; [C0 -|-|prev`_signals`[0`]-|-|`= 1.0 `* maxscale`_step / maxscale`_steps;]&]
[s0; [C0 -|-|prev`_signals`[1`]-|-|`= 1.0 `* timefwd`_step  / timefwd`_steps;]&]
[s0; [C0 -|-|]&]
[s0; [C0 -|-|int maxscale   `= 1 `+ maxscale`_step `* AMP`_MAXSCALE`_MUL;]&]
[s0; [C0 -|-|timestep`_total `= 1 << (AMP`_FWDSTEP`_BEGIN `+ timefwd`_step 
`+ group`_id);]&]
[s0; [C0 -|-|]&]
[s0; [C0 -|-|signal `= lower`_output`_signal `* maxscale;]&]
[s0; I don`'t have a clue why that code causes that slow oscillation 
in every agent.&]
[s0; I try to set only constant 1.0 to that prev`_signals sensor... 
that`'s the only part which transmits output data to input of 
next time position. Pretty reasonable...&]
[s0; Nope. It still occurs. Let`'s do a sanity check. Let`'s copy 
the signal actions back overwriting that previously mentioned. 
Yes, everything is normal with that. I really need to start to 
speculate the problem exactly in that code position. So, maxscale 
shouldn`'t affect anything, because SingleFixedSimBroker checks 
only >0 and <0.&]
[s0; ...&]
[s0; Finally, the point of sanity. The amp`-module, which was cloned 
from signal`-module, is giving the identical output with constant 
1x multiplier. Obviously, I would start working on this in this 
way if I ever had to do this again.&]
[s0; Hmm... except that it turned immediately to the point of chaos. 
It start with identical signal, and then the weird oscillating 
problem starts again. This is just madness. This definitely should 
give only the identical graph to the signal module now. I definitely 
got the clearest view of the problem so far.&]
[s0; So the problem is now to get the amp`-module produce the identical 
output to input with 1x multiplier.&]
[s0; I had to repeat this test few times to by sure, but that `"`* 
maxscale`" is that what causes the oscillation. I can`'t find 
the leak where that is meaningful... &]
[s0; ...&]
[s0; And it is solved. It was a fucking expensive typo. That doesn`'t 
really surprise me or anyone.&]
[s0; This is sort of embarrasing, but I managed to fix some bugs 
on the way, so it wasn`'t a total loss. This is also a good reminder 
how expensive these bugs can be. This kind of problem could be 
avoided with the team work and peer`-reviewed commits, but unfortunately 
I am far from those with this project. One improvement was especially 
good: reducing the learning rate increases the quality as you 
can in see the ConvNet painter example. That improvement might 
directly reduce lossess now.&]
[s0; The [C maxscale ]multiplier trigged the problem, because amp and 
signal was using the same memory slot and the value was identical 
as long as multiplier was 1. That`'s so obvious afterwards...&]
[s0; ...&]
[s0; I think I`'ll write a rant about over`-simplifying yellow lightbulb`-heads. 
About those who use a lot of words `'believing`' and `'forgiving`' 
and like to watch sports and have a fight club attitude against 
everything, even when their new claim is contradicting their 
previous claim. Those who trust simple visual symbolism and has 
empty feeling without different substances... Those who live 
in a read`-only mode from the happiness of the youngness to the 
bitterness of the oldness. Those who think that oldest economic 
models or new cryptocurrencies works... It`'s not a specific 
group, but a collection of traits what we all have. In a old 
and mysterious voice: [/ during your lifetime, there`'s nothing 
more valuable than breaking the yellow illusion...]&]
[s0; [/ ...]&]
[s0; What a fucking fat`-finger I was at this week.&]
[s0; &]
[s3; 15.9.2017&]
[s0; I finally got the whole stack up and running in realtime today. 
The performance was positive, but there was some faults. I noticed 
again the lack of `"fuse`" part. I really don`'t now better naming 
for that. The pre`-filtering of time ranges doesn`'t really fix 
that at all, even though that was derived from the previous `"fuse`" 
effort.&]
[s0; It`'s difficult to get that fuse`-part right. It can`'t have 
the same reward function as the signal or the amp. My current 
suggestion is to follow a drawdown of short changes during the 
action. The reward could be the change of the drawdown, because 
that shows the accumulation of losses in relation to gains, which 
is what we want to prevent. It must also be sensitive, so pre`-determined 
timesteps can`'t be used. Instead of timesteps, ranges of the 
drawdown can be used. When the drawdown indicator breaks the 
channel range to up or down, then the action ends.&]
[s0; &]
[s3; 19.9.2017&]
[s0; The result changed much and I don`'t know what caused it. It 
must have been because of some small change. The reason might 
be longer timesteps in that previous invalid setup. I guess you 
should increase timesteps if drawdown is too much. In that way 
the system optimizes itself to less volatile periods. For busy 
times the current configuration seems to work.&]
[s0; This is just a pain in the ass to train all over again...&]
[s0; &]
[s3; 22.9.2017&]
[s0; So much small details...&]
[s0; I didn`'t get the training to pass, because something had to 
be changedd constantly, which required restarting the training. 
Last that kind of change was, that those agents which had slow 
dynamic timestep didn`'t get enough training. I just fixed it 
and restarted training.&]
[s0; I didn`'t get this running in the whole week even once without 
pending restart. Week ago I started and thought that I would 
get this running at monday, but no...&]
[s0; I tested, that extra sensors actually gave worse result. Without 
sensors, 15 worked with less than 3 extra timesteps, and with 
sensors, only 8 worked in the same limit. Extra timesteps are 
bad, and it`'s a big measurement number. One timestep increase 
requires 40000 iterations with failed result. That was also a 
huge processing time consumer, so luckily that can be avoided.&]
[s0; Allowed forex pairs are hardcoded to the program. We all have 
those same pairs in use, and with other pairs you get problems, 
like not getting long`-term data or costs are too high. One could 
limit that group even more, if broker has too much spread in 
some of those instruments, but agents actually has sensors for 
other instruments, so they can be used in that way also. Those 
costly pairs are affecting each other in the real world, so it`'s 
still a sensible feature.&]
[s0; The new graph, which shows how different filters were activated 
during last week, is very cool. It can also show red/blue colored 
signals, if you click it. You can see, that the busiest filter 
activated with different agents in the same time often.&]
[s0; This is in the release state currently. I think I`'ll upload 
the v0.3 release later this evening.&]
[s0; &]
[s3; 25.9.2017&]
[s0; The `"fuse`" agent did not work well. It did reduce drawdown 
with some instruments, but the cost was too high and average 
drawdown was higher. Seems like copying the `"amp`" agent and 
changing multiplier to on/off switch might be more reliable. 
After that change, all agent parts are very similar and should 
be combined to one class to avoid small bugs. It reduces the 
size of the code overall and makes the porting to OpenCL version 
easier.&]
[s0; Yesterday, I removed the group`_step variable, but the need 
for it occured again after training. It was used to give `"more 
patience`" to less volatile times. Setting it by hand is not 
good, but automatical adjustment is difficult.&]
[s0; ...&]
[s0; I tried to simplify the theory behind the current implementation, 
because it actually changed with new additions to the code.&]
[s0; So, the idea in the system before the amp part is to train the 
agent to be active when it sees it`'s assigned volatility and 
signal in front of it. Currently, the implementation is a mess, 
when considering that theory. Currently, the system filters the 
time to volatility ranges and then tries to guess the direction.&]
[s0; But when you try to implement that revised theory, things get 
complicated. This takes too much resources, if every agent is 
forwarded every minute to check if it`'s channel is activated. 
The current implementation might actually be close to it anyway.&]
[s0; ...&]
[s0; Oh, obviously filter parts can now be replaced with very efficient 
indicators. The filtered step is to move from slower and less 
volatile time to faster and more volatile and vice versa. Different 
directions (long/short) can be filtered separately. Minimum change 
of value can be required, which can be rewarded with a constant 
value. Timestep is balanced to volatility in hard coded way, 
which requires different training and testing.&]
[s0; ...&]
[s0; Damn. Everything broke when I tried to replace those filter 
DQN:s. I don`'t like this. I had to revert changes and take the 
more conservative approach with less changes. I am not sure why 
this works currently in the training so well. When I go into 
details then I lose the working version. I guess I should make 
some clear blueprints and refine the theory. I knew already that 
this method has apparent flaws.&]
[s0; In the end, I only added some small changes to tune down drawdowns 
and to make processing a little faster. I simplified the fuse 
part to be more robust also.&]
[s0; &]
[s3; 27.9.2017&]
[s0; Ah, the volatility sum should be used as counter instead of 
the time. Enough said.&]
[s0; &]
[s3; 28.9.2017&]
[s0; Ah, both the time and the volatility sum should be used as counter. 
Target values should be known and euclidean distance to it should 
be calculated. Getting target values needs some statistics and 
k`-means etc. It will be similar to the current setup. The whole 
configuration of agents can be done in more intelligent way at 
the same time.&]
[s0; ...&]
[s0; Hmm... I am repeating that completely failing idea all the time. 
I must say `"no`" to myself. This must follow the current setup 
which works. Closest thing to the current is to sample some important 
reward correlating values, then find 2 cluster centers with k`-mean. 
Repeat that around found centers to zoom. In that way, filter`-dqn 
agents learns to tell which cluster center is closer. It`'s a 
repeating mistake to not fill the whole time with at least one 
binary classification.&]
[s0; I took a dump and thought, that maybe both reward and action 
should be only about which cluster center is closer. You could 
actually get continuous `"zooming`" to all binary or short integer 
variables. That`'s just an idea, but it`'s interesting. Zooming 
would happen always, when backward a.k.a learning is unnecessary.&]
[s0; In that `"zooming`", idea is, that the previous `"zoom`-level`" 
has given correct answer. Currently, it is done by training the 
previous phase completely, but it also can be done in a way, 
that you use the correct action, instead of the agent`'s action. 
That would allow simultaneous training of all levels.&]
[s0; We are approaching the version, where the duplicate code of 
agent`-parts can be discarded... There is a lot of small improvements 
that couldn`'t be implemented to the current version. Now, even 
the theory part begins to match.&]
[s0; ...&]
[s0; Yeah... this pretty much requires clearing most of the current 
Agent code. That zooming part requires complete agent system 
overhaul and nothing new fits existing. It just screams a fresh 
start.&]
[s0; &]
[s3; 29.9.2017&]
[s0; So much going on in planning. If you use agent just to decide 
which pole is closer from inputs, then you can use past values 
directly and calculate distance to average cluster center inputs 
values. You can even use linear bit values (1 `-> 1 bit true, 
4 `-> 4 bits true) and Hamming distance to make the processing 
insanely fast.&]
[s0; ...&]
[s0; Much rewriting has to be done. Seems like DQN`-agent is unncesessary 
now. At least I`'ll try first cheaper algorithm. I follow previous 
version very closely, but even then huge changes must be done.&]
[s0; Currently, filter agents splits the data to sectors, but that 
will be improved by making cluster tree hiearchy with K`-mean 
algorithm. It will follow the current `"splitting into two`" 
method, and that creates sort of a `"zoom`" by selecting which 
cluster is closer to data position inputs. Basically, data position 
inputs are matched to output result space by seeking to poles 
which are closer to inputs. That is sort of a forward propagation. 
Some sort of `"learning`" or `"backward propagation`" is done 
by collecting statistics that which input gives correct next 
pole and which doesn`'t. That next zoom node selecting in nodes 
can be done with DQN`-agents and that is how it is being done 
in the latest version. Both techniques can be used (selecting 
the next zoom node by statistics or by DQN`-agent) and both can 
and will be tested with a separate testing data.&]
[s0; It`'s very early to tell about this yet. I am still confused 
about this method and about making DQN`-agents secondary. I`'ve 
checked many times, that these planned features should be an 
improvement to the current version.&]
[s0; The main strength of these planned features is that a K`-mean 
cluster tree with two`-branch nodes could accurately tell if 
currently identified cluster has e.g. likely long opportunity. 
It could be a fast way to find matching past data and to recognize 
opportunities of very probable outcomes. It is not a flexible 
solution to a unknown situation, but a fast and efficient method 
for recognizing certain outcomes as they come up.&]
[s0; To simplify to the maximum: known output (result) space clusters 
are approached step`-by`-step by comparing current inputs to 
average inputs of next 2 clusters. The found cluster is analyzed 
for opportunities. Also, the 2 cluster splitting could be used 
to recognize the right momentum (dynamic pending order) and to 
recognize the end position (dynamic tp/sl).&]
[s0; In the end, the DQN`-agent was just making a binary decision 
from input values and in this use case, ambiguous inputs can 
be ignored. The app should be playing only the safest option 
anyway... I guess, that if a pipeline can be implemented using 
only binary options, there is no need for any `"black box AI`".&]
[s0; &]
[s3; 30.9.2017&]
[s0; Things seems to get out of hand in a Rick `& Morty level mindfuck. 
That clustering can be done in many ways and with different count 
of branching (or just 1 level and many branches) and that data 
position can be thought to be in many different level of depth 
nodes at the same time. Also, data is considered to get closer 
to next branch center or to jump out of branch like a computer 
program. So the forecaster has huge amount of next possible paths 
from those matching branches, and those paths can be handled 
with simple probability calculations.&]
[s0; However, this whole plan can be simplified to a lightweight 
version, which is much less exciting.&]
[s0; ..&]
[s0; Whew... a lot of confusing journal text lately, but I finally 
found the most simplified plan and started implementing it.&]
[s0; &]
[s3; 1.10.2017&]
[s0; I ended up with much less exciting improvements. Filters are 
replaced with input cluster to output cluster matching and pending 
orders and tp/sl are done in a similar way. Surprisingly, VOR`-to`-VOR 
flying was a huge inspiration, as this kinda will have a distance 
calculation from pending`-pole to TP`-pole. The sending of an 
order is triggered while moving closer to TP`-pole from pending`-pole. 
It`'s sounds crazy, I know.&]
[s0; &]
[s3; 2.10.2017&]
[s0; I could write all upcoming changes while Bryan Lunduke is finishing 
his W3C membership fundrising campaign, where he streams 24h 
and now 11h is remaining.&]
[s0; &]
[s3; 3.10.2017&]
[s0; The official statement of Las Vegas shooting is logically invalid 
as long as some visual evidences are known to be valid: [^https`:`/`/www`.youtube`.com`/watch`?v`=gywc58Bxxc8^ t
he alleged shooter was in 32nd floor, but the video shows clearly 
that the shooting came from around 10th floor]  `[note: it was 
strobo light, nevermind`]. Was the floor statement an error? 
Was it black`-op distraction? Statements are contradicting visual 
evidence and everything is confusing. I had to download that 
video in case there will be political cheating.&]
[s0; There is extremely contradicting journalism going on. CNBC and 
New York Post reports that he made suicide after shooting, but 
Alex Jones reports having heard from hostage squad that they 
killed him while they stormed the room. Very different stories.&]
[s0; If you go into the conspiracy theories, the timing was correct 
to distract people from Catalonia episode in case someone wanted. 
Nobody actually witnessed that guy doing anything and he was 
already shot to head after the police came. Maybe the real shooter 
was a dumb dark operative tool guy in 10th floor taking insensitivity 
pills and doing it all from a command. In that case, traces would 
lead to big politics, big money and big illusion, but I don`'t 
know or want to know actually.&]
[s0; There is nothing making sense in the background story either. 
How could some old guy handle that much hateful aggression and 
target republican majority concert while himself going to those 
concerts often? It just doesn`'t add up. That kind of old man 
couldn`'t do that without chemical overdose of something.&]
[s0; Or maybe his doctor actually gave accidentally a prescription 
for some highly insensitiving medication?&]
[s0; Very sad event anyway.&]
[s0; ...&]
[s0; But back to the timing with the `"leftist`" Catalonia independence 
referendum. The shooter was targeting `"right`-wing`" people 
and `"had antifa literature in the room`" and the news week would 
have otherwise started with the main topic about police brutality 
and violence against `"leftist`" movement in Catalonia. So maybe 
that couldn`'t happen and they needed something else to be more 
interesting. This whole issue might be a showcase of insane global 
human resource handling by some outdated deep belief leaders. 
They are just asking for that wrong kind of transparency movement...&]
[s0; Super`-establishment`-friendly`-president might already be a 
discontinued product, which is actually a hidden common feature 
with the Trump movement and Catalonia independcy movement, even 
though it contradicts left`-right oppositions.&]
[s0; I don`'t normally write conspiracy theories like this in this 
journal.&]
[s0; ...&]
[s0; So I wrote most of the completely new code yesterday while listening 
to 24`-hour`-lunduke`-athon.&]
[s0; ...&]
[s0; The first version of the filter`-agent replacement system is 
now written and it runs without crashing, but there is some quality 
issues. I hope it`'s not because of faulty theory. I need some 
debugging widgets in GUI etc.&]
[s0; It`'s kinda bummer, I wanted this to run today.&]
[s0; &]
[s3; 4.10.2017&]
[s0; About previous post: that light in the video seemed to be some 
strobo light. I like especially this comment `"[/ one more time: 
THE FUCKING FLASHING ON THE 4TH FLOOR IS A FIRE ALARM STROBE.]`". 
To my defence, many others were mistaken too. I am out of that 
discussion now...&]
[s0; However, the  same stuff what I wrote yesterday is now in the 
top article and the most discussed topic in the [^http`:`/`/www`.zerohedge`.com`/news`/2017`-10`-04`/16`-unanswered`-questions`-about`-las`-vegas`-shooting`-mainstream`-media`-doesnt`-want`-talk`-a^ z
erohedge], so I wasn`'t wrong about that being interesting... 
It`'s actually just getting more fuel, because `"Stephen G Paddock 
(age 66) is listed at 7272 Ne 8th Dr Boca Raton, FL and is affiliated 
with the Democratic Party.`"... and it`'s pretty much right`-wing 
only forum. This is a epic pinnacle of last week`'s Antifa topics. 
Even republican`-like people `"come together`" somewhere (minding 
that it`'s a international forum). It`'s weird that I`'ve been 
reading that forum regularly since year 1. It doesn`'t feel like 
it. I don`'t agree many times with the content. Also, I kinda 
like university, but as long as you can work from home. It was 
very surprising to follow the time during Trump vs Clinton campaign 
via that forum. Everything was there first and the comment section 
is priceless.&]
[s0; Yeah, the events of that Las Vegas tragedy were probably just 
as sad as reported. Illusioned `"leftist`" taking heavy psych 
meds and deciding to get out of this world spectacularly and 
thinking that he makes some of his fellow `"leftist`" happy by 
revenging `"right`-wing`" people. There were already a lot of 
comments in the Internet, that `"maybe those people deserved 
it`". Sad.&]
[s0; The timing with the Catalonia stuff is just Weird Shit on Earth 
(TM). You know, these kind of news reaches most of the people, 
so there is some bigger forces playing.&]
[s0; ...&]
[s0; Much tuning of code at this point. Indicator sectors are connected 
too easily to the most common result sector. Values can be interpreted 
in a different way or connections can be limited to more specific 
areas. Maybe both.&]
[s0; I just found [^https`:`/`/www`.kiva`.org`/lend`/expiring`-soon^ kiva.org] 
site and I love it. You just want to loan more than you can. 
Man, most of those people asks only some farming, tools, seeds, 
fertilizers, utilities and buffer money. I had to loan immediately.&]
[s0; ...&]
[s0; Back to the Las Vegas tragedy. In some local forums, some doctor`-like 
people have already started to ridicule all `"consipary theorists`" 
how stupid them are etc. I just love ZeroHedge discussion compared 
to that ignorance. Many questions are valid, even if there isn`'t 
any foul play. Also, it`'s much more fun than being a all`-knowing 
ignorant prick.&]
[s0; ...&]
[s0; At early morning hours, I finally managed to get the previous 
state partially working. Some agents has zero signal in, but 
some works.&]
[s0; &]
[s3; 5.10.2017&]
[s0; I must reiterate, that I consider having clean hands ethically 
with this application, even though this is problematic in the 
large scale. I guess that any branding, advertising or search 
engine optimization would be questionable, but I don`'t see this 
passively existing as a problem.&]
[s0; ...&]
[s0; I`'ve been tuning this app today, even though I should do school 
things. I just want to get this to run at background so bad...&]
[s0; A lot of many new weird quirks with the tuning. I haven`'t done 
that `"pole navigation`" previously. This seems rather robust 
now.&]
[s0; ...&]
[s0; It runs. I`'m so happy. And there is still the busy part of 
the friday for testing in the realtime.&]
[s0; &]
[s3; 6.10.2017&]
[s0; Nope. Forgot the spread in the signal agent and there wasn`'t 
any resistance. Can`'t do that. Also, there is some difficult 
problem with the input`->output areas. Even when I tuned the 
system to connect always to at least 1 output, some agents had 
only 6 triggers in a year.&]
[s0; ...&]
[s0; When I first found Fomenko`'s chronology research, it was labeled 
only as `"fringe theory`", but after Trump won, it is now labeled 
as `"pseudo science`", even though it is serious science, very 
reasonably argumented and the author is a awarded math professor. 
Many pieces fits better in that chronology than in the official 
chronology, which has much more mystical speculation in relation 
to e.g. pyramids of Giza.&]
[s0; There is just one thing... if his team was right... the corruption 
would be absolutely mind`-boggling. It would be beyond wildest 
imagination. You just don`'t want to even try to imagine that...&]
[s0; That shit makes you wonder the space. How the real story of 
the existence of 7.4 billion humans might be a minor detail, 
an afterthought. In the final echo chamber of a potential life. 
The sky is blue in many other planets too, think about that. 
Would evolution generate almost same than us anyway at some other 
place? Are we just the North Korea of the Milky Way? Would you 
care to know that?&]
[s0; &]
[s3; 7.10.2017&]
[s0; Tuning ready. Going strong to next trading week. Oh, look at 
the date. Such a beautiful symmetry `"710  2  017`".&]
[s0; &]
[s3; 9.10.2017&]
[s0; The correct tuning of settings is insanely difficult to achieve. 
There is many factors...&]
[s0; Improvement idea: different length `+/`- targets... That might 
had prevented the slow release, which happened after the positive 
peak today. I`'ll do it right now.&]
[s0; &]
[s3; 10.10.2017&]
[s0; It`'s always safe to talk about the ethical equality. Like, 
everyone deserves cheap electricity and running water. That gives 
you the warm and fuzzy feeling about the better world. It`'s 
much more difficult to safely talk about ethical inequality. 
One easy example is, that people sentenced to prison don`'t deserve 
access to weapons, but most people in the military deserves it.&]
[s0; The much more difficult example is, that mild long`-term accumulated 
injustice and stress against specific group of people might deserve 
compensation, but implementing it might break illusions and beliefs 
of another group. Even more difficult are those, when there is 
webs of beliefs, what can be measured to be logically valid or 
invalid, but those beliefs are also holding economical structures 
and some groups are gridlocked to fulfill some invalid beliefs, 
just to upkeep economical structures of some powerful illusioned 
groups. The only option for many in those weaker groups is to 
hide individually, so that they won`'t be a weak piece in the 
losing game, making the group weaker than ever. That causes even 
more unethical inequality.&]
[s0; The Overlook, and similar software, (in completely working state) 
could be used to create ethical inequality in individual scale. 
It would have some negative side effects, but it could alleviate 
problems of the `"producer`'s view`", which have been known to 
be impractical and mostly long`-term unethical in the current 
state. In the end, it just creates a pool of fake high`-quality 
trash without no`-one handling it properly.&]
[s0; If the only thing required in life was ethical equality, then 
we wouldn`'t need politics, but the life is very different experience 
for each of us, with some peak similarities, like taking a shit. 
The many`-party political system probably fits best to the different 
needs of the people, because life is not about taking a shit 
always.&]
[s0; (Note: I didn`'t check this text at all)&]
[s0; ...&]
[s0; I wrote the Fuse class. This is 3rd time, but I think it sticks 
this time. Previous versions morphed out to be some parts in 
the clustering system. It checks the account equity and can learns 
(hopefully) to skip failing periods.&]
[s0; &]
[s3; 12.10.2017&]
[s0; The performance has been good today with current settings. If 
this continues, the core feature is ready for use.&]
[s0; The new fuse`-part seemed to catch the downward trend of balance 
and turned it up. The training was good also and it did hit some 
technical high limit of double floating point value. I skipped 
the testing part with unknown data and I`'ll just run the testing 
in real`-time with a demo account. In this case, the real testing 
seems to be useful only for comparing stuff for scientific papers.&]
[s0; So yeah, pretty stable state now. I could do a release. I`'ll 
just clean this little fucker and let it go once again.&]
[s0; ...&]
[s0; There is many better algorithms, than the graph based DQN, which 
is used in the Overlook. Those have many restrictions, however. 
They are implemented with frameworks, which translates very badly 
to Ultimate`+`+ conventions. I watched a deep`-boot`-camp lecture, 
which told about C`-51 and others. I found some implementations 
also, but the convention gap for translating is too large.&]
[s0; The ConvNetCpp library, which I wrote by translating ConvNetJs 
to Ultimate`+`+ conventions, would be a good framework for producing 
professional products and standalone executables for all desktop 
platforms. I just don`'t have a clue about how to attract users 
and commiters. The social programming focus too much on typeless 
script languages, which are close to familiar math, but has many 
pitfalls in readability and error rate.&]
[s0; I think the world should use reference memory based subset of 
C`+`+ with type relaxations for scripting. Then you would only 
need to learn the best language (C`+`+) and use it in web browsers 
etc. The Hunagrian notation and standard conventions are pure 
brainfuck, but with the C`+`+ grammar there is enough flexibility 
for morphing conventions. One can`'t morph conventions with Java 
or C# or JavaScript... and they are all using that fucking brainfuck 
convention.&]
[s0; ....&]
[s0; Oops, that DQN discount factor was completely opposite all the 
time. There is no future reward potential with the action in 
this use case. I did the v0.3 release with the wrong value.&]
[s0; &]
[s3; 14.10.2017&]
[s0; The performance has been good, but small improvements wouldn`'t 
hurt.&]
[s0; Faster operating modes requires more agent groups, because DQN`-agents 
work optimally with certain amounts of data. Sectors and groups 
must be set accordingly. More groups requires much more processing, 
so the fast mode is not default. This could be done cleanly with 
planning and more workforce, but I just hacked this together.&]
[s0; &]
[s3; 16.10.2017&]
[s0; [/ The fog has cleared and a new summit can be seen...]&]
[s0; Testing seems to be required for real. The training performance 
is far from realtime performance. I`'ve been playing with the 
preprocessor settings and there is many working configurations. 
All those configurations should be available simultaneously and 
best parts should be combined and combinations should be tested, 
and the best combination should be tested even with a separate 
data for verification.&]
[s0; Changing preprocessor variables to dynamic is a very challenging 
task. Planned changes might be the most unpleasant to implement 
so far.&]
[s0; &]
[s3; 17.10.2017&]
[s0; Oh damn. Seems like DQN is bad for this use case, because the 
discount factor is 0. When DQN drives virtual car or does something, 
where single action is rather meaningless alone (with many small 
adjusting actions per timestep), then that is a good use case 
for DQN. Now, with discount factor 0, faster and more precise 
methods can be used, like SVM.&]
[s0; ...&]
[s0; By the way, one thing in the electric universe theory have been 
very interesting for me. That is those alternative scientific 
theories, which are constantly under witch hunt. So, at Mars, 
many of those distinctive features can`'t be impact craters and 
some are huge canyons. In short, the electric universe theory 
is speculating, that there is electrical forces carving those 
features, and [^https`:`/`/youtu`.be`/RPGRirezQlo`?t`=3m31s^ that 
would be causing the imbalance between south and north hemisphere]. 
So, Earth has that imbalance too. Could that be because of similar 
reasons? Me asking these questions is the reason why I am such 
an outsider at the campus.&]
[s0; &]
[s3; 18.10.2017&]
[s0; Fuck this. I had to clean almost everything away again. All 
agent and agentsystem code. Luckily, now this seems to integrate 
a lot better to the existing code.&]
[s0; &]
[s3; 19.10.2017&]
[s0; I wrote headers and stubs of the new ExpertSystem code. I searched 
for ideas from scientific papers, but didn`'t find much existing 
useful code. I thought, that SVM would be good choice, but then 
I found comparison to random trees, which turned out to suit 
better for my needs.&]
[s0; Karpathy the AI leader have written forestjs library, which 
I will use as I used ConvNetJS. Those libraries are just pure 
gold and are worth translating to C`+`+. It has nice X,Y to true/false 
example, which will be a nice GUI demo.&]
[s0; One problem occured, however. The forestjs supports only binary 
class and two input variables. First I thought, that it will 
be a blocking problem. However, I had just read a scientific 
paper about emotion classifiers, and had seen positive results 
about decision`-level fusion. Those binary classifiers can be 
combined with the tree structure to give sort of fusion of values... 
because it can also give probability instead of binary only. 
It`'s only remotely similar, but that`'s enough for me.&]
[s0; &]
[s3; 21.10.2017&]
[s0; I am that kind of guy, who likes to watch [^https`:`/`/www`.youtube`.com`/watch`?v`=facDr2lTAUM`&t`=5529s^ t
rain driver`'s view going through snow storm] and drink coffee 
while listening to SPA radio channel at [^https`:`/`/www`.1`.fm^ 1.fm] 
. My dream is that I can have VR glasses, which shows that driver`'s 
view at background while the programming IDE floats slightly 
transparently in front of it. It`'s definitely closer if you 
use MS Windows... but I don`'t see it coming in a near future 
anyway.&]
[s0; Life will always be about mysterious black box neural machines 
resisting the electric scalability and carving tunnels in time 
by their senses. The observer, what we all feel, might be that 
infinite gradient of flow. It`'s about being in a pattern, sensing 
far and close, to past and future. Manipuling those senses in 
exploitative manners is just the force of death.&]
[s0; The Internet have brought up the best and the worst of the fast 
communication based on visual content. The best feature is that 
some hard`-to`-notice issues can now be persistently covered 
first time ever. The worst feature is all the over simplified 
click`-bait economics and politics, which gives a constant repulsive 
feeling, but `"works statistically`".&]
[s0; In Finnish, we have a popular song, which says `"sadness plays 
with black keys of piano, even though it touched one a white 
key`". I am in affective computing course, which tells how 7 
basic emotions consist of 5 sad emotions, 1 neutral and 1 happy. 
Sometimes I feel, that establishment is a saddest sad entity 
which calls everyone to make them feel less sad. Why there isn`'t 
5 different happiness and only 1 negative feeling? I know immediately 
at least 5 happy feelings:&]
[s0; 1. the bliss at weekend sunrise with hot cup of coffee&]
[s0; 2. the happiness about relationship of two persons&]
[s0; 3. euphoric feeling of fast profits, e.g. slot machine wins&]
[s0; 4. affection from physical touch&]
[s0; 5. visual excitement from beauty&]
[s0; I am a huge fan of the visual excitement...&]
[s0; &]
[s3; 24.10.2017&]
[s0; I`'ve been writing the new expert system with genetic optimizer 
and random forest instead of DQN agents. This seems to be much 
more logical solution, but I couldn`'t find this without steps 
in`-between.&]
[s0; So, zigzag indicator can give ideal labels with 2`^x periods, 
and those can be used in learning sectors with random forests. 
Shortest period sector is `"advisor`" and it learns the label 
and it is usable. Advisors are fused together and trained for 
sensitive idling in negative trends. Sectors, advisors and fusions 
are optimized separately with DE solver. I don`'t know all optimized 
variables yet, but at least random forest inputs are optimized. 
The evolve function must take into account which variables are 
floating point numbers and which are enumerators without sane 
value between two values.&]
[s0; This is very simple version in comparison to current DQN system. 
It was difficult to upgrade it, however.&]
[s0; ...&]
[s0; It have been beautiful days lately. Frozen grass, trees and 
roads with blue skies. Not snow yet... only 4 months since last 
snowing ;)&]
[s0; &]
[s3; 25.10.2017&]
[s0; There is some #metoo momentum going on. I understand, that it 
is good to suppress the annoying behaviour of many men. Those 
men goes to whores, sex tourism and actually see women accepting 
sex always for some amount of money. I know there is a lot of 
them out there... Those men are prone to harass women for real 
and the campaign is addressing that problem. I get that.&]
[s0; However, that campaign is harmful in some cases. Women many 
times are very permissive and open to romantical encounters, 
but they tend to `"forget`" it afterwards. They say that they 
were drunk and didn`'t mean it, and then they pretend that they 
are some innocent little girls. My experience has been exactly 
that many times, especially because I am poor and unattractive 
without women being drunk. Women have been romantically open 
explicitly and when I don`'t respond immediately, but after a 
while, then they are pretending that they weren`'t ever acting 
like that. Some of those pretenders have gone probably along 
with the #metoo campaign. They did not have the real problem, 
they are pretending and some others have the real problem. They 
can`'t ethically and honestly do that, but now they are encouraged 
to.&]
[s0; I had a partner once, which was narcissistic and very abusive 
against me having women as friends and against me liking porn, 
and in the end she exited the relationship as pretending that 
I was sexually harassing her. She had wrote some innocent event 
to her diary in a innocently delusional way, that could have 
been interpreted as sexual harassment, and she found that diary 
entry much later with her low IQ hard drug graffiti gang friends 
and they decided to revenge to me and to my family. They owe 
me big time. Yet, they seem to get more social support, which 
is utterly insane and disgusting. Originally, that was some very 
mild and playful drunken parody about her abusive effort to make 
me stop watching porn, and she couldn`'t see it in that way, 
because she was so narcissistic and manipulative. She insisted 
coming over me, but she couldn`'t accept me liking porn. Shame 
is entirely on her and her party. I am very sorry for myself 
only and her party accumulated a huge unnecessary and painful 
mess, which they don`'t seem to clean ever...&]
[s0; It makes me wonder, how many narcissistic fake feminist women 
are there using that #metoo campaign as weapon against normal 
men. Those wouldn`'t be about equality between men and women, 
but about social power hungriness.&]
[s0; &]
[s0; &]
[s3; 26.10.2017&]
[s0; I didn`'t have time for doing this, yet I`'m still implementing 
this. I feel terrible about this time consuming... but this is 
just very expensive to leave without running version.&]
[s0; &]
[s3; 27.10.2017&]
[s0; New expert system has requirements for evolve functions done, 
but many issues have came up.&]
[s0; The random forest algorithm seems to be much more expensive 
than I thought. I might cope with it anyway, because the differential 
evolution solver might work with short samples too. Those can 
be taken from different positions.&]
[s0; I really don`'t have time for this from my school, but I`'ll 
do it anyway. I`'m feeling guilty...&]
[s0; Labels are invalid, but otherwise I completed today`'s tasks 
o n time. They should be visually verfiable anyway.&]
[s0; &]
[s3; 28.10.2017&]
[s0; First snow of the winter is snowing. Only 5 months since last 
snowing. Everything is looks gray and miserable already.&]
[s0; ...&]
[s0; So, Trump released JFK assasination cables. The high ranking 
doctor, who did the autopsy, wrote that there was obviously second 
shooter and now that conspiracy theory became conspiracy fact. 
We could go on and on from this topic to all other topics, like 
termite and cruise missiles at skyscrapers, chemtrails everywhere 
for wheather control, intentional fluoride poisoning, nuclear 
tsunamis, fake history chronology with cement pyramids, lizard 
people as neighbours, controlled class differences, the new spy 
industry, crop circles, little alien book... who knows? It`'s 
the spooky new world, which would make too many to scare monsters 
under their beds.&]
[s0; I have listened to Art Bell radio show and many callers there 
are clearly hoaxing, some more obviously and some less. One never 
know, but the repeating stories of the human breeding centre 
gets old for some of us. One thing is certain: news, maps and 
Internet makes the Earth feel way too small in comparison to 
how large it is...&]
[s0; &]
[s3; 30.10.2017&]
[s0; The monolithic version of the ExpertSystem genetic optimizer 
runs, but it takes huge amount of memory (10`-20Gb) and crashes 
because of that easily. It also does unnecessary work without 
caching. It was the best waypoint, however, and splitting it 
to parts before this would have been a bad choice, because I 
would have done it wrong. The better performance is achieved 
with VectorBool cache objects and random forest re`-using instead 
of random forest caching.&]
[s0; The ExpertSystem runs in realtime, and did show positive results 
immediately. However, the quality is limited because of the monolithic 
inefficiency.&]
[s0; The current monolithic ExpertSystem must be splitted to small 
pipeline parts for efficiency and better quality.&]
[s0; This was a good time to clean all old agent system code away....&]
[s0; ]]